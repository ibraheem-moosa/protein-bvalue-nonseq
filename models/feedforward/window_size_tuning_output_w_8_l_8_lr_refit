7
Input read.
(540304, 15)
(540304, 315)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.48424297
Validation score: 0.129185
Iteration 2, loss = 0.43028145
Validation score: 0.168569
Iteration 3, loss = 0.41831848
Validation score: 0.182723
Iteration 4, loss = 0.41300035
Validation score: 0.188641
Iteration 5, loss = 0.41060898
Validation score: 0.190584
Iteration 6, loss = 0.40938050
Validation score: 0.192230
Iteration 7, loss = 0.40860185
Validation score: 0.191629
Iteration 8, loss = 0.40776304
Validation score: 0.194318
Iteration 9, loss = 0.40718398
Validation score: 0.195192
Iteration 10, loss = 0.40666888
Validation score: 0.195610
Iteration 11, loss = 0.40623384
Validation score: 0.196004
Iteration 12, loss = 0.40594805
Validation score: 0.196324
Iteration 13, loss = 0.40570020
Validation score: 0.196886
Iteration 14, loss = 0.40537603
Validation score: 0.196969
Iteration 15, loss = 0.40513271
Validation score: 0.196367
Iteration 16, loss = 0.40499591
Validation score: 0.196306
Iteration 17, loss = 0.40472329
Validation score: 0.197346
Iteration 18, loss = 0.40459618
Validation score: 0.197240
Iteration 19, loss = 0.40449368
Validation score: 0.194554
Iteration 20, loss = 0.40427748
Validation score: 0.197063
Iteration 21, loss = 0.40412255
Validation score: 0.197372
Iteration 22, loss = 0.40410654
Validation score: 0.197220
Iteration 23, loss = 0.40387963
Validation score: 0.196815
Iteration 24, loss = 0.40381431
Validation score: 0.197308
Iteration 25, loss = 0.40369556
Validation score: 0.196533
Iteration 26, loss = 0.40353424
Validation score: 0.197254
Iteration 27, loss = 0.40341487
Validation score: 0.197404
Iteration 28, loss = 0.40336072
Validation score: 0.196934
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.8026139292468512, total= 2.0min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.42059696
Validation score: 0.165241
Iteration 2, loss = 0.41247105
Validation score: 0.191161
Iteration 3, loss = 0.41127276
Validation score: 0.193117
Iteration 4, loss = 0.41046940
Validation score: 0.191269
Iteration 5, loss = 0.41012276
Validation score: 0.194583
Iteration 6, loss = 0.41008706
Validation score: 0.192989
Iteration 7, loss = 0.41004419
Validation score: 0.193613
Iteration 8, loss = 0.40969643
Validation score: 0.190649
Iteration 9, loss = 0.41015112
Validation score: 0.193067
Iteration 10, loss = 0.40914833
Validation score: 0.188489
Iteration 11, loss = 0.40974363
Validation score: 0.192609
Iteration 12, loss = 0.40930130
Validation score: 0.193416
Iteration 13, loss = 0.40963951
Validation score: 0.190340
Iteration 14, loss = 0.40926321
Validation score: 0.193081
Iteration 15, loss = 0.40923433
Validation score: 0.194919
Iteration 16, loss = 0.40897277
Validation score: 0.191857
Iteration 17, loss = 0.40935809
Validation score: 0.193262
Iteration 18, loss = 0.40934070
Validation score: 0.193518
Iteration 19, loss = 0.40910009
Validation score: 0.194682
Iteration 20, loss = 0.40931433
Validation score: 0.190909
Iteration 21, loss = 0.40938122
Validation score: 0.190542
Iteration 22, loss = 0.40941177
Validation score: 0.193683
Iteration 23, loss = 0.40930748
Validation score: 0.192502
Iteration 24, loss = 0.40923562
Validation score: 0.185359
Iteration 25, loss = 0.40944731
Validation score: 0.193855
Iteration 26, loss = 0.40932208
Validation score: 0.190232
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8039805977048051, total= 1.7min
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.53209573
Validation score: 0.184869
Iteration 2, loss = 0.41272907
Validation score: 0.188802
Iteration 3, loss = 0.41098491
Validation score: 0.189604
Iteration 4, loss = 0.40877596
Validation score: 0.196816
Iteration 5, loss = 0.40704919
Validation score: 0.198582
Iteration 6, loss = 0.40595092
Validation score: 0.199558
Iteration 7, loss = 0.40512362
Validation score: 0.198281
Iteration 8, loss = 0.40470374
Validation score: 0.200148
Iteration 9, loss = 0.40431537
Validation score: 0.199336
Iteration 10, loss = 0.40410343
Validation score: 0.199762
Iteration 11, loss = 0.40375071
Validation score: 0.201011
Iteration 12, loss = 0.40345111
Validation score: 0.201099
Iteration 13, loss = 0.40331571
Validation score: 0.200777
Iteration 14, loss = 0.40310719
Validation score: 0.199601
Iteration 15, loss = 0.40303667
Validation score: 0.197922
Iteration 16, loss = 0.40278909
Validation score: 0.200859
Iteration 17, loss = 0.40275767
Validation score: 0.199543
Iteration 18, loss = 0.40261514
Validation score: 0.198967
Iteration 19, loss = 0.40240873
Validation score: 0.199696
Iteration 20, loss = 0.40232517
Validation score: 0.200762
Iteration 21, loss = 0.40228090
Validation score: 0.199916
Iteration 22, loss = 0.40228066
Validation score: 0.199567
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8012059409397237, total= 1.6min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.43319363
Validation score: 0.181677
Iteration 2, loss = 0.41206553
Validation score: 0.182160
Iteration 3, loss = 0.41081612
Validation score: 0.183572
Iteration 4, loss = 0.41018902
Validation score: 0.181301
Iteration 5, loss = 0.41000253
Validation score: 0.174156
Iteration 6, loss = 0.40978125
Validation score: 0.187017
Iteration 7, loss = 0.40907052
Validation score: 0.187954
Iteration 8, loss = 0.40887066
Validation score: 0.185555
Iteration 9, loss = 0.40880537
Validation score: 0.183518
Iteration 10, loss = 0.40846618
Validation score: 0.185912
Iteration 11, loss = 0.40846098
Validation score: 0.185778
Iteration 12, loss = 0.40822545
Validation score: 0.187065
Iteration 13, loss = 0.40787237
Validation score: 0.180909
Iteration 14, loss = 0.40778076
Validation score: 0.187627
Iteration 15, loss = 0.40763943
Validation score: 0.185341
Iteration 16, loss = 0.40770951
Validation score: 0.188989
Iteration 17, loss = 0.40756716
Validation score: 0.187870
Iteration 18, loss = 0.40734770
Validation score: 0.187593
Iteration 19, loss = 0.40737806
Validation score: 0.188057
Iteration 20, loss = 0.40743271
Validation score: 0.187062
Iteration 21, loss = 0.40687731
Validation score: 0.185061
Iteration 22, loss = 0.40710302
Validation score: 0.188742
Iteration 23, loss = 0.40665395
Validation score: 0.186807
Iteration 24, loss = 0.40686180
Validation score: 0.188789
Iteration 25, loss = 0.40660373
Validation score: 0.191276
Iteration 26, loss = 0.40671877
Validation score: 0.187934
Iteration 27, loss = 0.40633653
Validation score: 0.188778
Iteration 28, loss = 0.40656222
Validation score: 0.188745
Iteration 29, loss = 0.40659969
Validation score: 0.189395
Iteration 30, loss = 0.40643633
Validation score: 0.191072
Iteration 31, loss = 0.40605450
Validation score: 0.187058
Iteration 32, loss = 0.40663184
Validation score: 0.190830
Iteration 33, loss = 0.40631652
Validation score: 0.189767
Iteration 34, loss = 0.40636893
Validation score: 0.188729
Iteration 35, loss = 0.40634370
Validation score: 0.187082
Iteration 36, loss = 0.40633818
Validation score: 0.188822
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.8013976006128418, total= 2.3min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.44904436
Validation score: 0.186016
Iteration 2, loss = 0.41142181
Validation score: 0.198613
Iteration 3, loss = 0.40855879
Validation score: 0.202768
Iteration 4, loss = 0.40721802
Validation score: 0.204425
Iteration 5, loss = 0.40651206
Validation score: 0.204379
Iteration 6, loss = 0.40572015
Validation score: 0.205009
Iteration 7, loss = 0.40516022
Validation score: 0.204763
Iteration 8, loss = 0.40464348
Validation score: 0.204840
Iteration 9, loss = 0.40445781
Validation score: 0.203861
Iteration 10, loss = 0.40394742
Validation score: 0.205094
Iteration 11, loss = 0.40359527
Validation score: 0.205646
Iteration 12, loss = 0.40323919
Validation score: 0.204695
Iteration 13, loss = 0.40302535
Validation score: 0.205006
Iteration 14, loss = 0.40275282
Validation score: 0.205178
Iteration 15, loss = 0.40250427
Validation score: 0.203894
Iteration 16, loss = 0.40230976
Validation score: 0.203355
Iteration 17, loss = 0.40210871
Validation score: 0.203548
Iteration 18, loss = 0.40183194
Validation score: 0.204719
Iteration 19, loss = 0.40175777
Validation score: 0.203981
Iteration 20, loss = 0.40157298
Validation score: 0.204555
Iteration 21, loss = 0.40133894
Validation score: 0.204531
Iteration 22, loss = 0.40129310
Validation score: 0.204980
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.8017642083386834, total= 1.5min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.44618136
Validation score: 0.176000
Iteration 2, loss = 0.41371446
Validation score: 0.189041
Iteration 3, loss = 0.40994890
Validation score: 0.183856
Iteration 4, loss = 0.40855869
Validation score: 0.194166
Iteration 5, loss = 0.40776508
Validation score: 0.197728
Iteration 6, loss = 0.40722117
Validation score: 0.193293
Iteration 7, loss = 0.40699473
Validation score: 0.196725
Iteration 8, loss = 0.40690476
Validation score: 0.196595
Iteration 9, loss = 0.40731885
Validation score: 0.196276
Iteration 10, loss = 0.40686204
Validation score: 0.196527
Iteration 11, loss = 0.40659027
Validation score: 0.197394
Iteration 12, loss = 0.40668801
Validation score: 0.196316
Iteration 13, loss = 0.40638826
Validation score: 0.195320
Iteration 14, loss = 0.40654970
Validation score: 0.197584
Iteration 15, loss = 0.40631334
Validation score: 0.194506
Iteration 16, loss = 0.40621232
Validation score: 0.197922
Iteration 17, loss = 0.40601286
Validation score: 0.195299
Iteration 18, loss = 0.40604438
Validation score: 0.195217
Iteration 19, loss = 0.40633857
Validation score: 0.191942
Iteration 20, loss = 0.40615062
Validation score: 0.192376
Iteration 21, loss = 0.40601438
Validation score: 0.196524
Iteration 22, loss = 0.40585844
Validation score: 0.194514
Iteration 23, loss = 0.40594652
Validation score: 0.197253
Iteration 24, loss = 0.40596344
Validation score: 0.195847
Iteration 25, loss = 0.40602327
Validation score: 0.197063
Iteration 26, loss = 0.40604350
Validation score: 0.197766
Iteration 27, loss = 0.40579201
Validation score: 0.196110
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8025265043230598, total= 2.4min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.57738829
Validation score: -0.036261
Iteration 2, loss = 0.50983438
Validation score: 0.000982
Iteration 3, loss = 0.47510586
Validation score: 0.143318
Iteration 4, loss = 0.42077968
Validation score: 0.178034
Iteration 5, loss = 0.41290715
Validation score: 0.184618
Iteration 6, loss = 0.41088043
Validation score: 0.186756
Iteration 7, loss = 0.41010708
Validation score: 0.188237
Iteration 8, loss = 0.40971238
Validation score: 0.188122
Iteration 9, loss = 0.40941196
Validation score: 0.189350
Iteration 10, loss = 0.40917794
Validation score: 0.189559
Iteration 11, loss = 0.40897644
Validation score: 0.189929
Iteration 12, loss = 0.40881334
Validation score: 0.190544
Iteration 13, loss = 0.40860855
Validation score: 0.190667
Iteration 14, loss = 0.40847148
Validation score: 0.190905
Iteration 15, loss = 0.40832904
Validation score: 0.190954
Iteration 16, loss = 0.40814379
Validation score: 0.191514
Iteration 17, loss = 0.40800843
Validation score: 0.191112
Iteration 18, loss = 0.40779439
Validation score: 0.191717
Iteration 19, loss = 0.40768695
Validation score: 0.191747
Iteration 20, loss = 0.40750108
Validation score: 0.191540
Iteration 21, loss = 0.40733236
Validation score: 0.192448
Iteration 22, loss = 0.40717709
Validation score: 0.192358
Iteration 23, loss = 0.40699877
Validation score: 0.193019
Iteration 24, loss = 0.40685459
Validation score: 0.193033
Iteration 25, loss = 0.40669980
Validation score: 0.193496
Iteration 26, loss = 0.40657919
Validation score: 0.193370
Iteration 27, loss = 0.40644546
Validation score: 0.194038
Iteration 28, loss = 0.40631135
Validation score: 0.193906
Iteration 29, loss = 0.40619721
Validation score: 0.193557
Iteration 30, loss = 0.40604962
Validation score: 0.194164
Iteration 31, loss = 0.40592336
Validation score: 0.194125
Iteration 32, loss = 0.40580677
Validation score: 0.194560
Iteration 33, loss = 0.40567388
Validation score: 0.194408
Iteration 34, loss = 0.40554367
Validation score: 0.194516
Iteration 35, loss = 0.40547344
Validation score: 0.194702
Iteration 36, loss = 0.40534773
Validation score: 0.194526
Iteration 37, loss = 0.40527538
Validation score: 0.193684
Iteration 38, loss = 0.40520296
Validation score: 0.195091
Iteration 39, loss = 0.40505258
Validation score: 0.192420
Iteration 40, loss = 0.40499595
Validation score: 0.194565
Iteration 41, loss = 0.40493792
Validation score: 0.195465
Iteration 42, loss = 0.40476310
Validation score: 0.195003
Iteration 43, loss = 0.40469811
Validation score: 0.194489
Iteration 44, loss = 0.40463925
Validation score: 0.195281
Iteration 45, loss = 0.40452811
Validation score: 0.195506
Iteration 46, loss = 0.40445103
Validation score: 0.195664
Iteration 47, loss = 0.40438057
Validation score: 0.195535
Iteration 48, loss = 0.40430540
Validation score: 0.194081
Iteration 49, loss = 0.40423659
Validation score: 0.195638
Iteration 50, loss = 0.40408828
Validation score: 0.195396
Iteration 51, loss = 0.40400680
Validation score: 0.195665
Iteration 52, loss = 0.40398203
Validation score: 0.196211
Iteration 53, loss = 0.40383912
Validation score: 0.195123
Iteration 54, loss = 0.40381557
Validation score: 0.196239
Iteration 55, loss = 0.40370592
Validation score: 0.196016
Iteration 56, loss = 0.40367031
Validation score: 0.195780
Iteration 57, loss = 0.40357667
Validation score: 0.195073
Iteration 58, loss = 0.40349085
Validation score: 0.196462
Iteration 59, loss = 0.40341044
Validation score: 0.196204
Iteration 60, loss = 0.40334462
Validation score: 0.196363
Iteration 61, loss = 0.40328090
Validation score: 0.196385
Iteration 62, loss = 0.40324489
Validation score: 0.196362
Iteration 63, loss = 0.40315410
Validation score: 0.196097
Iteration 64, loss = 0.40309272
Validation score: 0.194946
Iteration 65, loss = 0.40301363
Validation score: 0.193669
Iteration 66, loss = 0.40294081
Validation score: 0.196011
Iteration 67, loss = 0.40293497
Validation score: 0.196487
Iteration 68, loss = 0.40287455
Validation score: 0.196667
Iteration 69, loss = 0.40277886
Validation score: 0.196488
Iteration 70, loss = 0.40273551
Validation score: 0.196229
Iteration 71, loss = 0.40262942
Validation score: 0.196351
Iteration 72, loss = 0.40265905
Validation score: 0.195658
Iteration 73, loss = 0.40261241
Validation score: 0.195940
Iteration 74, loss = 0.40251021
Validation score: 0.196016
Iteration 75, loss = 0.40247188
Validation score: 0.196207
Iteration 76, loss = 0.40241105
Validation score: 0.196114
Iteration 77, loss = 0.40236981
Validation score: 0.195967
Iteration 78, loss = 0.40232615
Validation score: 0.195941
Iteration 79, loss = 0.40227598
Validation score: 0.196193
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.8006969712650318, total= 6.4min
Iteration 1, loss = 0.48278971
Validation score: 0.130163
Iteration 2, loss = 0.43461857
Validation score: 0.146181
Iteration 3, loss = 0.42978958
Validation score: 0.150802
Iteration 4, loss = 0.42738263
Validation score: 0.154180
Iteration 5, loss = 0.42561069
Validation score: 0.156701
Iteration 6, loss = 0.42421145
Validation score: 0.158712
Iteration 7, loss = 0.42301921
Validation score: 0.160903
Iteration 8, loss = 0.42199251
Validation score: 0.162638
Iteration 9, loss = 0.42106063
Validation score: 0.163995
Iteration 10, loss = 0.42020190
Validation score: 0.164572
Iteration 11, loss = 0.41937606
Validation score: 0.166832
Iteration 12, loss = 0.41862340
Validation score: 0.168615
Iteration 13, loss = 0.41788031
Validation score: 0.169022
Iteration 14, loss = 0.41723319
Validation score: 0.171146
Iteration 15, loss = 0.41652763
Validation score: 0.171950
Iteration 16, loss = 0.41592127
Validation score: 0.172510
Iteration 17, loss = 0.41533699
Validation score: 0.174399
Iteration 18, loss = 0.41476468
Validation score: 0.175246
Iteration 19, loss = 0.41420013
Validation score: 0.176745
Iteration 20, loss = 0.41371245
Validation score: 0.177100
Iteration 21, loss = 0.41317342
Validation score: 0.177865
Iteration 22, loss = 0.41264124
Validation score: 0.178442
Iteration 23, loss = 0.41213560
Validation score: 0.180197
Iteration 24, loss = 0.41166498
Validation score: 0.180710
Iteration 25, loss = 0.41120407
Validation score: 0.181920
Iteration 26, loss = 0.41075516
Validation score: 0.182853
Iteration 27, loss = 0.41031319
Validation score: 0.183464
Iteration 28, loss = 0.40987281
Validation score: 0.184477
Iteration 29, loss = 0.40946361
Validation score: 0.183440
Iteration 30, loss = 0.40906204
Validation score: 0.185629
Iteration 31, loss = 0.40870823
Validation score: 0.185319
Iteration 32, loss = 0.40835772
Validation score: 0.185769
Iteration 33, loss = 0.40801224
Validation score: 0.187199
Iteration 34, loss = 0.40769179
Validation score: 0.187472
Iteration 35, loss = 0.40747519
Validation score: 0.187586
Iteration 36, loss = 0.40719505
Validation score: 0.187170
Iteration 37, loss = 0.40693037
Validation score: 0.188785
Iteration 38, loss = 0.40667602
Validation score: 0.189071
Iteration 39, loss = 0.40647693
Validation score: 0.189130
Iteration 40, loss = 0.40622315
Validation score: 0.190019
Iteration 41, loss = 0.40601691
Validation score: 0.190329
Iteration 42, loss = 0.40579760
Validation score: 0.188724
Iteration 43, loss = 0.40563653
Validation score: 0.190742
Iteration 44, loss = 0.40540915
Validation score: 0.188920
Iteration 45, loss = 0.40528629
Validation score: 0.191166
Iteration 46, loss = 0.40510856
Validation score: 0.191373
Iteration 47, loss = 0.40489529
Validation score: 0.190334
Iteration 48, loss = 0.40474770
Validation score: 0.191543
Iteration 49, loss = 0.40456201
Validation score: 0.191751
Iteration 50, loss = 0.40443481
Validation score: 0.191652
Iteration 51, loss = 0.40425170
Validation score: 0.192444
Iteration 52, loss = 0.40410989
Validation score: 0.192587
Iteration 53, loss = 0.40404953
Validation score: 0.192743
Iteration 54, loss = 0.40386004
Validation score: 0.192912
Iteration 55, loss = 0.40377336
Validation score: 0.193067
Iteration 56, loss = 0.40360361
Validation score: 0.192658
Iteration 57, loss = 0.40346136
Validation score: 0.193231
Iteration 58, loss = 0.40333992
Validation score: 0.192981
Iteration 59, loss = 0.40325391
Validation score: 0.192880
Iteration 60, loss = 0.40315389
Validation score: 0.193146
Iteration 61, loss = 0.40305181
Validation score: 0.193557
Iteration 62, loss = 0.40298069
Validation score: 0.193966
Iteration 63, loss = 0.40286808
Validation score: 0.193615
Iteration 64, loss = 0.40273810
Validation score: 0.193842
Iteration 65, loss = 0.40269662
Validation score: 0.194070
Iteration 66, loss = 0.40258986
Validation score: 0.194189
Iteration 67, loss = 0.40250410
Validation score: 0.194099
Iteration 68, loss = 0.40241566
Validation score: 0.194247
Iteration 69, loss = 0.40230844
Validation score: 0.194785
Iteration 70, loss = 0.40225432
Validation score: 0.194391
Iteration 71, loss = 0.40217375
Validation score: 0.194642
Iteration 72, loss = 0.40206696
Validation score: 0.194390
Iteration 73, loss = 0.40203693
Validation score: 0.194206
Iteration 74, loss = 0.40194766
Validation score: 0.193963
Iteration 75, loss = 0.40191766
Validation score: 0.195196
Iteration 76, loss = 0.40184965
Validation score: 0.195095
Iteration 77, loss = 0.40174261
Validation score: 0.194970
Iteration 78, loss = 0.40171488
Validation score: 0.194540
Iteration 79, loss = 0.40160779
Validation score: 0.195058
Iteration 80, loss = 0.40161420
Validation score: 0.194445
Iteration 81, loss = 0.40150545
Validation score: 0.195070
Iteration 82, loss = 0.40146695
Validation score: 0.195385
Iteration 83, loss = 0.40141156
Validation score: 0.194468
Iteration 84, loss = 0.40133820
Validation score: 0.195111
Iteration 85, loss = 0.40127833
Validation score: 0.194829
Iteration 86, loss = 0.40130631
Validation score: 0.195317
Iteration 87, loss = 0.40119164
Validation score: 0.194776
Iteration 88, loss = 0.40113151
Validation score: 0.194450
Iteration 89, loss = 0.40110855
Validation score: 0.195485
Iteration 90, loss = 0.40105250
Validation score: 0.195064
Iteration 91, loss = 0.40106562
Validation score: 0.195615
Iteration 92, loss = 0.40098054
Validation score: 0.195104
Iteration 93, loss = 0.40095262
Validation score: 0.195697
Iteration 94, loss = 0.40088301
Validation score: 0.195300
Iteration 95, loss = 0.40086817
Validation score: 0.195032
Iteration 96, loss = 0.40082319
Validation score: 0.193594
Iteration 97, loss = 0.40078283
Validation score: 0.195479
Iteration 98, loss = 0.40078090
Validation score: 0.195453
Iteration 99, loss = 0.40072024
Validation score: 0.195248
Iteration 100, loss = 0.40072462
Validation score: 0.195702
Iteration 101, loss = 0.40063073
Validation score: 0.195389
Iteration 102, loss = 0.40062511
Validation score: 0.195168
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.000125
0.2061073196789981
[[0.20032967 0.26185481 0.11748508 0.13784077 0.1813878  0.16384184
  0.21103062 0.16181912 0.18075589 0.15547191 0.17472682 0.14912661
  0.1531264  0.14880436 0.18807579 0.21984955 0.23354126 0.20140276
  0.12814654 0.23773696 0.13817002]
 [0.21336575 0.20844616 0.19275909 0.14604299 0.22311252 0.12834876
  0.23286522 0.19809565 0.19328992 0.19075417 0.20416872 0.15041268
  0.14388253 0.21854667 0.16360264 0.26698518 0.18161489 0.1958437
  0.20252159 0.19575987 0.21583644]
 [0.20483052 0.22291994 0.15583768 0.19847011 0.17560824 0.23671753
  0.16619641 0.1213988  0.22432449 0.23181238 0.16228232 0.17079419
  0.21408112 0.29814716 0.2666938  0.27742687 0.27476373 0.30674508
  0.24751647 0.19845196 0.13740436]
 [0.23334848 0.26429574 0.20706144 0.31648427 0.26499573 0.23186616
  0.22313739 0.19583883 0.1861449  0.22258506 0.24236368 0.27823006
  0.23623341 0.29287873 0.3354447  0.5380382  0.28886845 0.27434304
  0.3110724  0.34770037 0.21183106]
 [0.24016956 0.32151844 0.31985175 0.27998404 0.18676391 0.20529237
  0.20966641 0.22584712 0.21901755 0.23213133 0.2884722  0.28131923
  0.26537432 0.20837297 0.23999595 0.41386925 0.33433677 0.20316453
  0.29220043 0.36814211 0.25159243]
 [0.20786717 0.27521074 0.2110734  0.22450779 0.18059666 0.18228123
  0.2064583  0.19079751 0.17322662 0.11797984 0.30853074 0.14809279
  0.19562246 0.25579973 0.24411191 0.33768351 0.25272393 0.28130559
  0.25166608 0.31745597 0.18926747]
 [0.15849671 0.17828103 0.1734199  0.20341763 0.1487732  0.12215878
  0.14489772 0.20008455 0.11636382 0.16100522 0.19696813 0.17112496
  0.19021588 0.22743295 0.25769635 0.37329862 0.2495552  0.1778455
  0.23019701 0.21577003 0.22655565]
 [0.21739245 0.22470349 0.19032416 0.17588676 0.18522061 0.1371278
  0.18138047 0.19776062 0.21650068 0.11904614 0.18489914 0.16745094
  0.17227783 0.21769278 0.19018692 0.29440983 0.2011878  0.23597907
  0.17342558 0.30889805 0.21902679]]
[array([[ 2.47676287e-001, -1.32114741e-001,  1.80322103e-316,
         2.70805676e-316,  1.27312133e-001,  4.43103330e-001,
        -2.22869209e-317, -8.44912043e-002],
       [-4.14299337e-001,  2.72483361e-001, -3.50501893e-316,
         1.57010441e-316, -2.32267386e-002, -1.08489876e-001,
        -1.47807243e-316,  6.99221713e-002],
       [-1.71319558e-001,  3.12507358e-001, -2.00845032e-316,
         8.18245238e-317,  6.47830978e-001, -1.17744739e-001,
         1.66059214e-316,  3.86674968e-002],
       [-3.96114901e-002,  4.11346298e-001,  1.27464861e-316,
         1.47237694e-316, -8.33903302e-002, -1.75358934e-001,
         2.44982238e-316,  4.18132448e-001],
       [ 1.60421905e-001, -2.00453191e-001,  3.56106139e-316,
         1.54272314e-316, -4.20148628e-001,  4.72314398e-001,
        -8.29791256e-317,  1.99106068e-001],
       [ 4.15868052e-001, -4.48803736e-001, -1.68342597e-316,
         2.46689734e-316,  2.39395096e-002, -2.22955702e-001,
        -2.21281183e-317, -3.52120946e-002],
       [ 3.07509488e-001, -4.32955245e-001, -2.86862241e-316,
        -6.82575158e-317, -7.20318453e-002,  1.73037765e-001,
        -8.29393484e-317, -1.43605864e-001],
       [ 1.82793378e-001, -3.85641989e-001,  4.19544736e-317,
        -2.07062601e-316, -8.16926886e-002,  2.63806924e-001,
        -3.76033398e-316, -1.73114769e-001]]), array([[ 9.24797732e-002, -2.70085389e-001,  1.63463221e-001,
         3.66791100e-001, -1.08532771e-001,  5.07477891e-002,
        -5.24118394e-001,  5.10417158e-001],
       [ 3.75266518e-002,  5.42581348e-001,  1.19718874e-001,
        -2.28515605e-001, -2.42213060e-001, -7.91422988e-002,
         3.91196295e-001,  1.60482120e-001],
       [ 3.29280089e-316,  1.39285905e-316, -1.78260708e-316,
         2.26213489e-317,  4.50374186e-317, -2.94904177e-316,
         1.30491694e-316, -3.61090585e-316],
       [-7.63563189e-317,  4.72314356e-317, -1.39650254e-316,
         1.68492788e-317,  3.73991681e-316,  3.47927139e-316,
        -1.41650740e-316, -1.34299844e-316],
       [ 4.10364679e-002,  5.29562663e-001,  1.18465679e-001,
        -2.67795731e-001,  2.02907614e-002,  1.58419036e-001,
         5.33347560e-001, -3.11758971e-001],
       [-3.20394926e-001, -3.19808176e-001, -4.31075377e-001,
        -1.78429090e-002, -5.35330860e-002,  7.52232936e-002,
         2.85130485e-001,  5.16475167e-001],
       [-1.46514233e-316, -9.49170411e-317, -1.41443781e-317,
        -3.51902372e-316, -6.84199399e-317, -4.59346072e-317,
        -5.97721063e-317, -1.19423898e-316],
       [-9.43475899e-002,  3.02737515e-001,  1.68590762e-001,
        -2.05762567e-001, -8.97501949e-003,  1.33069527e-001,
         3.37136032e-001, -2.30001116e-001]]), array([[-3.58129319e-002,  5.79582030e-002, -1.43304464e-001,
        -2.82845169e-001,  3.15200710e-316, -1.32234602e-001,
        -3.10211388e-316, -1.13375107e-001],
       [-1.00092108e-001,  1.95634004e-001, -2.89092981e-001,
         4.39669254e-001, -1.32090664e-316,  2.52422603e-001,
        -3.35379562e-316,  4.55096749e-001],
       [-1.91919120e-001,  3.08802975e-001, -2.12671748e-002,
         2.18922648e-001,  5.89681281e-317, -5.91053067e-002,
         1.99369880e-316,  2.25860606e-001],
       [-1.33913365e-001, -3.26730760e-001, -2.14614301e-002,
         2.28596773e-002, -3.02764648e-316, -3.36571626e-001,
         2.42696750e-316, -7.31731165e-002],
       [ 2.11850132e-002,  8.91799951e-002,  9.39480236e-002,
         1.46418065e-001,  2.49997340e-316,  8.25494444e-003,
        -2.19115935e-316,  5.70684223e-002],
       [-9.28385050e-002, -3.50894597e-001,  1.27916864e-001,
         5.52758735e-001,  2.20232029e-316,  7.83886785e-002,
        -1.50535182e-317, -1.75596737e-001],
       [-1.34431632e-001,  2.19684175e-001, -1.22343207e-001,
         3.54426712e-001, -8.48724889e-317,  4.73900266e-001,
        -1.65878445e-316,  4.96935739e-001],
       [-1.64514213e-001, -1.13381868e-002, -2.56024715e-001,
        -5.91126207e-001, -1.22879319e-316, -4.33183466e-002,
         1.50756306e-316, -1.99113858e-001]]), array([[-7.05942494e-002, -2.45349476e-002,  3.87485861e-002,
         3.98568058e-002,  1.93947391e-316, -1.64899824e-316,
        -4.89548749e-317,  8.99360442e-317],
       [-3.68101587e-001,  3.11231291e-001,  2.56916431e-001,
         2.85075016e-001,  3.56801611e-317,  3.18537215e-316,
         2.23848348e-317,  2.25733179e-316],
       [-2.10718838e-001, -8.76545884e-002,  1.70831333e-001,
         1.91088895e-001,  2.92669454e-316, -7.97911720e-317,
         3.50437596e-316, -7.02484966e-317],
       [-5.35516905e-001,  1.69291383e-001,  5.34869364e-001,
         1.34543706e-001, -1.68523816e-318,  2.72004432e-317,
        -1.12354737e-316,  3.59813608e-316],
       [-9.10352513e-317, -3.15735314e-316,  1.16805523e-316,
         2.69060206e-316, -2.05963418e-317, -1.11538551e-316,
         3.00701677e-316,  8.13395095e-319],
       [-5.54937785e-001, -2.06205273e-001,  4.77964073e-001,
         2.57964168e-001, -2.76661031e-316,  2.84073369e-317,
        -4.06447649e-317, -7.02464314e-317],
       [-2.01964802e-316,  5.63070955e-317, -6.36299240e-317,
         9.11336593e-317, -1.78743588e-316, -2.24050416e-316,
         2.98479755e-316, -2.81000058e-316],
       [ 4.21633118e-001, -4.24162288e-001,  3.21015040e-001,
         4.09452806e-001,  1.69325595e-316,  2.22611415e-316,
        -6.39291895e-317,  1.11284087e-317]]), array([[ 4.07730024e-001,  3.16629464e-316, -2.34077073e-001,
         1.56896631e-001,  1.83240534e-316,  4.47101156e-001,
        -3.76542716e-001,  2.51702903e-002],
       [-4.92229742e-002, -7.16967314e-317, -1.20442766e-001,
        -5.89042686e-003,  2.58020181e-316,  3.42647118e-001,
        -1.65202376e-001,  1.51320279e-002],
       [-1.19738211e-001,  5.02025883e-317,  6.40066331e-001,
         1.63814423e-001, -1.51889939e-316,  2.37759246e-002,
         8.70590833e-002, -1.20519986e-001],
       [-4.40510496e-001,  1.96155227e-317,  3.59801073e-001,
         4.71135616e-001, -2.63474339e-316,  2.33331205e-002,
         1.41016905e-001, -8.25864308e-003],
       [ 5.97553624e-317,  5.73996624e-317,  1.50419323e-317,
        -9.28775233e-318,  2.03206641e-316, -4.59031154e-317,
         2.81719690e-317, -6.80283237e-317],
       [-7.70665630e-317,  1.63836190e-316,  1.15861008e-316,
        -2.07935022e-316, -3.23876933e-316, -1.51208391e-316,
         1.27766547e-316,  2.97235475e-317],
       [-2.41369008e-316,  4.69391365e-317, -1.00380058e-317,
        -8.37146757e-317, -4.95321363e-317,  5.36873420e-317,
         3.20635264e-318, -4.12056875e-317],
       [-3.60765875e-316,  2.27891292e-316,  3.10507936e-316,
         1.48461811e-316, -2.05533458e-316,  1.17931770e-316,
         1.76640049e-316,  1.13604600e-316]]), array([[-2.33379759e-001, -4.60504907e-001,  1.61526581e-001,
         8.19756424e-001, -1.54489163e-001, -2.57636542e-001,
        -8.03086805e-002,  5.32383498e-003],
       [-2.69346211e-316, -3.93763378e-316,  2.18491461e-316,
         2.28727617e-316, -5.75318694e-317, -1.86821290e-317,
         1.98041175e-317,  1.66517217e-316],
       [-4.53928669e-001,  1.11847841e-001,  9.88646617e-002,
        -1.24055858e-001,  3.34852619e-001,  6.04820413e-001,
         5.46283885e-002, -2.48660969e-002],
       [ 5.35047342e-001,  1.95510143e-001,  3.75656878e-001,
         9.98352475e-002, -4.22457491e-001,  6.05570536e-001,
        -3.73574082e-001, -6.83707253e-003],
       [ 1.49694687e-316, -7.66103181e-317,  1.06337477e-316,
        -9.28375287e-317, -9.01855424e-317, -5.62085491e-317,
         1.52760473e-316,  2.03159843e-317],
       [ 6.59490015e-001, -3.40625956e-001,  2.73083630e-004,
         1.65183609e-001,  7.94245752e-003, -7.39042001e-002,
         3.66364849e-001, -3.17506721e-003],
       [-3.90274652e-001, -1.31816706e-001,  3.92389453e-001,
         1.57271254e-001,  2.29270456e-001,  4.52942193e-001,
         3.39242710e-001, -1.33097187e-002],
       [ 5.76852810e-002,  2.90317288e-003,  1.52012871e-002,
         7.03763951e-002, -1.65731420e-002,  2.15756533e-002,
         3.44604285e-002,  8.79776970e-004]]), array([[ 5.29486007e-001,  1.77754241e-316,  5.34047367e-001,
         2.87682781e-002, -2.97377964e-316, -2.81966016e-316,
         8.46134602e-317,  8.85309610e-317],
       [-4.40270277e-001, -4.47936120e-317, -2.47372478e-001,
        -5.35521517e-002, -1.17988973e-316, -1.15458107e-316,
        -1.08798690e-317, -1.43417015e-316],
       [-1.39002838e-001,  3.10501766e-316, -3.90688631e-001,
        -3.05861474e-002,  2.01604129e-316,  7.62380099e-317,
         7.46562538e-317,  8.62359718e-317],
       [ 6.11053890e-001, -1.73099357e-317,  7.00222094e-001,
         1.70526994e-002,  1.65356025e-316, -2.66164823e-317,
        -9.52669335e-317, -2.79833120e-316],
       [-1.78154631e-001, -1.61492426e-316, -2.56676760e-001,
        -3.38015509e-002,  4.71676369e-317, -1.48954014e-316,
        -5.53321211e-317,  2.79574111e-317],
       [-6.88924132e-001, -4.82069534e-317, -1.88940360e-001,
        -1.13525217e-001,  8.38111420e-317, -7.61266525e-317,
         1.56998633e-316,  8.05971561e-317],
       [ 3.04172616e-001,  3.92813814e-316,  2.25635713e-001,
        -4.52083192e-002,  2.29943329e-316, -1.71744382e-316,
         8.91532565e-318,  8.51789084e-317],
       [ 9.59568648e-002,  2.79636437e-316, -5.27061787e-002,
        -4.61457754e-003,  1.58923972e-317,  4.19614202e-317,
         2.32367719e-317, -6.13456708e-317]]), array([[-8.58419674e-001],
       [ 2.63178577e-316],
       [-9.68427089e-001],
       [-1.14957366e-001],
       [-1.54623229e-316],
       [ 1.66193278e-316],
       [-5.93217556e-317],
       [ 1.22594984e-316]])]
[ 0.04058231 -0.08081095  0.04488076  0.18317784  0.05095032  0.09349698
 -0.06987476  0.04623765]
TRAIN
Mean PCC: 0.48130225611112154 +- 0.4290438499718833
PCC: Min: -0.08215833412592982 Max: 0.8778087828500345
Mean MSE: 0.773844007602573 +- 0.40831101706092804
MSE: Min: 0.3375667975431455 Max: 1.359135210329337
MSE:
ArgMin: [('4rgi', 71), ('3o2e', 86), ('2yvi', 89), ('6c4q', 85), ('5aiz', 110), ('4o7q', 94), ('4hlb', 95), ('1tif', 76), ('5w0h', 80), ('2jku', 35)]
ArgMax: [('4aqo', 86), ('3dt5', 119), ('1j0p', 108), ('1jni', 62), ('5dbl', 130), ('2pne', 81), ('1lmi', 131), ('2a3m', 107), ('2w9y', 136), ('3zfp', 148)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('2nwf', 141), ('4aqo', 86), ('1jni', 62), ('2h5c', 198), ('3zfp', 148), ('3tch', 517), ('2c1i', 383), ('1j0p', 108)]
ArgMax: [('4rgi', 71), ('5w0h', 80), ('3bv8', 85), ('3o2e', 86), ('1xmt', 95), ('2yvi', 89), ('2p0h', 118), ('5aiz', 110), ('4hlb', 95), ('1tif', 76)]
MSE vs Length correlation: 0.06197773266696005
PCC vs Length correlation: 0.07290246148964163
MSE vs b-val mean correlation: 2.5199019350719e-05
PCC vs b-val mean correlation: 3.408986284747506e-05
VAL
Mean PCC: 0.4787462282916247 +- 0.42604803923862145
PCC: Min: -0.01731569230797853 Max: 0.888396586069065
Mean MSE: 0.7761056242912229 +- 0.40143110160831574
MSE: Min: 0.2982453808436405 Max: 1.3321466580628027
MSE:
ArgMin: [('2vc8', 72), ('2i5u', 77), ('4i6x', 117), ('3mao', 105), ('4gos', 115), ('3tbn', 87), ('5hqh', 96), ('2b1k', 149), ('3hrl', 94), ('2q3t', 121)]
ArgMax: [('2rkn', 77), ('2rbk', 261), ('3sw0', 186), ('1u5p', 211), ('3gvo', 342), ('3fgh', 67), ('2v9k', 467), ('4e1b', 330), ('4rep', 489), ('5hfg', 205)]
PCC:
ArgMin: [('2rbk', 261), ('2rkn', 77), ('1u5p', 211), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('4e1b', 330), ('4rep', 489), ('5hfg', 205), ('5gof', 390)]
ArgMax: [('2vc8', 72), ('4i6x', 117), ('2i5u', 77), ('3mao', 105), ('5hqh', 96), ('3tbn', 87), ('4gos', 115), ('2q3t', 121), ('2b1k', 149), ('3fk8', 131)]
MSE vs Length correlation: 0.0752759173367582
PCC vs Length correlation: 0.08719607959107123
MSE vs b-val mean correlation: 0.0006807663140014908
PCC vs b-val mean correlation: 0.0005589342423559795
TEST
Mean PCC: 0.470244071478463 +- 0.43601648596817744
PCC: Min: -0.05820209983560064 Max: 0.8937693381809342
Mean MSE: 0.7836019655495223 +- 0.41275711880513566
MSE: Min: 0.3095682314909476 Max: 1.357371598793245
MSE:
ArgMin: [('3cp0', 63), ('4qq6', 58), ('2od5', 91), ('3t7l', 74), ('5ol9', 81), ('5kuj', 95), ('3o70', 55), ('4h4n', 62), ('2ovg', 58), ('3chm', 161)]
ArgMax: [('4npn', 71), ('3b6e', 182), ('5i8g', 226), ('4xxt', 221), ('2vac', 134), ('4gs3', 90), ('4qdn', 118), ('4uyr', 188), ('2o1a', 122), ('1r5y', 361)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('1r5y', 361), ('3b6e', 182), ('2vac', 134), ('4uyr', 188), ('4qdn', 118), ('4r1b', 282), ('1s2w', 258)]
ArgMax: [('3cp0', 63), ('2od5', 91), ('4qq6', 58), ('1dqg', 134), ('5ol9', 81), ('5kuj', 95), ('3chm', 161), ('1mud', 225), ('3t7l', 74), ('1od3', 131)]
MSE vs Length correlation: 0.059857477125873415
PCC vs Length correlation: 0.06303422592161212
MSE vs b-val mean correlation: 4.34557997200935e-05
PCC vs b-val mean correlation: 3.5966467431869376e-05
8
Input read.
(540304, 17)
(540304, 357)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.45281002
Validation score: 0.176577
Iteration 2, loss = 0.41268966
Validation score: 0.187221
Iteration 3, loss = 0.40994242
Validation score: 0.188063
Iteration 4, loss = 0.40888713
Validation score: 0.189705
Iteration 5, loss = 0.40769574
Validation score: 0.192069
Iteration 6, loss = 0.40707512
Validation score: 0.193224
Iteration 7, loss = 0.40629949
Validation score: 0.193570
Iteration 8, loss = 0.40604255
Validation score: 0.193957
Iteration 9, loss = 0.40546830
Validation score: 0.194345
Iteration 10, loss = 0.40511602
Validation score: 0.194516
Iteration 11, loss = 0.40480828
Validation score: 0.194759
Iteration 12, loss = 0.40451341
Validation score: 0.194047
Iteration 13, loss = 0.40438627
Validation score: 0.195986
Iteration 14, loss = 0.40403566
Validation score: 0.195289
Iteration 15, loss = 0.40384355
Validation score: 0.195796
Iteration 16, loss = 0.40365491
Validation score: 0.191295
Iteration 17, loss = 0.40345558
Validation score: 0.193600
Iteration 18, loss = 0.40330429
Validation score: 0.194243
Iteration 19, loss = 0.40310364
Validation score: 0.194920
Iteration 20, loss = 0.40284731
Validation score: 0.196023
Iteration 21, loss = 0.40251789
Validation score: 0.196191
Iteration 22, loss = 0.40254113
Validation score: 0.195466
Iteration 23, loss = 0.40226222
Validation score: 0.195346
Iteration 24, loss = 0.40222004
Validation score: 0.194630
Iteration 25, loss = 0.40216593
Validation score: 0.195977
Iteration 26, loss = 0.40196765
Validation score: 0.190680
Iteration 27, loss = 0.40188920
Validation score: 0.196358
Iteration 28, loss = 0.40186461
Validation score: 0.196328
Iteration 29, loss = 0.40175825
Validation score: 0.196098
Iteration 30, loss = 0.40153260
Validation score: 0.196621
Iteration 31, loss = 0.40154498
Validation score: 0.195792
Iteration 32, loss = 0.40140222
Validation score: 0.195861
Iteration 33, loss = 0.40135337
Validation score: 0.195611
Iteration 34, loss = 0.40117200
Validation score: 0.195463
Iteration 35, loss = 0.40115764
Validation score: 0.195587
Iteration 36, loss = 0.40103843
Validation score: 0.196097
Iteration 37, loss = 0.40096230
Validation score: 0.195764
Iteration 38, loss = 0.40086325
Validation score: 0.194552
Iteration 39, loss = 0.40094618
Validation score: 0.192600
Iteration 40, loss = 0.40085682
Validation score: 0.194977
Iteration 41, loss = 0.40065970
Validation score: 0.195634
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.0005
0.2080405253637374
[[0.19349874 0.18202233 0.20758292 0.1543904  0.20068268 0.204552
  0.20762638 0.16741809 0.23852748 0.19503874 0.17901494 0.18769263
  0.13405753 0.26921025 0.21903869 0.21920448 0.20914357 0.19628713
  0.24477018 0.23406072 0.48838252]
 [0.22103758 0.17091418 0.14305721 0.2019771  0.25560782 0.3020317
  0.20026043 0.2951797  0.2643283  0.22261871 0.24045378 0.22234321
  0.18449659 0.53830966 0.20147694 0.20563849 0.20178468 0.20105045
  0.16609168 0.21644177 0.21843511]
 [0.2063658  0.19643446 0.28490555 0.33438004 0.27976563 0.27169328
  0.18747915 0.22546115 0.18672902 0.28177003 0.31621891 0.26141776
  0.29970447 0.48509579 0.39172711 0.31264113 0.25453319 0.24785423
  0.27935833 0.32063073 0.37668796]
 [0.28951451 0.36216202 0.36850456 0.40102705 0.27847132 0.53277688
  0.3477051  0.32482915 0.26583671 0.27367552 0.39387862 0.37725023
  0.40905912 0.62865527 0.41420052 0.50278912 0.41742281 0.40198509
  0.56326245 0.45489387 0.47243616]
 [0.24767623 0.42553962 0.43412657 0.31812024 0.22696692 0.43305051
  0.34680689 0.35209592 0.31414499 0.25388673 0.37300077 0.31534637
  0.38740118 0.45504438 0.45642656 0.33892747 0.46248255 0.46284904
  0.3363451  0.37197768 0.52971909]
 [0.23413425 0.29414328 0.23961949 0.30155496 0.26774854 0.27124758
  0.22554559 0.25598868 0.2442906  0.25593879 0.27810186 0.2149393
  0.27716855 0.27576664 0.36110027 0.28534046 0.38839837 0.41321641
  0.31149674 0.37523574 0.63863956]
 [0.25037126 0.19879846 0.19126765 0.20426336 0.16801515 0.20609331
  0.20148538 0.16694421 0.14353444 0.24305522 0.19163303 0.26633599
  0.24638794 0.14630465 0.34461508 0.18544614 0.30991787 0.25558805
  0.27898406 0.31011582 0.15574893]
 [0.22902326 0.15112086 0.14126204 0.19094307 0.16406286 0.133985
  0.19170445 0.18843927 0.1909394  0.25071206 0.16140302 0.19694129
  0.23107425 0.23657958 0.28378879 0.34369922 0.25640081 0.13387663
  0.28952605 0.26827816 0.22766016]]
[array([[-3.09135437e-316,  2.25626959e-316,  3.53135415e-001,
        -3.02089047e-001, -3.78899692e-001,  1.97647753e-001,
        -1.41684006e-316,  2.77683655e-001],
       [-3.55250867e-316,  2.01924926e-317, -1.35263914e-001,
        -3.03462710e-001, -1.76466286e-001,  5.39970723e-001,
         2.80877056e-316,  3.36515123e-001],
       [-5.37470034e-316,  2.44588809e-316, -4.38492496e-001,
         2.08002004e-001,  5.16487678e-001, -3.82277434e-001,
        -2.84140685e-316,  9.18060370e-002],
       [-5.66298765e-316, -2.84139134e-316,  5.48185797e-001,
         1.46790169e-001,  4.94373201e-001,  3.48322518e-001,
         1.81026216e-316, -2.13842678e-002],
       [-1.27564726e-316,  5.41555236e-318, -4.52322828e-002,
         6.42974503e-001, -3.90416808e-001, -1.29926722e-001,
        -3.92005137e-316,  3.73259033e-002],
       [-1.63220046e-316, -5.32113740e-317, -3.08466473e-001,
         2.11034665e-001,  2.20254361e-001,  2.51036986e-003,
         1.08424944e-316,  4.51789920e-001],
       [-2.28046033e-316,  1.49597905e-316,  1.35570520e-001,
         5.78150428e-001,  4.36696226e-001,  8.92598899e-002,
        -2.25391463e-317,  3.93808837e-001],
       [-1.96166655e-316,  2.98047102e-316,  3.93663869e-001,
        -3.48712147e-001, -8.89836466e-002, -1.51370788e-001,
        -1.12801995e-316,  3.70035551e-001]]), array([[ 1.82177814e-317, -2.43638641e-317,  1.19428171e-316,
        -5.85190570e-316,  2.92409872e-316,  1.60547674e-316,
         1.82444016e-317,  5.88297942e-316],
       [-2.97930655e-316, -3.95860405e-316, -2.82717149e-316,
         1.80206265e-316, -3.86372077e-316, -2.68012639e-316,
        -1.95100417e-316, -7.88159259e-317],
       [ 1.72285526e-001, -7.19460271e-317,  4.16873407e-316,
        -4.05662538e-001,  3.21887118e-316,  2.96874454e-001,
        -2.06002843e-002,  1.44064050e-001],
       [ 1.06006050e-001, -3.62114066e-316,  2.82205119e-316,
         6.35101506e-001, -1.25296915e-316, -4.49549994e-001,
         1.03994916e-001,  4.89591711e-001],
       [-1.70486008e-001, -1.51692975e-319, -2.48015337e-316,
         5.12992073e-001,  5.78172783e-316,  1.23364359e-001,
         1.27803349e-001, -2.93157525e-001],
       [ 3.19686344e-001, -7.39655501e-317, -1.64663686e-316,
        -1.73233330e-001,  9.93205642e-317,  4.77841692e-001,
         3.03367841e-002, -6.44555899e-002],
       [-2.19752494e-317, -5.95505870e-317, -3.44746577e-316,
        -1.96401020e-316,  3.16327921e-316, -6.06696951e-316,
        -2.84874506e-316,  2.30282881e-316],
       [-2.91135827e-001,  2.45848226e-316, -2.05180478e-316,
        -9.60129149e-002, -3.44573980e-316,  5.68305253e-001,
         1.76915211e-001,  3.67516639e-001]]), array([[ 5.51388071e-001,  4.53101967e-001, -1.68809643e-001,
         3.43447062e-001, -3.34856673e-001, -3.90530781e-317,
         2.81906998e-001,  1.35386442e-001],
       [-2.27286897e-317,  5.60853939e-316,  3.47773060e-316,
        -4.47169676e-316, -2.40306811e-316,  1.27868962e-316,
        -1.28634289e-317, -2.25835351e-316],
       [ 4.01883436e-316, -7.03287180e-317,  1.43249463e-316,
        -2.90898619e-316,  2.41731064e-316, -5.66198983e-317,
         2.31524428e-316,  2.41463473e-316],
       [-1.90500379e-001, -9.99629190e-002, -4.34127773e-001,
        -4.18273247e-001, -2.36206117e-001, -4.57365857e-317,
        -1.90313976e-001,  1.05221573e-001],
       [-5.35997392e-317,  4.00559473e-316, -8.52169367e-317,
        -1.97326197e-316,  2.55186729e-316,  5.26766636e-316,
        -4.32923105e-316, -1.80899814e-317],
       [-2.41437124e-001, -2.20666332e-001,  3.96369759e-001,
         3.81229437e-001,  2.58660117e-001,  5.22177981e-320,
         5.58647399e-001, -3.20301625e-001],
       [-9.96258304e-002, -1.96232160e-001,  1.18971354e-002,
        -5.95578348e-002,  1.68599495e-002, -1.61398934e-316,
        -1.62300042e-002,  9.60015982e-002],
       [ 3.19195970e-001,  2.69952837e-001,  3.19599335e-001,
         4.08523717e-001,  1.69043785e-001, -1.26140147e-317,
         1.60076432e-001, -1.45507860e-001]]), array([[-2.64633721e-001, -1.54997632e-317, -6.80185655e-001,
         1.10032925e-316,  3.48416518e-001,  1.03094323e-001,
        -1.99924602e-317, -1.68633236e-001],
       [-3.42658579e-001,  1.73628502e-318, -4.55530333e-001,
        -3.30443712e-316,  4.03872444e-001,  2.60181434e-002,
        -4.06098132e-316, -3.40091952e-001],
       [-4.80062905e-001,  4.28851505e-316,  8.16155429e-002,
         1.59972814e-316,  2.88129426e-001,  1.74145766e-001,
        -2.24527174e-316,  4.47675809e-001],
       [-4.77437225e-001,  1.12267223e-316, -3.21226443e-001,
        -5.65813760e-317,  3.48327108e-001,  4.07256759e-001,
        -2.65467514e-316,  4.75840884e-001],
       [-4.31408246e-002,  3.65794055e-316,  5.86630756e-002,
        -1.38055731e-316,  3.12598511e-002,  3.58124588e-001,
        -1.97460326e-316,  4.22744235e-001],
       [-1.12402756e-316, -3.78319538e-316, -5.46111163e-317,
         4.04397973e-316, -2.27035822e-316, -6.55613501e-317,
        -1.43086352e-317, -9.15874685e-318],
       [-1.98636903e-001,  4.54025103e-316,  1.61357463e-001,
         1.48877345e-317,  5.85840608e-001,  2.72737026e-001,
         1.27467385e-316, -2.32969730e-001],
       [ 2.08690194e-001, -4.10518058e-317, -9.03219888e-002,
        -7.74253732e-318, -2.47378084e-001, -1.06379696e-001,
         2.17540819e-316, -1.82819550e-001]]), array([[ 8.63405454e-001,  9.93276937e-002, -1.60825175e-002,
         1.67059168e-316, -5.99122759e-002,  2.88549238e-316,
         4.18640633e-008,  2.25111451e-316],
       [ 1.32641577e-316, -6.36061644e-317, -5.99834725e-318,
        -2.39366851e-316, -4.81572485e-316, -1.52098109e-317,
         1.37789968e-319, -8.25516501e-318],
       [ 7.18833110e-001,  1.49377448e-001, -1.46080093e-002,
         2.80277878e-316, -5.94279562e-001, -2.96305229e-316,
         1.99702321e-009, -1.71670846e-316],
       [ 2.47368595e-316, -7.46128551e-317,  1.14927604e-316,
         1.06681470e-317, -4.44095362e-316, -4.44963534e-316,
         3.46469379e-316, -6.82707320e-317],
       [-2.88615995e-001, -3.25650184e-001, -3.57030534e-002,
        -1.41845056e-316,  4.71314155e-001, -1.04497799e-316,
        -7.50386303e-005,  5.74409658e-316],
       [ 1.65161721e-001,  2.26116554e-001,  2.98278697e-001,
         1.80000368e-317,  5.47332784e-001,  1.55035231e-316,
        -5.65494992e-007,  1.65295185e-316],
       [ 6.73717994e-317,  1.86547810e-316, -4.33019932e-317,
         2.13230927e-316, -1.36475096e-316,  2.22117092e-317,
        -4.13653458e-316, -3.63507707e-316],
       [-2.38464551e-001,  2.98622026e-001,  3.34963141e-001,
         1.04286512e-316,  3.66139309e-001, -3.07953410e-316,
        -2.28736426e-006,  4.59121124e-317]]), array([[ 4.15424130e-317,  5.32711703e-316,  1.63311700e-002,
        -4.84980226e-001,  3.85053284e-002,  7.19037877e-001,
        -1.89863191e-001,  6.80525532e-001],
       [-1.79959795e-316,  2.90405611e-316, -4.97506253e-002,
        -1.11594141e-001,  1.06347620e-002,  1.76879368e-001,
        -8.29057741e-002,  1.20716889e-001],
       [ 3.73623696e-316,  3.94279528e-316, -6.67567915e-003,
        -2.45803250e-001,  3.02799492e-001, -2.38688283e-001,
         9.18749158e-002,  7.97665145e-002],
       [-5.19133153e-317, -1.09048233e-316, -3.56660046e-316,
         3.42885600e-316,  9.96930798e-317, -5.84598976e-316,
         3.47305481e-316, -1.27449179e-316],
       [ 5.58727703e-316,  7.24413872e-319,  6.18160598e-001,
         6.38690075e-001,  2.94617665e-001, -2.66342632e-001,
         6.16938959e-001, -2.56614504e-001],
       [ 1.59002148e-316,  1.83954573e-317,  2.13861157e-316,
         2.30103189e-316, -4.19394333e-316,  8.01922100e-317,
         4.64334257e-317,  1.21488682e-316],
       [ 3.27567327e-316,  3.04380934e-316,  1.55532605e-008,
         1.73520680e-007, -7.35158438e-014,  1.69815480e-007,
         3.90204851e-010,  6.51143822e-007],
       [ 3.49834495e-316, -4.82663846e-317,  1.11166692e-316,
         2.10023092e-316,  4.87886619e-316, -3.01945220e-316,
        -1.25368199e-316, -4.04653949e-316]]), array([[-3.12479229e-318, -2.81957533e-316,  1.69908909e-316,
        -3.56244394e-316, -2.66250578e-316,  2.00201526e-317,
        -2.43655835e-316,  3.30760685e-316],
       [-1.01061138e-316,  5.88602266e-316,  3.84664685e-316,
        -2.25200522e-316, -2.69356344e-316, -1.82716617e-316,
        -3.85824148e-316,  1.32947971e-316],
       [-4.33700242e-001, -1.07303301e-317,  1.71038164e-001,
        -2.03942958e-001,  4.29868534e-001,  4.14848064e-316,
         1.06210158e-001,  5.78819521e-002],
       [-2.25137251e-001, -3.73156977e-316, -1.04729254e-001,
         1.34844849e-001,  2.51253893e-001,  4.43142626e-316,
        -1.59201339e-001, -4.90627377e-001],
       [ 2.49488321e-001, -3.94307423e-316,  2.44506919e-001,
        -2.63186009e-002,  4.89353179e-002, -3.02607105e-316,
         8.84383910e-002, -6.26069984e-002],
       [ 4.35420475e-001,  4.25873920e-316, -2.40747353e-001,
        -9.21465404e-002, -2.57341137e-001, -2.84585073e-316,
         2.49391297e-001,  4.76532595e-001],
       [ 1.31857253e-001, -1.21300685e-316,  3.55984148e-001,
         3.30855503e-001,  4.91671557e-001, -2.44830718e-316,
        -2.83980197e-001,  1.27600313e-001],
       [ 5.67290038e-001,  1.26452594e-317,  3.07898955e-002,
        -7.78580171e-002,  2.02958116e-001, -2.40393193e-316,
         5.34100756e-001,  3.27865631e-001]]), array([[ 8.18497434e-001],
       [ 5.69790381e-316],
       [-4.13522763e-001],
       [-2.05275574e-001],
       [-5.73401635e-001],
       [ 3.94995311e-316],
       [ 5.41618265e-001],
       [ 6.55409267e-001]])]
[-0.1375701   0.07607621  0.08910978  0.15623042  0.1281643   0.06516488
 -0.05569077 -0.11948962]
TRAIN
Mean PCC: 0.48273124173233906 +- 0.438176196103615
PCC: Min: -0.11630391179996957 Max: 0.8885803212992094
Mean MSE: 0.7723416514823523 +- 0.4317370156732944
MSE: Min: 0.30524436199526 Max: 1.3837461890169136
MSE:
ArgMin: [('4hlb', 95), ('3bv8', 85), ('5aiz', 110), ('5w0h', 80), ('6c4q', 85), ('4rgi', 71), ('2yvi', 89), ('2huj', 125), ('4o7q', 94), ('3o2e', 86)]
ArgMax: [('4aqo', 86), ('3dt5', 119), ('1j0p', 108), ('5dbl', 130), ('2pne', 81), ('1lmi', 131), ('1jni', 62), ('2w9y', 136), ('2a3m', 107), ('2igd', 61)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('2nwf', 141), ('4aqo', 86), ('2h5c', 198), ('3zfp', 148), ('2w9y', 136), ('4rlc', 135), ('2pne', 81), ('3tch', 517)]
ArgMax: [('3bv8', 85), ('5w0h', 80), ('4hlb', 95), ('5aiz', 110), ('5zt3', 114), ('2huj', 125), ('4rgi', 71), ('2p0h', 118), ('6c4q', 85), ('1xmt', 95)]
MSE vs Length correlation: 0.05307740580735853
PCC vs Length correlation: 0.0705456026657707
MSE vs b-val mean correlation: 3.21114763852659e-05
PCC vs b-val mean correlation: 2.5101951039330217e-05
VAL
Mean PCC: 0.48089744283446234 +- 0.42889071289961656
PCC: Min: -0.004142741651699495 Max: 0.8851546780323454
Mean MSE: 0.7742648919261697 +- 0.4158376807260292
MSE: Min: 0.27146947469161237 Max: 1.3560467084634027
MSE:
ArgMin: [('2vc8', 72), ('2i5u', 77), ('3mao', 105), ('4i6x', 117), ('4gos', 115), ('5hqh', 96), ('5ijm', 98), ('2b1k', 149), ('3tbn', 87), ('4zc3', 57)]
ArgMax: [('2rkn', 77), ('3sw0', 186), ('2rbk', 261), ('3fgh', 67), ('1u5p', 211), ('3gvo', 342), ('2v9k', 467), ('4e1b', 330), ('3cao', 102), ('4rep', 489)]
PCC:
ArgMin: [('2rbk', 261), ('2rkn', 77), ('3gvo', 342), ('2v9k', 467), ('3sw0', 186), ('1u5p', 211), ('4e1b', 330), ('5hfg', 205), ('4rep', 489), ('4k73', 221)]
ArgMax: [('2vc8', 72), ('4i6x', 117), ('3mao', 105), ('5hqh', 96), ('2i5u', 77), ('4gos', 115), ('3tbn', 87), ('5ijm', 98), ('2b1k', 149), ('4zc3', 57)]
MSE vs Length correlation: 0.06417208850964295
PCC vs Length correlation: 0.08523322752749374
MSE vs b-val mean correlation: 0.0008844937399277164
PCC vs b-val mean correlation: 0.0006296465347011004
TEST
Mean PCC: 0.471277295390931 +- 0.44007500672859445
PCC: Min: -0.0732101307380137 Max: 0.8411213498142057
Mean MSE: 0.7833137865119724 +- 0.4304204730168254
MSE: Min: 0.3445646424187505 Max: 1.4249173239899784
MSE:
ArgMin: [('2od5', 91), ('5kuj', 95), ('4qq6', 58), ('3t7l', 74), ('5ol9', 81), ('3o70', 55), ('3cp0', 63), ('3chm', 161), ('1dqg', 134), ('1tzv', 141)]
ArgMax: [('4npn', 71), ('2o1a', 122), ('5i8g', 226), ('3b6e', 182), ('2vac', 134), ('4xxt', 221), ('4gs3', 90), ('1uoy', 64), ('4qdn', 118), ('5fie', 142)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('1r5y', 361), ('4r1b', 282), ('2vac', 134), ('4uyr', 188), ('3b6e', 182), ('2o1a', 122), ('3ip0', 158)]
ArgMax: [('2od5', 91), ('5ol9', 81), ('5kuj', 95), ('4rwu', 81), ('1mud', 225), ('4qq6', 58), ('3t7l', 74), ('1dqg', 134), ('3cp0', 63), ('3chm', 161)]
MSE vs Length correlation: 0.05029639735330548
PCC vs Length correlation: 0.06162199032583915
MSE vs b-val mean correlation: 6.956967455340468e-05
PCC vs b-val mean correlation: 4.088137048607887e-05
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.46392501
Validation score: 0.153072
Iteration 2, loss = 0.41982054
Validation score: 0.171678
Iteration 3, loss = 0.41328241
Validation score: 0.178536
Iteration 4, loss = 0.41072178
Validation score: 0.182010
Iteration 5, loss = 0.40928436
Validation score: 0.183854
Iteration 6, loss = 0.40854221
Validation score: 0.185031
Iteration 7, loss = 0.40790204
Validation score: 0.184102
Iteration 8, loss = 0.40741962
Validation score: 0.186192
Iteration 9, loss = 0.40687907
Validation score: 0.186209
Iteration 10, loss = 0.40632614
Validation score: 0.186645
Iteration 11, loss = 0.40588773
Validation score: 0.187050
Iteration 12, loss = 0.40548328
Validation score: 0.186622
Iteration 13, loss = 0.40507263
Validation score: 0.188138
Iteration 14, loss = 0.40470415
Validation score: 0.188388
Iteration 15, loss = 0.40431810
Validation score: 0.188316
Iteration 16, loss = 0.40404340
Validation score: 0.188196
Iteration 17, loss = 0.40361418
Validation score: 0.189078
Iteration 18, loss = 0.40343667
Validation score: 0.189615
Iteration 19, loss = 0.40311273
Validation score: 0.189341
Iteration 20, loss = 0.40285249
Validation score: 0.189763
Iteration 21, loss = 0.40257486
Validation score: 0.189793
Iteration 22, loss = 0.40234205
Validation score: 0.189964
Iteration 23, loss = 0.40213602
Validation score: 0.190108
Iteration 24, loss = 0.40187449
Validation score: 0.190120
Iteration 25, loss = 0.40174621
Validation score: 0.190001
Iteration 26, loss = 0.40162262
Validation score: 0.189787
Iteration 27, loss = 0.40142790
Validation score: 0.189734
Iteration 28, loss = 0.40128955
Validation score: 0.189778
Iteration 29, loss = 0.40116046
Validation score: 0.189895
Iteration 30, loss = 0.40105245
Validation score: 0.189370
Iteration 31, loss = 0.40089550
Validation score: 0.189406
Iteration 32, loss = 0.40080435
Validation score: 0.187706
Iteration 33, loss = 0.40071736
Validation score: 0.189569
Iteration 34, loss = 0.40054901
Validation score: 0.189504
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.804111889828125, total= 2.6min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.42070060
Validation score: 0.191834
Iteration 2, loss = 0.41026547
Validation score: 0.194653
Iteration 3, loss = 0.40967865
Validation score: 0.193524
Iteration 4, loss = 0.40921235
Validation score: 0.195234
Iteration 5, loss = 0.40879026
Validation score: 0.197115
Iteration 6, loss = 0.40919813
Validation score: 0.192927
Iteration 7, loss = 0.40868360
Validation score: 0.191722
Iteration 8, loss = 0.40862418
Validation score: 0.193406
Iteration 9, loss = 0.40857965
Validation score: 0.193808
Iteration 10, loss = 0.40852281
Validation score: 0.193906
Iteration 11, loss = 0.40819332
Validation score: 0.190106
Iteration 12, loss = 0.40837458
Validation score: 0.193806
Iteration 13, loss = 0.40859131
Validation score: 0.195289
Iteration 14, loss = 0.40811754
Validation score: 0.194659
Iteration 15, loss = 0.40809082
Validation score: 0.193613
Iteration 16, loss = 0.40774646
Validation score: 0.193423
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.8028405363098614, total= 1.0min
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.44577189
Validation score: 0.184261
Iteration 2, loss = 0.41169786
Validation score: 0.189725
Iteration 3, loss = 0.40972034
Validation score: 0.191923
Iteration 4, loss = 0.40840589
Validation score: 0.191210
Iteration 5, loss = 0.40691481
Validation score: 0.192864
Iteration 6, loss = 0.40659550
Validation score: 0.195429
Iteration 7, loss = 0.40596748
Validation score: 0.193563
Iteration 8, loss = 0.40553403
Validation score: 0.194807
Iteration 9, loss = 0.40534855
Validation score: 0.193838
Iteration 10, loss = 0.40523210
Validation score: 0.195378
Iteration 11, loss = 0.40516440
Validation score: 0.196229
Iteration 12, loss = 0.40486321
Validation score: 0.195101
Iteration 13, loss = 0.40485364
Validation score: 0.197058
Iteration 14, loss = 0.40476261
Validation score: 0.196730
Iteration 15, loss = 0.40463616
Validation score: 0.194753
Iteration 16, loss = 0.40437256
Validation score: 0.196433
Iteration 17, loss = 0.40442825
Validation score: 0.196554
Iteration 18, loss = 0.40425763
Validation score: 0.196446
Iteration 19, loss = 0.40415744
Validation score: 0.196039
Iteration 20, loss = 0.40396594
Validation score: 0.196646
Iteration 21, loss = 0.40403812
Validation score: 0.197029
Iteration 22, loss = 0.40390188
Validation score: 0.193070
Iteration 23, loss = 0.40368280
Validation score: 0.197926
Iteration 24, loss = 0.40378264
Validation score: 0.195881
Iteration 25, loss = 0.40358840
Validation score: 0.196792
Iteration 26, loss = 0.40365236
Validation score: 0.195898
Iteration 27, loss = 0.40349749
Validation score: 0.194939
Iteration 28, loss = 0.40315204
Validation score: 0.196266
Iteration 29, loss = 0.40309701
Validation score: 0.197842
Iteration 30, loss = 0.40311301
Validation score: 0.197086
Iteration 31, loss = 0.40287149
Validation score: 0.197837
Iteration 32, loss = 0.40269442
Validation score: 0.194673
Iteration 33, loss = 0.40281187
Validation score: 0.194956
Iteration 34, loss = 0.40253318
Validation score: 0.196718
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8006720931612966, total= 3.0min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.42688899
Validation score: 0.183265
Iteration 2, loss = 0.41435768
Validation score: 0.188794
Iteration 3, loss = 0.41255415
Validation score: 0.188584
Iteration 4, loss = 0.41128719
Validation score: 0.188283
Iteration 5, loss = 0.41135362
Validation score: 0.183068
Iteration 6, loss = 0.41133306
Validation score: 0.189496
Iteration 7, loss = 0.41080888
Validation score: 0.190082
Iteration 8, loss = 0.41085495
Validation score: 0.193556
Iteration 9, loss = 0.41053361
Validation score: 0.188927
Iteration 10, loss = 0.41069552
Validation score: 0.192159
Iteration 11, loss = 0.41038628
Validation score: 0.186634
Iteration 12, loss = 0.41084828
Validation score: 0.190361
Iteration 13, loss = 0.41029794
Validation score: 0.186660
Iteration 14, loss = 0.41041866
Validation score: 0.184428
Iteration 15, loss = 0.41052452
Validation score: 0.191522
Iteration 16, loss = 0.41045528
Validation score: 0.188493
Iteration 17, loss = 0.41017803
Validation score: 0.189726
Iteration 18, loss = 0.41037503
Validation score: 0.191806
Iteration 19, loss = 0.41062651
Validation score: 0.188523
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8027526387895019, total= 1.1min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.44891056
Validation score: 0.183110
Iteration 2, loss = 0.41200174
Validation score: 0.187596
Iteration 3, loss = 0.40980211
Validation score: 0.190390
Iteration 4, loss = 0.40842161
Validation score: 0.191323
Iteration 5, loss = 0.40721321
Validation score: 0.193125
Iteration 6, loss = 0.40616130
Validation score: 0.194098
Iteration 7, loss = 0.40541564
Validation score: 0.195021
Iteration 8, loss = 0.40479818
Validation score: 0.194498
Iteration 9, loss = 0.40442025
Validation score: 0.195328
Iteration 10, loss = 0.40396519
Validation score: 0.195751
Iteration 11, loss = 0.40373290
Validation score: 0.194653
Iteration 12, loss = 0.40345071
Validation score: 0.194697
Iteration 13, loss = 0.40318740
Validation score: 0.193945
Iteration 14, loss = 0.40300357
Validation score: 0.195006
Iteration 15, loss = 0.40269436
Validation score: 0.195709
Iteration 16, loss = 0.40245586
Validation score: 0.196147
Iteration 17, loss = 0.40230426
Validation score: 0.195623
Iteration 18, loss = 0.40198638
Validation score: 0.196834
Iteration 19, loss = 0.40194173
Validation score: 0.196625
Iteration 20, loss = 0.40172418
Validation score: 0.197140
Iteration 21, loss = 0.40149930
Validation score: 0.195708
Iteration 22, loss = 0.40140021
Validation score: 0.196187
Iteration 23, loss = 0.40129714
Validation score: 0.196541
Iteration 24, loss = 0.40101187
Validation score: 0.196021
Iteration 25, loss = 0.40089806
Validation score: 0.194804
Iteration 26, loss = 0.40098476
Validation score: 0.196367
Iteration 27, loss = 0.40079920
Validation score: 0.195893
Iteration 28, loss = 0.40062423
Validation score: 0.193483
Iteration 29, loss = 0.40053646
Validation score: 0.195737
Iteration 30, loss = 0.40045362
Validation score: 0.194345
Iteration 31, loss = 0.40054244
Validation score: 0.195792
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.799864399362072, total= 2.3min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.42758716
Validation score: 0.178074
Iteration 2, loss = 0.40873034
Validation score: 0.184396
Iteration 3, loss = 0.40716423
Validation score: 0.189382
Iteration 4, loss = 0.40661842
Validation score: 0.188671
Iteration 5, loss = 0.40604670
Validation score: 0.189963
Iteration 6, loss = 0.40578548
Validation score: 0.193039
Iteration 7, loss = 0.40566934
Validation score: 0.189939
Iteration 8, loss = 0.40524385
Validation score: 0.190659
Iteration 9, loss = 0.40505062
Validation score: 0.192440
Iteration 10, loss = 0.40477403
Validation score: 0.191041
Iteration 11, loss = 0.40504270
Validation score: 0.188497
Iteration 12, loss = 0.40467432
Validation score: 0.193380
Iteration 13, loss = 0.40452834
Validation score: 0.193023
Iteration 14, loss = 0.40438672
Validation score: 0.192561
Iteration 15, loss = 0.40429687
Validation score: 0.184706
Iteration 16, loss = 0.40411794
Validation score: 0.190124
Iteration 17, loss = 0.40396342
Validation score: 0.193912
Iteration 18, loss = 0.40376472
Validation score: 0.192294
Iteration 19, loss = 0.40358985
Validation score: 0.192837
Iteration 20, loss = 0.40365551
Validation score: 0.193504
Iteration 21, loss = 0.40354267
Validation score: 0.193482
Iteration 22, loss = 0.40348387
Validation score: 0.193717
Iteration 23, loss = 0.40341636
Validation score: 0.192195
Iteration 24, loss = 0.40339364
Validation score: 0.193351
Iteration 25, loss = 0.40316869
Validation score: 0.193717
Iteration 26, loss = 0.40325231
Validation score: 0.192435
Iteration 27, loss = 0.40312708
Validation score: 0.184890
Iteration 28, loss = 0.40323326
Validation score: 0.192525
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8009583499093628, total= 2.0min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.50997245
Validation score: 0.006894
Iteration 2, loss = 0.48401167
Validation score: 0.103111
Iteration 3, loss = 0.43712723
Validation score: 0.154310
Iteration 4, loss = 0.42432733
Validation score: 0.168087
Iteration 5, loss = 0.41883292
Validation score: 0.175664
Iteration 6, loss = 0.41547318
Validation score: 0.181504
Iteration 7, loss = 0.41332331
Validation score: 0.184533
Iteration 8, loss = 0.41190244
Validation score: 0.186642
Iteration 9, loss = 0.41088906
Validation score: 0.188518
Iteration 10, loss = 0.41002718
Validation score: 0.190054
Iteration 11, loss = 0.40938221
Validation score: 0.190504
Iteration 12, loss = 0.40880530
Validation score: 0.191969
Iteration 13, loss = 0.40824704
Validation score: 0.192987
Iteration 14, loss = 0.40779022
Validation score: 0.193222
Iteration 15, loss = 0.40728819
Validation score: 0.192814
Iteration 16, loss = 0.40692098
Validation score: 0.194594
Iteration 17, loss = 0.40659146
Validation score: 0.195254
Iteration 18, loss = 0.40620752
Validation score: 0.195475
Iteration 19, loss = 0.40587244
Validation score: 0.195877
Iteration 20, loss = 0.40553788
Validation score: 0.196252
Iteration 21, loss = 0.40531440
Validation score: 0.196648
Iteration 22, loss = 0.40505614
Validation score: 0.196456
Iteration 23, loss = 0.40491865
Validation score: 0.196867
Iteration 24, loss = 0.40467716
Validation score: 0.197221
Iteration 25, loss = 0.40444118
Validation score: 0.197745
Iteration 26, loss = 0.40424493
Validation score: 0.197736
Iteration 27, loss = 0.40416715
Validation score: 0.197427
Iteration 28, loss = 0.40402479
Validation score: 0.197773
Iteration 29, loss = 0.40379844
Validation score: 0.198013
Iteration 30, loss = 0.40369923
Validation score: 0.197456
Iteration 31, loss = 0.40355306
Validation score: 0.198403
Iteration 32, loss = 0.40348347
Validation score: 0.198285
Iteration 33, loss = 0.40336635
Validation score: 0.198374
Iteration 34, loss = 0.40329032
Validation score: 0.198455
Iteration 35, loss = 0.40317221
Validation score: 0.195362
Iteration 36, loss = 0.40311297
Validation score: 0.198587
Iteration 37, loss = 0.40301145
Validation score: 0.198744
Iteration 38, loss = 0.40290436
Validation score: 0.198688
Iteration 39, loss = 0.40288169
Validation score: 0.198444
Iteration 40, loss = 0.40287805
Validation score: 0.198349
Iteration 41, loss = 0.40279485
Validation score: 0.197933
Iteration 42, loss = 0.40272635
Validation score: 0.198599
Iteration 43, loss = 0.40271083
Validation score: 0.198464
Iteration 44, loss = 0.40264728
Validation score: 0.198905
Iteration 45, loss = 0.40257542
Validation score: 0.198165
Iteration 46, loss = 0.40251716
Validation score: 0.198410
Iteration 47, loss = 0.40251997
Validation score: 0.197983
Iteration 48, loss = 0.40240950
Validation score: 0.198730
Iteration 49, loss = 0.40232443
Validation score: 0.198599
Iteration 50, loss = 0.40233060
Validation score: 0.198536
Iteration 51, loss = 0.40228138
Validation score: 0.198713
Iteration 52, loss = 0.40224143
Validation score: 0.198598
Iteration 53, loss = 0.40217640
Validation score: 0.197967
Iteration 54, loss = 0.40216600
Validation score: 0.198606
Iteration 55, loss = 0.40212670
Validation score: 0.198499
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.8027494381743421, total= 4.7min
9
Input read.
(540304, 19)
(540304, 399)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.45098592
Validation score: 0.186397
Iteration 2, loss = 0.40859430
Validation score: 0.191105
Iteration 3, loss = 0.40719729
Validation score: 0.191469
Iteration 4, loss = 0.40659825
Validation score: 0.191759
Iteration 5, loss = 0.40608941
Validation score: 0.191757
Iteration 6, loss = 0.40564331
Validation score: 0.191476
Iteration 7, loss = 0.40496695
Validation score: 0.193620
Iteration 8, loss = 0.40486076
Validation score: 0.191576
Iteration 9, loss = 0.40454963
Validation score: 0.193563
Iteration 10, loss = 0.40416279
Validation score: 0.194387
Iteration 11, loss = 0.40405126
Validation score: 0.193779
Iteration 12, loss = 0.40397100
Validation score: 0.186911
Iteration 13, loss = 0.40371631
Validation score: 0.193397
Iteration 14, loss = 0.40347706
Validation score: 0.193668
Iteration 15, loss = 0.40342111
Validation score: 0.192368
Iteration 16, loss = 0.40326487
Validation score: 0.192977
Iteration 17, loss = 0.40327730
Validation score: 0.194183
Iteration 18, loss = 0.40317791
Validation score: 0.192455
Iteration 19, loss = 0.40277198
Validation score: 0.191169
Iteration 20, loss = 0.40277991
Validation score: 0.193136
Iteration 21, loss = 0.40279422
Validation score: 0.192488
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.002
0.20438623612027262
[[0.19246463 0.16484581 0.3196134  0.26837966 0.18971668 0.19726363
  0.30153418 0.16862213 0.19683287 0.28114839 0.19789325 0.22927865
  0.23407804 0.29307031 0.21419207 0.17510895 0.33682863 0.14544026
  0.33037328 0.27998032 0.17564413]
 [0.22641339 0.23824651 0.24861316 0.2161758  0.30854217 0.23244952
  0.37911609 0.18426272 0.16505082 0.30086707 0.23577683 0.25221259
  0.20540406 0.27264563 0.1910868  0.27745968 0.29399906 0.18893677
  0.22119446 0.17487069 0.29144225]
 [0.40662048 0.30063471 0.26238167 0.30156392 0.41399401 0.23376846
  0.49756049 0.26371838 0.31195499 0.24608388 0.31840568 0.4144432
  0.48003703 0.60155618 0.29486351 0.39684503 0.45078901 0.45575699
  0.36671432 0.39183035 0.35956866]
 [0.63590551 0.75371424 0.3727029  0.50077749 0.80863731 0.46917195
  0.83308625 0.34961404 0.59237401 0.37311014 0.3347075  0.48987708
  0.61794691 0.92964702 0.75045077 0.59916823 0.61234519 0.87375354
  0.45008004 0.76264131 0.65505272]
 [0.73348133 0.6124679  0.59040961 0.42216525 0.51333304 0.34874814
  0.56737205 0.54218455 0.77411631 0.42221782 0.33021104 0.40288896
  0.49210271 0.58573064 0.52448253 0.60581144 0.44332884 0.77861427
  0.76708321 0.56703483 0.77483824]
 [0.32079724 0.32504633 0.35106063 0.25166301 0.32248913 0.22111453
  0.39630733 0.39785974 0.49640229 0.29485085 0.31562819 0.3116072
  0.31849623 0.27667432 0.24728035 0.46957045 0.32616343 0.69753522
  0.40460055 0.37044811 0.74933483]
 [0.21794795 0.21675467 0.23038257 0.19012714 0.25328373 0.25171329
  0.24884575 0.20430412 0.36339945 0.17876049 0.26315928 0.21073639
  0.24816891 0.26581471 0.24376141 0.31792278 0.26240398 0.2317753
  0.25763185 0.26816418 0.40489646]
 [0.22666131 0.25563157 0.15863305 0.15830248 0.1879878  0.24496252
  0.23009836 0.24312459 0.28575407 0.23810847 0.20496253 0.22889715
  0.21173632 0.23805297 0.30316506 0.30389152 0.20260252 0.21479442
  0.23893002 0.35812675 0.4591798 ]]
[array([[-4.18259279e-002, -1.53315125e-001, -1.12247257e-004,
         2.00286360e-001,  5.31867076e-212,  4.22474388e-001,
        -1.03510311e-195,  6.62527498e-001],
       [-7.88045724e-119,  2.17174392e-058, -3.50516693e-079,
        -2.79594509e-030,  2.99101000e-216, -8.92302141e-020,
        -5.40646995e-181,  8.26571072e-012],
       [ 1.98181033e-002,  3.70444904e-001,  2.21921795e-003,
         2.70322587e-001, -3.35998112e-191, -2.39517678e-001,
         2.01961556e-213, -3.28516670e-001],
       [-1.09656797e-001, -3.52214153e-001, -4.64389904e-002,
         5.08178920e-003, -1.16929246e-218,  1.32820369e-001,
         4.89547145e-217,  5.13937332e-001],
       [ 1.50036547e-001, -6.03156015e-002,  2.96709834e-003,
         1.18970515e-001,  2.18443340e-210,  6.16525357e-001,
        -2.14468635e-207,  3.58505671e-001],
       [-3.98444362e-002, -5.06085568e-001, -5.48892239e-002,
         1.18690038e-001,  5.16185428e-214, -6.81459854e-002,
        -2.35165273e-204,  2.02905606e-001],
       [ 3.80918794e-002,  2.44040383e-001, -9.18320876e-003,
         4.26204388e-001, -9.03800236e-218, -2.99455582e-001,
         3.58446774e-176, -1.21069847e-001],
       [ 1.52569765e-001, -1.18902434e-001, -6.61810507e-003,
         4.50474799e-001, -7.24766715e-216,  1.25953549e-001,
         2.81076098e-214,  6.81483831e-001]]), array([[ 1.03634400e-001,  5.02091372e-002,  8.05511285e-003,
         1.74407910e-002, -1.41597001e-001,  2.82427873e-043,
         1.50313138e-006,  8.57334260e-002],
       [-1.34382703e-001,  6.35635001e-003,  3.25355125e-005,
         6.33225923e-002,  7.49011209e-001, -1.05986499e-040,
        -3.90612297e-003, -1.53691972e-001],
       [ 8.60514956e-003,  6.39145223e-003,  4.11975012e-003,
         4.95969878e-003,  4.03301536e-002,  6.36716505e-041,
        -1.94387467e-004,  1.40636960e-002],
       [ 2.24277379e-001,  1.03842377e-001, -4.17405777e-001,
        -1.03174195e-001,  5.57854116e-001, -2.54329333e-010,
        -4.35855304e-002,  5.25578774e-001],
       [-1.55507076e-214,  7.75329829e-192, -4.45377664e-194,
         8.69226756e-206, -1.27695595e-218, -1.23758858e-184,
        -8.91086103e-219,  1.60202360e-214],
       [ 5.33688824e-001,  2.28801104e-001,  4.68518627e-002,
         8.45499468e-002,  3.01347873e-002,  5.29048844e-034,
        -6.80624223e-003,  4.91153255e-001],
       [ 9.44166540e-201, -7.77468132e-205,  1.43604227e-218,
        -1.82715463e-203, -2.82610650e-189,  5.98673438e-207,
        -9.79950233e-218, -3.22061030e-210],
       [ 1.87618842e-001,  7.77570328e-002,  2.79699979e-001,
         2.39395180e-001, -5.78599083e-001, -3.59023331e-019,
        -1.41809165e-002,  4.94083757e-001]]), array([[-3.20812215e-001, -4.36139641e-188, -4.70961715e-001,
         9.16589406e-197, -9.25461497e-003,  1.50655800e-001,
         3.07211996e-001,  2.59186262e-001],
       [ 3.64332830e-002,  1.54418472e-216, -9.65884555e-002,
         3.67545092e-207,  5.45389510e-003,  1.10665693e-001,
         7.62745498e-002,  1.92307000e-001],
       [-1.48163886e-003, -2.48308382e-184,  2.49937106e-002,
         4.60521120e-219, -1.90171094e-008,  3.62079232e-002,
         7.40305665e-002,  2.06624958e-001],
       [-1.03106463e-001, -4.51695557e-212,  5.01832628e-001,
         7.39066962e-205,  6.91128518e-002, -4.57105307e-002,
        -1.00209207e-001,  4.38631383e-001],
       [ 5.18048874e-001,  3.54244511e-218,  4.81523249e-001,
        -4.53791003e-218,  3.07129212e-001, -1.60834469e-001,
         1.15735483e-001, -4.31730266e-001],
       [-1.59153883e-039, -4.39946531e-187, -4.27598406e-039,
        -5.67426907e-205,  3.88482766e-042, -8.98645590e-040,
         6.13342135e-040,  7.41111731e-037],
       [ 5.42199766e-003, -1.00520869e-214,  1.42764343e-003,
        -1.04050423e-216,  7.62727127e-005, -1.12276670e-003,
         2.51187502e-003, -6.80316548e-003],
       [-3.53757714e-001,  1.98693930e-216,  4.59235642e-002,
        -2.76579155e-211, -4.09799835e-003,  2.33809910e-001,
         2.64411686e-001,  6.36488385e-001]]), array([[ 2.00261300e-001,  1.42834942e-001, -9.53614231e-003,
         3.63258439e-001,  2.94548636e-001,  1.09808943e-001,
         3.90058024e-001, -3.40863172e-002],
       [ 1.86463860e-217,  1.23353834e-218,  4.86425993e-212,
         2.97809765e-193,  2.34029495e-199, -4.50869736e-209,
         4.77909883e-211, -3.91357319e-206],
       [ 1.96984275e-001, -2.07971542e-001,  1.93607127e-001,
         3.00828957e-001,  3.44326014e-001, -9.08598004e-002,
         1.42781277e-002, -4.53110945e-001],
       [ 3.14619337e-190, -1.72310844e-217,  1.39351232e-205,
        -1.40066944e-198, -6.97341510e-198, -1.15167669e-211,
        -4.10139451e-218,  2.05193892e-218],
       [ 4.22025986e-002, -5.90707274e-002,  4.93951931e-002,
         9.56688037e-002,  6.31551161e-002,  2.40507465e-003,
         1.13555727e-001, -7.22161258e-003],
       [ 1.54428787e-001,  1.32146532e-001, -2.24853540e-001,
        -1.52686261e-001, -1.51595965e-001, -2.89003296e-002,
         2.62167728e-001,  2.47886011e-001],
       [-1.79211734e-001,  3.06192704e-001,  9.73940987e-002,
        -7.67754849e-002, -5.00140475e-002, -6.19424547e-002,
         5.14591642e-001,  2.10150972e-001],
       [ 8.87697402e-002,  3.28535856e-001, -4.27182320e-001,
        -5.20485461e-002, -5.17174376e-001, -7.03656774e-002,
        -5.06145364e-001,  4.99325257e-001]]), array([[-3.03257552e-003,  3.91953982e-002,  1.33454207e-217,
         2.05352147e-001, -2.81530303e-003,  3.32414747e-122,
        -3.09051449e-213,  3.66265733e-001],
       [ 3.82314042e-002, -3.84622648e-001,  1.58935829e-191,
         2.90919258e-001, -3.01954815e-002,  4.77001223e-086,
        -7.62791262e-208, -1.76070624e-001],
       [ 9.97454619e-002,  7.73443404e-002, -2.71842047e-196,
         2.72236296e-001, -1.68257374e-003, -1.17057698e-088,
        -5.79528732e-219,  4.19749248e-001],
       [-5.50946794e-003,  3.93409792e-001, -6.12273901e-219,
        -2.05853161e-001, -4.68643052e-003, -1.75836435e-128,
        -3.83347868e-213,  4.69437465e-001],
       [-2.23404613e-002,  5.10350467e-001,  2.91114624e-218,
        -1.54158997e-002, -1.71170158e-002,  6.26620110e-130,
        -3.83403620e-215,  1.02622491e-001],
       [-3.28174816e-008,  3.80729533e-002,  6.79664539e-219,
         2.88249042e-002, -2.03711124e-005,  9.11928024e-187,
         1.39849448e-185,  4.90099824e-002],
       [-5.30532489e-002,  4.49740707e-001, -2.10214722e-206,
        -8.78405016e-002,  8.48462081e-004,  7.57685572e-159,
         1.72788791e-200,  5.53763292e-001],
       [-3.69691585e-004,  1.78290935e-001,  4.51935386e-220,
         7.11937268e-001, -3.98291029e-004, -1.43197792e-203,
        -1.52828093e-202, -1.72707742e-001]]), array([[-2.20266863e-005, -3.96964604e-006, -2.75510224e-005,
        -3.88189377e-005,  2.10136718e-008, -2.21632841e-005,
         2.36990582e-010,  9.70593563e-006],
       [-2.52407629e-001, -1.99219531e-001, -1.03893000e-001,
        -8.37268120e-002,  1.39558397e-001, -3.25564274e-001,
        -1.60875847e-001,  2.40371923e-001],
       [ 9.41928489e-217, -3.90769122e-210, -1.47711822e-188,
        -9.38090404e-023,  1.24727090e-218, -1.51865592e-213,
         3.33786301e-218, -1.15096999e-209],
       [ 5.32122899e-001,  3.21508148e-001,  4.49731490e-001,
         5.22440482e-001, -2.07344152e-001,  5.11723462e-001,
         9.56848018e-002,  2.46227046e-001],
       [-9.50616985e-006,  1.21908178e-209,  4.15018400e-005,
        -4.73807697e-027, -3.18904570e-005,  1.77682287e-005,
        -2.34796658e-004, -6.87978411e-005],
       [-2.39316068e-192,  4.77083128e-209,  2.84144836e-183,
        -2.02121576e-201,  3.70174130e-181, -4.84970815e-210,
        -9.18662371e-217,  3.57256714e-187],
       [ 4.22670734e-214, -6.78493545e-216, -2.84244613e-205,
        -3.35779684e-215, -1.35712169e-215,  1.62650397e-215,
         4.44530783e-217,  1.32425677e-215],
       [-2.45237319e-001, -4.63083630e-001, -4.13862086e-001,
        -5.32403711e-001,  1.04996887e-001, -1.44366966e-001,
        -8.24385828e-002,  2.79771215e-001]]), array([[ 6.23523014e-002,  3.21765745e-002, -6.82905397e-002,
        -1.35477144e-001, -2.43112654e-001, -1.49280685e-001,
         4.00037845e-001, -6.50502491e-205],
       [ 2.67742816e-001,  4.22511096e-002, -1.86003038e-002,
        -1.81843514e-002, -1.31560034e-001, -9.81601615e-002,
         4.14735210e-001, -4.21467260e-218],
       [ 3.56696255e-001,  1.15081162e-001, -2.36410355e-002,
         5.53089720e-003,  2.23851310e-001,  2.32595341e-002,
         4.41945608e-001,  1.17284251e-217],
       [ 3.64143947e-001,  5.18018702e-002, -2.26967962e-002,
         6.81330568e-004, -1.06695458e-001, -9.82301172e-002,
         5.44740722e-001,  6.00278960e-204],
       [-1.27077935e-001, -4.99845691e-002, -4.52647287e-002,
        -3.54929781e-002,  2.79688087e-001,  2.46628351e-001,
         3.41587563e-001, -2.32651579e-207],
       [ 3.08417078e-001,  3.34391572e-002, -7.41504263e-002,
        -7.80575564e-002,  1.08940213e-001, -2.05270712e-001,
         4.08961141e-001, -3.92988406e-218],
       [ 1.49460979e-001,  6.02040473e-003, -2.77431247e-002,
         3.55371167e-002, -1.06783893e-001,  6.29866497e-002,
         1.49742787e-001, -2.97870574e-183],
       [-5.29041803e-002, -3.79615225e-003,  4.72137287e-003,
         2.33857732e-001,  3.72252379e-001,  2.88255631e-001,
        -4.44302078e-001, -1.64098365e-211]]), array([[ 4.03771646e-001],
       [ 8.68671587e-002],
       [-3.34909429e-002],
       [-1.17974383e-001],
       [-4.11904475e-001],
       [-4.29418937e-001],
       [ 7.43600625e-001],
       [-1.32755350e-182]])]
[-0.16716212 -0.07502863 -0.0590133   0.14352702 -0.29375978  0.22777445
  0.05550345 -0.27912648]
TRAIN
Mean PCC: 0.4793733439467809 +- 0.44182241477453565
PCC: Min: -0.0814240561883383 Max: 0.87281918925352
Mean MSE: 0.7768130289524824 +- 0.43679707812657775
MSE: Min: 0.31543713445954685 Max: 1.3981897454960581
MSE:
ArgMin: [('4hlb', 95), ('6c4q', 85), ('4rgi', 71), ('5aiz', 110), ('5w0h', 80), ('2rff', 111), ('2yvi', 89), ('2huj', 125), ('3bv8', 85), ('3o2e', 86)]
ArgMax: [('4aqo', 86), ('1j0p', 108), ('3dt5', 119), ('5dbl', 130), ('1jni', 62), ('2pne', 81), ('1lmi', 131), ('2w9y', 136), ('5v0m', 98), ('1sau', 114)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('2nwf', 141), ('4aqo', 86), ('2h5c', 198), ('1jni', 62), ('3tch', 517), ('4rlc', 135), ('2w9y', 136), ('1j0p', 108)]
ArgMax: [('4hlb', 95), ('3bv8', 85), ('5w0h', 80), ('2huj', 125), ('6c4q', 85), ('4rgi', 71), ('5zt3', 114), ('1xmt', 95), ('2hcm', 159), ('5aiz', 110)]
MSE vs Length correlation: 0.047625202104628055
PCC vs Length correlation: 0.07366490537729442
MSE vs b-val mean correlation: 1.217991017488096e-06
PCC vs b-val mean correlation: 1.4859028052427448e-07
VAL
Mean PCC: 0.48239610035623337 +- 0.4303875430577022
PCC: Min: -0.020724232824156627 Max: 0.8845172494739448
Mean MSE: 0.7733940648299104 +- 0.4178226756091782
MSE: Min: 0.2690680041096145 Max: 1.4031816398544412
MSE:
ArgMin: [('2vc8', 72), ('4i6x', 117), ('2i5u', 77), ('3mao', 105), ('4gos', 115), ('5ijm', 98), ('5hqh', 96), ('2b1k', 149), ('3tbn', 87), ('4zc3', 57)]
ArgMax: [('2rkn', 77), ('2rbk', 261), ('3fgh', 67), ('1u5p', 211), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('3cao', 102), ('4e1b', 330), ('3lpz', 314)]
PCC:
ArgMin: [('2rkn', 77), ('2rbk', 261), ('3gvo', 342), ('1u5p', 211), ('3sw0', 186), ('2v9k', 467), ('4e1b', 330), ('4rep', 489), ('5hfg', 205), ('3lpz', 314)]
ArgMax: [('2vc8', 72), ('4i6x', 117), ('3mao', 105), ('5hqh', 96), ('2i5u', 77), ('4gos', 115), ('3tbn', 87), ('5ijm', 98), ('2b1k', 149), ('4zc3', 57)]
MSE vs Length correlation: 0.06179691350537231
PCC vs Length correlation: 0.08908159636502123
MSE vs b-val mean correlation: 0.0019768874817960302
PCC vs b-val mean correlation: 0.0013353329286367455
TEST
Mean PCC: 0.4730463487303203 +- 0.4446400685340941
PCC: Min: -0.0994000068155756 Max: 0.8614731417513851
Mean MSE: 0.7824722901949608 +- 0.4399120068648857
MSE: Min: 0.35236653973804016 Max: 1.5258987828769268
MSE:
ArgMin: [('3cp0', 63), ('4qq6', 58), ('2od5', 91), ('3o70', 55), ('5ol9', 81), ('3t7l', 74), ('5kuj', 95), ('3chm', 161), ('1dqg', 134), ('2ovg', 58)]
ArgMax: [('4npn', 71), ('5i8g', 226), ('3b6e', 182), ('4gs3', 90), ('2vac', 134), ('4xxt', 221), ('2o1a', 122), ('3zr8', 65), ('4qdn', 118), ('5fie', 142)]
PCC:
ArgMin: [('4npn', 71), ('5i8g', 226), ('4xxt', 221), ('1r5y', 361), ('2vac', 134), ('4r1b', 282), ('3b6e', 182), ('4qdn', 118), ('4gs3', 90), ('3ip0', 158)]
ArgMax: [('3cp0', 63), ('4qq6', 58), ('2od5', 91), ('4rwu', 81), ('1mud', 225), ('5ol9', 81), ('3chm', 161), ('3t7l', 74), ('1dqg', 134), ('3o70', 55)]
MSE vs Length correlation: 0.04156901724369911
PCC vs Length correlation: 0.05809233994772289
MSE vs b-val mean correlation: 3.285878847569812e-06
PCC vs b-val mean correlation: 1.1270198997381797e-06
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.46162739
Validation score: 0.182983
Iteration 2, loss = 0.41248041
Validation score: 0.193230
Iteration 3, loss = 0.40923301
Validation score: 0.195022
Iteration 4, loss = 0.40763850
Validation score: 0.195864
Iteration 5, loss = 0.40651924
Validation score: 0.196703
Iteration 6, loss = 0.40572621
Validation score: 0.197913
Iteration 7, loss = 0.40512138
Validation score: 0.197449
Iteration 8, loss = 0.40446858
Validation score: 0.197792
Iteration 9, loss = 0.40394685
Validation score: 0.195704
Iteration 10, loss = 0.40360821
Validation score: 0.196562
Iteration 11, loss = 0.40329683
Validation score: 0.197243
Iteration 12, loss = 0.40285845
Validation score: 0.193606
Iteration 13, loss = 0.40272893
Validation score: 0.195990
Iteration 14, loss = 0.40230963
Validation score: 0.195164
Iteration 15, loss = 0.40206400
Validation score: 0.194742
Iteration 16, loss = 0.40187834
Validation score: 0.193757
Iteration 17, loss = 0.40161647
Validation score: 0.193978
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.8022695466608224, total= 1.2min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.46731978
Validation score: 0.189561
Iteration 2, loss = 0.40905721
Validation score: 0.195604
Iteration 3, loss = 0.40704371
Validation score: 0.190398
Iteration 4, loss = 0.40666335
Validation score: 0.190761
Iteration 5, loss = 0.40615429
Validation score: 0.196210
Iteration 6, loss = 0.40588224
Validation score: 0.194711
Iteration 7, loss = 0.40557580
Validation score: 0.194099
Iteration 8, loss = 0.40517308
Validation score: 0.195422
Iteration 9, loss = 0.40536996
Validation score: 0.194107
Iteration 10, loss = 0.40484698
Validation score: 0.194411
Iteration 11, loss = 0.40484134
Validation score: 0.194519
Iteration 12, loss = 0.40481041
Validation score: 0.194471
Iteration 13, loss = 0.40473712
Validation score: 0.191493
Iteration 14, loss = 0.40431690
Validation score: 0.193816
Iteration 15, loss = 0.40421768
Validation score: 0.193501
Iteration 16, loss = 0.40427011
Validation score: 0.184329
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8003722177354077, total= 1.1min
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.47188967
Validation score: 0.177995
Iteration 2, loss = 0.41029620
Validation score: 0.184800
Iteration 3, loss = 0.40784890
Validation score: 0.188691
Iteration 4, loss = 0.40638194
Validation score: 0.189283
Iteration 5, loss = 0.40544914
Validation score: 0.190282
Iteration 6, loss = 0.40461929
Validation score: 0.187077
Iteration 7, loss = 0.40425703
Validation score: 0.190467
Iteration 8, loss = 0.40369794
Validation score: 0.190328
Iteration 9, loss = 0.40350446
Validation score: 0.187725
Iteration 10, loss = 0.40303147
Validation score: 0.189431
Iteration 11, loss = 0.40297373
Validation score: 0.188556
Iteration 12, loss = 0.40239100
Validation score: 0.183719
Iteration 13, loss = 0.40242178
Validation score: 0.190361
Iteration 14, loss = 0.40216435
Validation score: 0.188756
Iteration 15, loss = 0.40205017
Validation score: 0.186915
Iteration 16, loss = 0.40167513
Validation score: 0.190216
Iteration 17, loss = 0.40158925
Validation score: 0.189782
Iteration 18, loss = 0.40145002
Validation score: 0.188750
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8008964347040459, total= 1.2min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.41938102
Validation score: 0.191745
Iteration 2, loss = 0.40946570
Validation score: 0.191099
Iteration 3, loss = 0.40883846
Validation score: 0.199173
Iteration 4, loss = 0.40853909
Validation score: 0.195694
Iteration 5, loss = 0.40820586
Validation score: 0.196688
Iteration 6, loss = 0.40810001
Validation score: 0.189126
Iteration 7, loss = 0.40786978
Validation score: 0.189651
Iteration 8, loss = 0.40791134
Validation score: 0.198808
Iteration 9, loss = 0.40773803
Validation score: 0.195306
Iteration 10, loss = 0.40769692
Validation score: 0.190899
Iteration 11, loss = 0.40757299
Validation score: 0.196089
Iteration 12, loss = 0.40768999
Validation score: 0.198249
Iteration 13, loss = 0.40772404
Validation score: 0.195070
Iteration 14, loss = 0.40790278
Validation score: 0.198151
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.8035501737448909, total=  57.7s
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.50143021
Validation score: -0.000223
Iteration 2, loss = 0.50095796
Validation score: -0.000041
Iteration 3, loss = 0.50103851
Validation score: -0.000047
Iteration 4, loss = 0.50101665
Validation score: -0.000029
Iteration 5, loss = 0.50104367
Validation score: -0.000001
Iteration 6, loss = 0.50098309
Validation score: -0.000829
Iteration 7, loss = 0.50099105
Validation score: -0.000146
Iteration 8, loss = 0.50096197
Validation score: -0.000154
Iteration 9, loss = 0.50096794
Validation score: -0.000005
Iteration 10, loss = 0.50096845
Validation score: -0.000031
Iteration 11, loss = 0.50097540
Validation score: -0.000008
Iteration 12, loss = 0.50091440
Validation score: -0.000008
Iteration 13, loss = 0.50093505
Validation score: -0.000001
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.9913527798437142, total=  44.4s
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.47957760
Validation score: 0.137545
Iteration 2, loss = 0.42032109
Validation score: 0.165739
Iteration 3, loss = 0.41123702
Validation score: 0.171229
Iteration 4, loss = 0.40869498
Validation score: 0.172952
Iteration 5, loss = 0.40759228
Validation score: 0.174328
Iteration 6, loss = 0.40680172
Validation score: 0.174516
Iteration 7, loss = 0.40610344
Validation score: 0.173918
Iteration 8, loss = 0.40537608
Validation score: 0.175775
Iteration 9, loss = 0.40480008
Validation score: 0.176909
Iteration 10, loss = 0.40414709
Validation score: 0.177141
Iteration 11, loss = 0.40358901
Validation score: 0.177490
Iteration 12, loss = 0.40303781
Validation score: 0.178882
Iteration 13, loss = 0.40261557
Validation score: 0.180153
Iteration 14, loss = 0.40214956
Validation score: 0.178050
Iteration 15, loss = 0.40175022
Validation score: 0.180193
Iteration 16, loss = 0.40142035
Validation score: 0.181108
Iteration 17, loss = 0.40122885
Validation score: 0.181372
Iteration 18, loss = 0.40086883
Validation score: 0.180424
Iteration 19, loss = 0.40073140
Validation score: 0.181305
Iteration 20, loss = 0.40055085
Validation score: 0.180461
Iteration 21, loss = 0.40021190
Validation score: 0.181437
Iteration 22, loss = 0.40021815
Validation score: 0.180902
Iteration 23, loss = 0.39993595
Validation score: 0.181440
Iteration 24, loss = 0.39986287
Validation score: 0.181113
Iteration 25, loss = 0.39982960
Validation score: 0.180287
Iteration 26, loss = 0.39959687
Validation score: 0.181725
Iteration 27, loss = 0.39949209
Validation score: 0.180195
Iteration 28, loss = 0.39950406
Validation score: 0.181702
Iteration 29, loss = 0.39924089
Validation score: 0.181960
Iteration 30, loss = 0.39927689
Validation score: 0.181189
Iteration 31, loss = 0.39906519
Validation score: 0.181759
Iteration 32, loss = 0.39902525
Validation score: 0.181192
Iteration 33, loss = 0.39901344
Validation score: 0.180404
Iteration 34, loss = 0.39886783
Validation score: 0.181729
Iteration 35, loss = 0.39886809
Validation score: 0.180223
Iteration 36, loss = 0.39876070
Validation score: 0.181957
Iteration 37, loss = 0.39867701
Validation score: 0.181914
Iteration 38, loss = 0.39861589
Validation score: 0.181984
Iteration 39, loss = 0.39849225
Validation score: 0.181075
Iteration 40, loss = 0.39849515
Validation score: 0.179710
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.800667087681023, total= 3.2min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.49485267
Validation score: 0.073540
Iteration 2, loss = 0.45026079
Validation score: 0.125626
Iteration 3, loss = 0.43357363
Validation score: 0.144711
Iteration 4, loss = 0.42545483
Validation score: 0.156390
Iteration 5, loss = 0.41976556
Validation score: 0.165563
Iteration 6, loss = 0.41564352
Validation score: 0.171792
Iteration 7, loss = 0.41269082
Validation score: 0.175410
Iteration 8, loss = 0.41080277
Validation score: 0.178797
Iteration 9, loss = 0.40955325
Validation score: 0.179970
Iteration 10, loss = 0.40877938
Validation score: 0.180836
Iteration 11, loss = 0.40826214
Validation score: 0.181081
Iteration 12, loss = 0.40782955
Validation score: 0.181266
Iteration 13, loss = 0.40754200
Validation score: 0.181852
Iteration 14, loss = 0.40723461
Validation score: 0.182113
Iteration 15, loss = 0.40697558
Validation score: 0.181954
Iteration 16, loss = 0.40674546
Validation score: 0.182618
Iteration 17, loss = 0.40655332
Validation score: 0.182714
Iteration 18, loss = 0.40635828
Validation score: 0.183074
Iteration 19, loss = 0.40610043
Validation score: 0.183204
Iteration 20, loss = 0.40587706
Validation score: 0.183431
Iteration 21, loss = 0.40572606
Validation score: 0.183027
Iteration 22, loss = 0.40547694
Validation score: 0.183728
Iteration 23, loss = 0.40526913
Validation score: 0.183621
Iteration 24, loss = 0.40504047
Validation score: 0.183891
Iteration 25, loss = 0.40477667
Validation score: 0.183994
Iteration 26, loss = 0.40456357
Validation score: 0.184076
Iteration 27, loss = 0.40437687
Validation score: 0.183767
Iteration 28, loss = 0.40413204
Validation score: 0.184706
Iteration 29, loss = 0.40393470
Validation score: 0.184197
Iteration 30, loss = 0.40366649
Validation score: 0.185090
Iteration 31, loss = 0.40351513
Validation score: 0.184674
Iteration 32, loss = 0.40330387
Validation score: 0.184915
Iteration 33, loss = 0.40311294
Validation score: 0.185352
Iteration 34, loss = 0.40289840
Validation score: 0.185441
Iteration 35, loss = 0.40273413
Validation score: 0.185565
Iteration 36, loss = 0.40254117
Validation score: 0.185890
Iteration 37, loss = 0.40234840
Validation score: 0.185688
Iteration 38, loss = 0.40223055
Validation score: 0.185548
Iteration 39, loss = 0.40202480
Validation score: 0.185525
Iteration 40, loss = 0.40188370
Validation score: 0.185403
Iteration 41, loss = 0.40172980
Validation score: 0.186010
Iteration 42, loss = 0.40161152
Validation score: 0.185334
Iteration 43, loss = 0.40148275
Validation score: 0.186205
Iteration 44, loss = 0.40134573
Validation score: 0.185828
Iteration 45, loss = 0.40119691
Validation score: 0.185852
Iteration 46, loss = 0.40105728
Validation score: 0.185094
Iteration 47, loss = 0.40094076
Validation score: 0.185566
Iteration 48, loss = 0.40080935
Validation score: 0.185616
Iteration 49, loss = 0.40066981
Validation score: 0.185013
Iteration 50, loss = 0.40063285
Validation score: 0.185051
Iteration 51, loss = 0.40044380
Validation score: 0.186407
Iteration 52, loss = 0.40033717
Validation score: 0.185606
Iteration 53, loss = 0.40024252
Validation score: 0.184994
Iteration 54, loss = 0.40014837
Validation score: 0.186016
Iteration 55, loss = 0.40008234
Validation score: 0.185924
Iteration 56, loss = 0.39996438
Validation score: 0.185813
Iteration 57, loss = 0.39989590
Validation score: 0.185930
Iteration 58, loss = 0.39981166
Validation score: 0.186026
Iteration 59, loss = 0.39967736
Validation score: 0.185302
Iteration 60, loss = 0.39959180
Validation score: 0.185675
Iteration 61, loss = 0.39950444
Validation score: 0.185300
Iteration 62, loss = 0.39946209
Validation score: 0.185598
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.8042368124384275, total= 4.6min
10
Input read.
(540304, 21)
(540304, 441)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.48993965
Validation score: 0.124966
Iteration 2, loss = 0.42253407
Validation score: 0.173344
Iteration 3, loss = 0.41172723
Validation score: 0.182075
Iteration 4, loss = 0.40890423
Validation score: 0.185472
Iteration 5, loss = 0.40754420
Validation score: 0.187287
Iteration 6, loss = 0.40666365
Validation score: 0.188451
Iteration 7, loss = 0.40598525
Validation score: 0.189274
Iteration 8, loss = 0.40535907
Validation score: 0.189746
Iteration 9, loss = 0.40480229
Validation score: 0.191177
Iteration 10, loss = 0.40433688
Validation score: 0.190412
Iteration 11, loss = 0.40390507
Validation score: 0.192044
Iteration 12, loss = 0.40354243
Validation score: 0.192755
Iteration 13, loss = 0.40317733
Validation score: 0.193148
Iteration 14, loss = 0.40285578
Validation score: 0.193090
Iteration 15, loss = 0.40256298
Validation score: 0.193336
Iteration 16, loss = 0.40234636
Validation score: 0.192838
Iteration 17, loss = 0.40213821
Validation score: 0.193877
Iteration 18, loss = 0.40193825
Validation score: 0.193000
Iteration 19, loss = 0.40177551
Validation score: 0.194385
Iteration 20, loss = 0.40163573
Validation score: 0.194469
Iteration 21, loss = 0.40150549
Validation score: 0.194337
Iteration 22, loss = 0.40130955
Validation score: 0.194112
Iteration 23, loss = 0.40120861
Validation score: 0.194521
Iteration 24, loss = 0.40110449
Validation score: 0.194437
Iteration 25, loss = 0.40101167
Validation score: 0.194535
Iteration 26, loss = 0.40087304
Validation score: 0.194594
Iteration 27, loss = 0.40079464
Validation score: 0.194312
Iteration 28, loss = 0.40069765
Validation score: 0.194565
Iteration 29, loss = 0.40059375
Validation score: 0.194735
Iteration 30, loss = 0.40053888
Validation score: 0.194963
Iteration 31, loss = 0.40044044
Validation score: 0.194635
Iteration 32, loss = 0.40031463
Validation score: 0.194302
Iteration 33, loss = 0.40029414
Validation score: 0.194671
Iteration 34, loss = 0.40019558
Validation score: 0.194085
Iteration 35, loss = 0.40016858
Validation score: 0.194514
Iteration 36, loss = 0.40005947
Validation score: 0.194579
Iteration 37, loss = 0.39997481
Validation score: 0.193797
Iteration 38, loss = 0.39992623
Validation score: 0.194499
Iteration 39, loss = 0.39983131
Validation score: 0.194229
Iteration 40, loss = 0.39974497
Validation score: 0.193563
Iteration 41, loss = 0.39971932
Validation score: 0.194245
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.000125
0.2043751313199289
[[0.18028561 0.18800991 0.26664039 0.25800931 0.18862827 0.18714879
  0.20717136 0.19698945 0.2121143  0.22761141 0.19868686 0.23129462
  0.18135252 0.23270829 0.23799401 0.22029669 0.24474334 0.16411119
  0.30750512 0.20441973 0.25562612]
 [0.17668224 0.16805933 0.21625141 0.17881774 0.20221742 0.19540209
  0.22811231 0.19678378 0.16463019 0.25046841 0.24244256 0.212436
  0.2348176  0.35547769 0.20860817 0.17392778 0.29872047 0.21116431
  0.27629892 0.19975642 0.27120695]
 [0.2396323  0.29224646 0.27134134 0.22201745 0.20289852 0.18210197
  0.28111568 0.13943754 0.1930249  0.22742701 0.21722441 0.30104991
  0.2036403  0.23658437 0.34384846 0.27115688 0.36303328 0.17468315
  0.23500455 0.26346187 0.29346492]
 [0.24201499 0.29434455 0.27452816 0.30021906 0.32397269 0.22489845
  0.2407664  0.26361647 0.31679628 0.26978609 0.22750843 0.23778869
  0.29738029 0.49160605 0.35616419 0.39870897 0.83125204 0.33307725
  0.66973102 0.33518063 0.57632338]
 [0.25932437 0.34834393 0.23640248 0.3080285  0.33998563 0.33361105
  0.29843967 0.2926465  0.22561221 0.36515473 0.26157889 0.22569388
  0.24924146 0.38072426 0.30414583 0.31262918 0.77852726 0.30936975
  0.43159181 0.27889423 0.38271666]
 [0.2466723  0.20973296 0.27403016 0.22827692 0.24606957 0.21061603
  0.20142199 0.21144427 0.2168456  0.19260998 0.21409061 0.25566026
  0.21282588 0.31616652 0.2950179  0.2938259  0.58802784 0.19557055
  0.22220962 0.23697665 0.29082951]
 [0.19137342 0.24814914 0.23100727 0.16169393 0.28936597 0.21093806
  0.22889381 0.1728748  0.18584247 0.17016939 0.20147104 0.2534439
  0.190313   0.24347653 0.33229545 0.20330658 0.37837328 0.23610455
  0.26831477 0.20244699 0.22889209]
 [0.17937639 0.21832273 0.23659994 0.20717887 0.17512024 0.19972128
  0.23083849 0.22157574 0.22157601 0.24646023 0.27268004 0.22219537
  0.17006535 0.17722338 0.29723427 0.21473496 0.29644084 0.20174371
  0.25913345 0.24622718 0.26022379]]
[array([[-2.77660086e-316, -4.37835421e-001,  2.10093466e-002,
         5.04392950e-001, -3.65336873e-001, -2.61066555e-001,
        -3.39392685e-001,  5.43956214e-001],
       [-5.70195678e-317, -1.97887698e-002,  1.32660264e-001,
         9.87327243e-002, -5.11060368e-001, -2.84800502e-001,
         8.64302042e-002,  5.54999809e-001],
       [-8.09371474e-317,  5.06377569e-001,  2.00528292e-001,
        -2.17663136e-001,  3.16865755e-002,  8.49897293e-002,
         1.87660376e-001, -3.72992482e-001],
       [-8.89404377e-317, -2.51629908e-001,  6.07983069e-001,
        -3.99012781e-001, -3.62862652e-001, -8.53011489e-002,
        -3.85431463e-001, -4.32556808e-002],
       [ 2.89255416e-316,  2.58209328e-001,  1.75524879e-001,
        -3.61082897e-002,  4.64797946e-001, -2.55680936e-001,
         3.85432868e-001,  1.47421511e-001],
       [-3.04965108e-316, -3.53165389e-001, -9.87469032e-002,
        -4.22769234e-001,  8.11332046e-002,  1.27075970e-001,
         7.71486184e-002,  3.39305111e-001],
       [ 8.67445333e-317,  3.03620376e-001, -1.70071363e-001,
         1.64064290e-001,  4.75271577e-001,  4.89286456e-001,
         2.13384370e-001,  3.12439334e-001],
       [ 4.33783017e-317, -2.04516422e-001, -1.42057245e-003,
        -1.85538870e-001, -2.50152073e-001,  3.47283666e-002,
         1.03778969e-002,  4.79865964e-001]]), array([[ 5.59059339e-317,  7.54202226e-317,  3.94567890e-317,
         3.15476690e-316,  6.32969929e-317, -9.61384109e-317,
        -2.32496759e-316, -3.04890380e-318],
       [-2.52437988e-001,  2.11047237e-001,  3.41337108e-001,
        -7.35944607e-002, -2.60655456e-001,  2.84042374e-001,
         1.23942044e-316,  3.14190606e-001],
       [ 1.07162333e-001, -7.04988200e-002, -2.96829886e-001,
         2.39209561e-001,  1.88238511e-001, -3.13725225e-002,
        -6.58252850e-317,  5.72488440e-002],
       [-1.12402669e-001,  1.66785409e-001,  5.48860272e-001,
         6.90974197e-002,  2.46603744e-001,  2.50538326e-001,
         2.15328517e-316, -1.11480267e-002],
       [ 6.26919935e-002,  1.65999905e-001,  3.09261663e-001,
        -6.53903886e-002, -3.65740871e-001,  3.31479267e-001,
         2.01327003e-316, -1.45849900e-001],
       [-1.87582007e-001, -2.93052947e-002,  1.85243589e-001,
        -7.09553547e-002, -6.52185282e-003,  1.39870139e-001,
        -3.61678207e-316,  2.53066379e-003],
       [-1.41273775e-002,  3.35641912e-001,  4.38495766e-001,
         3.63988969e-002, -3.49597651e-001,  4.03264305e-001,
        -9.57456485e-317, -3.60530885e-002],
       [ 5.62859122e-001,  2.90357250e-001, -3.56388333e-002,
         2.29446860e-001, -1.26123598e-002, -2.07649869e-002,
         1.94367806e-316, -1.75565674e-002]]), array([[-7.73024819e-290,  4.95542473e-001, -3.50902346e-001,
        -4.39878333e-001, -5.42085072e-317,  1.77086793e-316,
        -2.82979527e-316,  4.95520371e-001],
       [ 7.29331703e-317,  5.53998658e-002,  3.19166766e-001,
         3.82562764e-003, -5.10789323e-317,  4.04915502e-317,
         1.73001532e-317,  3.02985443e-001],
       [ 1.46225679e-316,  6.58416964e-001,  5.63471843e-001,
         2.53687245e-001,  2.46931505e-316,  7.54010726e-317,
        -8.68771207e-317, -3.90450967e-001],
       [-1.30421498e-316, -2.44890459e-001,  2.65030520e-001,
        -9.95913005e-002,  2.42894000e-316,  1.94165412e-316,
        -3.06982314e-316,  5.37566682e-001],
       [-1.10485479e-317, -2.05209137e-002,  2.90050614e-001,
         3.55038800e-001, -1.75776403e-317,  8.24813742e-317,
         2.53014999e-316,  3.94540710e-001],
       [-2.96551165e-316,  2.13721114e-001, -1.43711281e-001,
         6.45781712e-001,  3.04757556e-316,  2.06195600e-316,
         1.70395395e-316,  8.40546549e-002],
       [ 3.63706129e-317,  1.68936405e-316, -1.73287147e-316,
         3.93807523e-317,  1.34966511e-316,  2.41604731e-316,
         2.51612164e-316,  2.57687630e-316],
       [ 6.78443336e-317, -6.34222309e-003, -1.90750687e-002,
        -1.13173591e-002, -2.74358383e-316, -2.03579107e-316,
        -3.29763868e-317,  7.41905749e-002]]), array([[-1.87002429e-316, -7.47462825e-317,  5.55494705e-317,
        -3.20810544e-316,  5.91195839e-317, -2.17191475e-316,
        -2.79186566e-316, -3.58970786e-316],
       [-2.60252270e-002,  1.72882643e-002, -4.53432551e-317,
        -8.17758287e-317, -3.04460267e-316,  3.04731173e-002,
         5.02538680e-001, -7.92236683e-002],
       [-3.57775796e-002, -2.00399604e-003, -1.44428852e-316,
        -1.55663969e-316, -5.36058953e-317, -2.83972947e-001,
         7.60520425e-002,  1.07049030e-001],
       [ 2.28086192e-002, -4.03217980e-002,  6.57719901e-317,
         1.25085228e-316,  6.88613282e-317, -1.88762047e-001,
         3.23756976e-001,  5.28810406e-001],
       [ 2.00893826e-316,  6.28869036e-317,  9.70195325e-317,
        -2.30002835e-316, -1.71001807e-316,  8.73171109e-317,
        -6.38646101e-317,  2.61617196e-316],
       [-2.73977286e-317, -1.90380904e-316, -1.76117881e-316,
         5.26444979e-317,  8.23457038e-317, -3.30767355e-316,
        -1.56218231e-316,  4.41673640e-317],
       [-1.58270768e-316,  4.71764461e-317, -4.80624244e-317,
        -2.30093016e-316, -1.97214553e-317, -3.78649836e-317,
         6.84105526e-318, -1.65380091e-316],
       [-4.87883210e-002,  4.27889094e-002, -3.49882923e-316,
         2.14094800e-317, -9.71368632e-317,  5.31444263e-001,
        -5.22065347e-001, -2.26023911e-001]]), array([[-2.76078097e-316, -4.66762591e-002,  1.65847042e-002,
         5.83916037e-002, -7.96008510e-002,  2.65624117e-003,
         2.71579714e-316,  9.54246540e-317],
       [ 3.15293975e-316, -2.76725620e-002,  4.13103094e-002,
         4.71192471e-002, -4.58886356e-002, -3.36094603e-003,
         3.01646133e-316,  6.26656561e-318],
       [-3.16094603e-317,  1.52887809e-316, -4.99841570e-317,
         8.38075156e-318, -1.90144395e-316,  4.00068471e-317,
        -1.44910047e-317,  1.21543281e-316],
       [ 1.82269725e-316, -4.62359032e-317, -2.74537932e-316,
        -1.97609643e-316,  2.34195703e-316, -7.58886709e-317,
         8.99127095e-317,  5.90417291e-317],
       [ 2.61886931e-316, -2.02223080e-316, -3.62855367e-316,
         8.78400152e-317,  2.10144508e-316, -3.02959448e-316,
        -1.16395419e-316, -7.99810710e-317],
       [ 8.09898147e-317, -3.42526425e-002,  7.15785654e-001,
         3.72099454e-001, -4.87869936e-001, -2.03417484e-001,
         3.82557253e-317, -1.82472934e-316],
       [ 3.02975505e-316,  4.29919172e-001, -3.67112080e-001,
         4.58464991e-001,  5.84434961e-001, -2.15977463e-001,
         2.47136858e-316, -1.18866443e-316],
       [ 5.25609810e-317,  5.66533191e-002, -4.04436308e-317,
         2.99105691e-001,  3.20108852e-001,  1.08992656e-002,
        -3.01584874e-316, -1.28760721e-317]]), array([[-2.56067895e-316,  7.98348078e-317, -1.20835942e-316,
         3.56425819e-316, -4.74562404e-318, -1.58158570e-316,
        -1.77227656e-316,  4.51151549e-317],
       [ 1.54379974e-001, -2.62074138e-316,  2.82864153e-001,
        -9.97641188e-002,  2.79232712e-001, -2.64118295e-316,
        -2.62438953e-002, -5.67355708e-002],
       [ 6.87928802e-001, -3.11400056e-316, -1.40964319e-001,
         3.91405629e-001, -6.43141825e-001, -1.52160673e-316,
         1.35129823e-001,  3.05801994e-001],
       [ 3.47473274e-001,  4.91933259e-317,  2.80129698e-001,
         4.55595965e-001,  1.25441391e-001,  1.96000387e-317,
         1.18617541e-002,  3.61492245e-001],
       [ 3.80891545e-003, -3.57226310e-316,  1.65063193e-001,
        -5.59437155e-001,  3.43934452e-001, -1.96453001e-317,
        -1.40682546e-001, -4.27480080e-001],
       [ 1.82288620e-002,  3.10350537e-316, -3.74033940e-002,
         4.15899757e-002, -3.83931936e-002,  7.26473434e-317,
        -7.92327278e-004,  1.90490176e-002],
       [-3.69558030e-316, -3.30238512e-316,  1.69244050e-316,
         2.24480194e-316,  4.89304039e-317,  2.96753613e-318,
        -3.82636106e-317, -2.66174853e-317],
       [ 7.65489008e-317,  2.10381250e-316,  1.41105148e-320,
         2.45060706e-316, -2.15171275e-316, -1.36493979e-316,
         7.76230242e-317, -2.07577758e-316]]), array([[ 2.77562499e-001,  1.36427565e-002, -2.80724064e-001,
        -1.58564287e-002,  5.59418037e-001,  3.45967532e-001,
         3.07925766e-001, -1.67362697e-316],
       [-2.07309258e-316, -2.90856880e-316,  2.35367424e-316,
         1.83339915e-316, -3.56718262e-317, -3.52150230e-318,
        -5.51595835e-317,  2.80880697e-316],
       [-3.18719539e-001,  9.12017212e-002,  2.19333562e-001,
        -1.19770001e-001, -5.17920894e-001, -4.45010232e-001,
         4.97849196e-002,  1.26786499e-316],
       [ 4.67069400e-001, -2.26388674e-001, -5.28097787e-001,
         1.33307346e-001,  6.60208934e-001,  5.17192203e-001,
        -4.65820909e-003,  2.21556438e-276],
       [-4.06980268e-001, -3.33610461e-001,  3.40071288e-001,
         1.56077955e-001,  1.61072515e-002, -2.58068011e-001,
        -6.25460491e-001,  1.72198239e-302],
       [-3.10707168e-316, -8.73361324e-318, -2.36427086e-316,
         6.43954442e-317, -1.10961956e-316, -3.73181522e-316,
         4.37657529e-317, -4.38819917e-317],
       [ 6.09583863e-002,  3.01198661e-002, -7.22656109e-002,
         2.49404429e-002,  8.28456416e-002,  1.16658568e-001,
         1.24795696e-001, -1.82601184e-316],
       [ 1.51400950e-001,  3.97078163e-001,  4.06324398e-001,
         4.61372727e-001,  3.00627271e-001,  4.09275540e-001,
         1.07241102e-001,  1.54011578e-275]]), array([[ 4.01502482e-001],
       [ 1.92114878e-001],
       [-8.68040593e-001],
       [ 1.59403087e-001],
       [ 5.36227515e-001],
       [ 8.24072620e-001],
       [ 9.05144946e-001],
       [ 2.49179291e-317]])]
[ 0.02224576  0.09312228  0.14330312  0.15158743  0.21940444 -0.06390797
  0.09694466 -0.01881366]
TRAIN
Mean PCC: 0.47878364295722387 +- 0.4428381325634169
PCC: Min: -0.06199394356550219 Max: 0.8721312589263872
Mean MSE: 0.7768231065915556 +- 0.44006262689334885
MSE: Min: 0.29844758506944963 Max: 1.4387846482083055
MSE:
ArgMin: [('5aiz', 110), ('6c4q', 85), ('4hlb', 95), ('3o2e', 86), ('2huj', 125), ('4rgi', 71), ('1tif', 76), ('4o7q', 94), ('3bv8', 85), ('2yvi', 89)]
ArgMax: [('4aqo', 86), ('1j0p', 108), ('3dt5', 119), ('2pne', 81), ('5dbl', 130), ('1jni', 62), ('5v0m', 98), ('2a3m', 107), ('2w9y', 136), ('1sau', 114)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('4aqo', 86), ('2nwf', 141), ('2h5c', 198), ('2pne', 81), ('3zfp', 148), ('5nuv', 301), ('2w9y', 136), ('3tch', 517)]
ArgMax: [('3bv8', 85), ('4hlb', 95), ('2huj', 125), ('5aiz', 110), ('1tif', 76), ('6c4q', 85), ('2p0h', 118), ('5w0h', 80), ('3o2e', 86), ('5zt3', 114)]
MSE vs Length correlation: 0.04692613226051057
PCC vs Length correlation: 0.06996829301438101
MSE vs b-val mean correlation: 1.4091481492783942e-07
PCC vs b-val mean correlation: 2.247553441470096e-06
VAL
Mean PCC: 0.4818919942319684 +- 0.4346214443500359
PCC: Min: -0.0021850510630933634 Max: 0.8828713783972828
Mean MSE: 0.7730174212185307 +- 0.4253936234415716
MSE: Min: 0.25946181751974406 Max: 1.3552378604127804
MSE:
ArgMin: [('2vc8', 72), ('3mao', 105), ('2i5u', 77), ('5hqh', 96), ('5ijm', 98), ('4i6x', 117), ('4gos', 115), ('2b1k', 149), ('3tbn', 87), ('2cxy', 114)]
ArgMax: [('2rkn', 77), ('3fgh', 67), ('2rbk', 261), ('1u5p', 211), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('3zt9', 192), ('3s9x', 159), ('5hfg', 205)]
PCC:
ArgMin: [('2rbk', 261), ('2rkn', 77), ('3gvo', 342), ('3sw0', 186), ('1u5p', 211), ('2v9k', 467), ('5hfg', 205), ('4e1b', 330), ('3s9x', 159), ('4rep', 489)]
ArgMax: [('2vc8', 72), ('5hqh', 96), ('3mao', 105), ('4i6x', 117), ('2i5u', 77), ('5ijm', 98), ('3tbn', 87), ('4gos', 115), ('2b1k', 149), ('2cxy', 114)]
MSE vs Length correlation: 0.06325687276949254
PCC vs Length correlation: 0.08576800986910682
MSE vs b-val mean correlation: 0.0017272968250638954
PCC vs b-val mean correlation: 0.0017605372859539337
TEST
Mean PCC: 0.47170744291977446 +- 0.44841249531061234
PCC: Min: -0.0823233590014541 Max: 0.853034571217989
Mean MSE: 0.7830536299105838 +- 0.44075824383374795
MSE: Min: 0.3406201112765549 Max: 1.4176361744298627
MSE:
ArgMin: [('4qq6', 58), ('2od5', 91), ('5ol9', 81), ('3t7l', 74), ('5kuj', 95), ('3o70', 55), ('3cp0', 63), ('3chm', 161), ('1tuk', 67), ('1mud', 225)]
ArgMax: [('4npn', 71), ('5i8g', 226), ('3b6e', 182), ('4gs3', 90), ('2vac', 134), ('4xxt', 221), ('4qdn', 118), ('2c4x', 250), ('4uyr', 188), ('3zr8', 65)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('1r5y', 361), ('2vac', 134), ('3ip0', 158), ('4uyr', 188), ('4qdn', 118), ('3b6e', 182), ('4r1b', 282)]
ArgMax: [('4qq6', 58), ('2od5', 91), ('5ol9', 81), ('1mud', 225), ('3t7l', 74), ('5kuj', 95), ('3cp0', 63), ('4rwu', 81), ('1tuk', 67), ('3o70', 55)]
MSE vs Length correlation: 0.04616679530596479
PCC vs Length correlation: 0.06006261248554156
MSE vs b-val mean correlation: 2.5489428101543865e-07
PCC vs b-val mean correlation: 3.074714632234077e-06
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.48312661
Validation score: 0.177132
Iteration 2, loss = 0.40965335
Validation score: 0.188840
Iteration 3, loss = 0.40662612
Validation score: 0.191646
Iteration 4, loss = 0.40526895
Validation score: 0.191981
Iteration 5, loss = 0.40469334
Validation score: 0.188641
Iteration 6, loss = 0.40414656
Validation score: 0.192526
Iteration 7, loss = 0.40358899
Validation score: 0.194039
Iteration 8, loss = 0.40320578
Validation score: 0.192633
Iteration 9, loss = 0.40312518
Validation score: 0.194499
Iteration 10, loss = 0.40265701
Validation score: 0.192623
Iteration 11, loss = 0.40243112
Validation score: 0.192919
Iteration 12, loss = 0.40233166
Validation score: 0.193342
Iteration 13, loss = 0.40208781
Validation score: 0.192883
Iteration 14, loss = 0.40203922
Validation score: 0.189476
Iteration 15, loss = 0.40183306
Validation score: 0.193030
Iteration 16, loss = 0.40148954
Validation score: 0.192810
Iteration 17, loss = 0.40173998
Validation score: 0.190993
Iteration 18, loss = 0.40154278
Validation score: 0.191475
Iteration 19, loss = 0.40117329
Validation score: 0.193054
Iteration 20, loss = 0.40102791
Validation score: 0.188508
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.7989704355075027, total= 1.5min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.42212533
Validation score: 0.203204
Iteration 2, loss = 0.41200632
Validation score: 0.199215
Iteration 3, loss = 0.41099149
Validation score: 0.208136
Iteration 4, loss = 0.41068148
Validation score: 0.207448
Iteration 5, loss = 0.41024904
Validation score: 0.206876
Iteration 6, loss = 0.40983205
Validation score: 0.206065
Iteration 7, loss = 0.40978845
Validation score: 0.200462
Iteration 8, loss = 0.40971831
Validation score: 0.206134
Iteration 9, loss = 0.40976399
Validation score: 0.207698
Iteration 10, loss = 0.40943958
Validation score: 0.210124
Iteration 11, loss = 0.40963501
Validation score: 0.209992
Iteration 12, loss = 0.40956630
Validation score: 0.206750
Iteration 13, loss = 0.40926478
Validation score: 0.208525
Iteration 14, loss = 0.40943852
Validation score: 0.207389
Iteration 15, loss = 0.40909830
Validation score: 0.207099
Iteration 16, loss = 0.40923150
Validation score: 0.206603
Iteration 17, loss = 0.40936573
Validation score: 0.203941
Iteration 18, loss = 0.40915716
Validation score: 0.207445
Iteration 19, loss = 0.40904155
Validation score: 0.207403
Iteration 20, loss = 0.40882727
Validation score: 0.210003
Iteration 21, loss = 0.40901350
Validation score: 0.208464
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.8037408156456305, total= 1.5min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.63796630
Validation score: -0.008418
Iteration 2, loss = 0.50343264
Validation score: -0.000022
Iteration 3, loss = 0.50297543
Validation score: -0.000152
Iteration 4, loss = 0.50285457
Validation score: -0.000019
Iteration 5, loss = 0.50275947
Validation score: -0.000047
Iteration 6, loss = 0.50267136
Validation score: -0.000171
Iteration 7, loss = 0.50259290
Validation score: -0.000130
Iteration 8, loss = 0.50251334
Validation score: -0.000136
Iteration 9, loss = 0.50246815
Validation score: -0.000189
Iteration 10, loss = 0.50239691
Validation score: -0.000017
Iteration 11, loss = 0.50236476
Validation score: -0.000220
Iteration 12, loss = 0.50232423
Validation score: -0.000342
Iteration 13, loss = 0.50229592
Validation score: -0.000002
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.9913511071406064, total=  55.2s
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.42332405
Validation score: 0.192045
Iteration 2, loss = 0.40867600
Validation score: 0.194094
Iteration 3, loss = 0.40711065
Validation score: 0.195357
Iteration 4, loss = 0.40649465
Validation score: 0.193498
Iteration 5, loss = 0.40591643
Validation score: 0.196215
Iteration 6, loss = 0.40583180
Validation score: 0.190132
Iteration 7, loss = 0.40551337
Validation score: 0.196960
Iteration 8, loss = 0.40512544
Validation score: 0.194210
Iteration 9, loss = 0.40521530
Validation score: 0.195800
Iteration 10, loss = 0.40498901
Validation score: 0.196368
Iteration 11, loss = 0.40468334
Validation score: 0.196499
Iteration 12, loss = 0.40474207
Validation score: 0.196757
Iteration 13, loss = 0.40430997
Validation score: 0.195560
Iteration 14, loss = 0.40421568
Validation score: 0.194945
Iteration 15, loss = 0.40435237
Validation score: 0.194597
Iteration 16, loss = 0.40418647
Validation score: 0.194642
Iteration 17, loss = 0.40401407
Validation score: 0.195933
Iteration 18, loss = 0.40379955
Validation score: 0.192069
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8013025286272658, total= 1.2min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.46163295
Validation score: 0.173998
Iteration 2, loss = 0.41462542
Validation score: 0.190769
Iteration 3, loss = 0.41259366
Validation score: 0.190027
Iteration 4, loss = 0.41247727
Validation score: 0.191083
Iteration 5, loss = 0.41152312
Validation score: 0.190412
Iteration 6, loss = 0.41207925
Validation score: 0.189516
Iteration 7, loss = 0.41101522
Validation score: 0.183865
Iteration 8, loss = 0.41165093
Validation score: 0.193036
Iteration 9, loss = 0.41141315
Validation score: 0.181551
Iteration 10, loss = 0.41069075
Validation score: 0.190819
Iteration 11, loss = 0.41107252
Validation score: 0.188028
Iteration 12, loss = 0.41086132
Validation score: 0.192636
Iteration 13, loss = 0.41070069
Validation score: 0.193716
Iteration 14, loss = 0.41118772
Validation score: 0.188141
Iteration 15, loss = 0.41078832
Validation score: 0.190064
Iteration 16, loss = 0.41084697
Validation score: 0.189155
Iteration 17, loss = 0.41042769
Validation score: 0.192727
Iteration 18, loss = 0.41021762
Validation score: 0.188097
Iteration 19, loss = 0.41071157
Validation score: 0.189392
Iteration 20, loss = 0.41021246
Validation score: 0.188297
Iteration 21, loss = 0.41021181
Validation score: 0.189781
Iteration 22, loss = 0.41008592
Validation score: 0.190133
Iteration 23, loss = 0.41031395
Validation score: 0.192810
Iteration 24, loss = 0.40977250
Validation score: 0.193378
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8035592053696983, total= 1.5min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.71539993
Validation score: -0.027691
Iteration 2, loss = 0.49938929
Validation score: 0.061864
Iteration 3, loss = 0.43375719
Validation score: 0.168914
Iteration 4, loss = 0.41500551
Validation score: 0.176496
Iteration 5, loss = 0.41201997
Validation score: 0.180561
Iteration 6, loss = 0.41080655
Validation score: 0.181201
Iteration 7, loss = 0.41007714
Validation score: 0.182674
Iteration 8, loss = 0.40954900
Validation score: 0.183012
Iteration 9, loss = 0.40913188
Validation score: 0.184152
Iteration 10, loss = 0.40866319
Validation score: 0.184646
Iteration 11, loss = 0.40827631
Validation score: 0.185282
Iteration 12, loss = 0.40782189
Validation score: 0.185996
Iteration 13, loss = 0.40735492
Validation score: 0.185456
Iteration 14, loss = 0.40694516
Validation score: 0.187066
Iteration 15, loss = 0.40649630
Validation score: 0.187915
Iteration 16, loss = 0.40612219
Validation score: 0.188414
Iteration 17, loss = 0.40574347
Validation score: 0.188093
Iteration 18, loss = 0.40536582
Validation score: 0.189197
Iteration 19, loss = 0.40503837
Validation score: 0.189268
Iteration 20, loss = 0.40471100
Validation score: 0.190163
Iteration 21, loss = 0.40447125
Validation score: 0.190156
Iteration 22, loss = 0.40418163
Validation score: 0.190060
Iteration 23, loss = 0.40391521
Validation score: 0.190692
Iteration 24, loss = 0.40371777
Validation score: 0.189997
Iteration 25, loss = 0.40354547
Validation score: 0.190531
Iteration 26, loss = 0.40336285
Validation score: 0.190287
Iteration 27, loss = 0.40320802
Validation score: 0.189209
Iteration 28, loss = 0.40302561
Validation score: 0.190673
Iteration 29, loss = 0.40290678
Validation score: 0.190693
Iteration 30, loss = 0.40276580
Validation score: 0.189806
Iteration 31, loss = 0.40262731
Validation score: 0.190011
Iteration 32, loss = 0.40254119
Validation score: 0.190506
Iteration 33, loss = 0.40240143
Validation score: 0.190916
Iteration 34, loss = 0.40230883
Validation score: 0.190829
Iteration 35, loss = 0.40219911
Validation score: 0.190710
Iteration 36, loss = 0.40211997
Validation score: 0.190773
Iteration 37, loss = 0.40201564
Validation score: 0.190868
Iteration 38, loss = 0.40189880
Validation score: 0.189630
Iteration 39, loss = 0.40186083
Validation score: 0.190424
Iteration 40, loss = 0.40172299
Validation score: 0.190083
Iteration 41, loss = 0.40164020
Validation score: 0.190702
Iteration 42, loss = 0.40154700
Validation score: 0.189331
Iteration 43, loss = 0.40153756
Validation score: 0.189677
Iteration 44, loss = 0.40142085
Validation score: 0.190429
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.7985969644500407, total= 3.8min
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.56572919
Validation score: 0.083383
Iteration 2, loss = 0.43580578
Validation score: 0.157417
Iteration 3, loss = 0.42489040
Validation score: 0.162062
Iteration 4, loss = 0.42263862
Validation score: 0.165199
Iteration 5, loss = 0.42091373
Validation score: 0.167924
Iteration 6, loss = 0.41933947
Validation score: 0.170868
Iteration 7, loss = 0.41787966
Validation score: 0.173462
Iteration 8, loss = 0.41652136
Validation score: 0.175340
Iteration 9, loss = 0.41528340
Validation score: 0.177663
Iteration 10, loss = 0.41410877
Validation score: 0.179392
Iteration 11, loss = 0.41308158
Validation score: 0.180977
Iteration 12, loss = 0.41215745
Validation score: 0.182815
Iteration 13, loss = 0.41132941
Validation score: 0.184489
Iteration 14, loss = 0.41055741
Validation score: 0.185565
Iteration 15, loss = 0.40990633
Validation score: 0.186276
Iteration 16, loss = 0.40927663
Validation score: 0.187870
Iteration 17, loss = 0.40878741
Validation score: 0.188784
Iteration 18, loss = 0.40824017
Validation score: 0.189237
Iteration 19, loss = 0.40780291
Validation score: 0.190300
Iteration 20, loss = 0.40734284
Validation score: 0.190988
Iteration 21, loss = 0.40697036
Validation score: 0.191636
Iteration 22, loss = 0.40661234
Validation score: 0.192258
Iteration 23, loss = 0.40625645
Validation score: 0.192414
Iteration 24, loss = 0.40596690
Validation score: 0.192334
Iteration 25, loss = 0.40564479
Validation score: 0.193526
Iteration 26, loss = 0.40534292
Validation score: 0.192964
Iteration 27, loss = 0.40508519
Validation score: 0.194391
Iteration 28, loss = 0.40488061
Validation score: 0.194313
Iteration 29, loss = 0.40456071
Validation score: 0.194188
Iteration 30, loss = 0.40441032
Validation score: 0.194415
Iteration 31, loss = 0.40420628
Validation score: 0.195230
Iteration 32, loss = 0.40400363
Validation score: 0.195747
Iteration 33, loss = 0.40376932
Validation score: 0.195941
Iteration 34, loss = 0.40360354
Validation score: 0.195875
Iteration 35, loss = 0.40342103
Validation score: 0.195754
Iteration 36, loss = 0.40326347
Validation score: 0.196009
Iteration 37, loss = 0.40313035
Validation score: 0.196108
Iteration 38, loss = 0.40305534
Validation score: 0.196555
Iteration 39, loss = 0.40283692
Validation score: 0.196558
Iteration 40, loss = 0.40266185
Validation score: 0.195889
Iteration 41, loss = 0.40252627
Validation score: 0.196915
Iteration 42, loss = 0.40240599
Validation score: 0.195908
Iteration 43, loss = 0.40226889
Validation score: 0.196804
Iteration 44, loss = 0.40218770
Validation score: 0.197224
Iteration 45, loss = 0.40209008
Validation score: 0.197336
Iteration 46, loss = 0.40191842
Validation score: 0.197301
Iteration 47, loss = 0.40183484
Validation score: 0.197334
Iteration 48, loss = 0.40170283
Validation score: 0.196713
Iteration 49, loss = 0.40155868
Validation score: 0.197146
Iteration 50, loss = 0.40151901
Validation score: 0.197313
Iteration 51, loss = 0.40138044
Validation score: 0.197211
Iteration 52, loss = 0.40131587
Validation score: 0.196374
Iteration 53, loss = 0.40120099
Validation score: 0.196872
Iteration 54, loss = 0.40109193
Validation score: 0.197316
Iteration 55, loss = 0.40106482
Validation score: 0.196943
Iteration 56, loss = 0.40089768
Validation score: 0.196409
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.8020776264566277, total= 4.6min
11
Input read.
(540304, 23)
(540304, 483)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.42294091
Validation score: 0.184923
Iteration 2, loss = 0.40724380
Validation score: 0.184753
Iteration 3, loss = 0.40627430
Validation score: 0.182936
Iteration 4, loss = 0.40572751
Validation score: 0.188402
Iteration 5, loss = 0.40509652
Validation score: 0.188671
Iteration 6, loss = 0.40481191
Validation score: 0.189718
Iteration 7, loss = 0.40447274
Validation score: 0.188846
Iteration 8, loss = 0.40431267
Validation score: 0.185746
Iteration 9, loss = 0.40426254
Validation score: 0.190044
Iteration 10, loss = 0.40393766
Validation score: 0.188506
Iteration 11, loss = 0.40388596
Validation score: 0.189510
Iteration 12, loss = 0.40365669
Validation score: 0.190688
Iteration 13, loss = 0.40386919
Validation score: 0.190853
Iteration 14, loss = 0.40364535
Validation score: 0.190619
Iteration 15, loss = 0.40345907
Validation score: 0.191981
Iteration 16, loss = 0.40345628
Validation score: 0.190232
Iteration 17, loss = 0.40322560
Validation score: 0.188748
Iteration 18, loss = 0.40329204
Validation score: 0.191053
Iteration 19, loss = 0.40317395
Validation score: 0.189090
Iteration 20, loss = 0.40312047
Validation score: 0.188571
Iteration 21, loss = 0.40313521
Validation score: 0.187748
Iteration 22, loss = 0.40300040
Validation score: 0.188785
Iteration 23, loss = 0.40291862
Validation score: 0.189625
Iteration 24, loss = 0.40285347
Validation score: 0.189413
Iteration 25, loss = 0.40282232
Validation score: 0.189483
Iteration 26, loss = 0.40277418
Validation score: 0.187625
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.002
0.20845227525148358
[[0.33786426 0.29711822 0.34526935 0.18461006 0.31477872 0.22498385
  0.22523826 0.30720421 0.32570578 0.26520539 0.2767142  0.25232121
  0.2412793  0.32587952 0.26341762 0.37599479 0.41889511 0.20189692
  0.25417082 0.27454064 0.26060494]
 [0.38455045 0.31373493 0.37191281 0.23273284 0.30310318 0.32237092
  0.25158178 0.30322008 0.29564194 0.18633957 0.29419306 0.29729899
  0.23631531 0.20302313 0.34898073 0.43994349 0.2598385  0.2239865
  0.36173936 0.23215118 0.27582197]
 [0.51113649 0.35211019 0.56818397 0.33953206 0.39153144 0.42438284
  0.40296333 0.27559572 0.37013048 0.36934733 0.44140713 0.30288272
  0.37800034 0.30326049 0.43913478 0.69866604 0.54498123 0.38037978
  0.35892601 0.37350615 0.25312777]
 [0.59619818 0.69234049 0.832821   0.61181421 0.57265003 0.40370502
  0.5765838  0.57437905 0.71861948 0.66805906 0.56252267 0.45241314
  0.63286345 0.58563361 0.78660233 0.95251723 0.55659919 1.26398137
  0.57386164 0.82418589 0.94666781]
 [0.64816053 0.51679849 0.45756415 0.75672444 0.35954509 0.53729012
  0.63991904 0.68768102 0.736273   0.62422412 0.48913672 0.51216466
  0.59966079 0.60234489 0.73409412 0.96853183 0.70652602 1.10047983
  0.67332458 0.78636044 0.74610449]
 [0.40276806 0.28636404 0.44923281 0.38797602 0.31919433 0.30762815
  0.38478226 0.39997606 0.32727357 0.30441721 0.34868483 0.33693025
  0.41939249 0.45132631 0.69927193 0.66559099 0.46024809 0.42594337
  0.48678918 0.47947726 0.40981349]
 [0.29096114 0.2875342  0.29215457 0.22775823 0.26487236 0.29567256
  0.37536425 0.3089719  0.24285087 0.33233859 0.29575777 0.3594876
  0.36064622 0.35912992 0.56213506 0.41075913 0.22375046 0.33155609
  0.20825922 0.48379385 0.43472334]
 [0.30031713 0.22411667 0.1742238  0.30797899 0.34924283 0.28156969
  0.26940166 0.25300646 0.18233349 0.31643306 0.28552703 0.3061836
  0.23091042 0.24413916 0.43228276 0.29775707 0.26822797 0.2421236
  0.22436458 0.45748836 0.2377906 ]]
[array([[ 1.29104910e-142, -2.44723055e-151,  5.34013264e-316,
        -2.63192751e-170,  5.95653440e-151,  3.98004162e-131,
         1.20977251e-152, -1.71753490e-173],
       [ 1.14212707e-001, -1.72958494e-001,  4.46993618e-312,
        -1.22450007e-001, -2.39942275e-001, -3.01156090e-001,
        -1.29297111e-001, -2.23548409e-001],
       [ 4.25841746e-001, -4.88889002e-001, -1.58924638e-312,
         3.98653371e-002,  3.34317857e-001, -1.08258780e-001,
        -1.14857976e-001, -1.35735196e-001],
       [-2.22672491e-001,  3.19319611e-001, -6.31313986e-295,
         1.76507724e-002,  2.93867921e-001,  7.39086592e-002,
         1.60355887e-001,  3.43624223e-001],
       [ 6.72105044e-001, -8.37815430e-002, -8.25181480e-316,
         5.49225595e-002,  1.67372215e-001, -3.64016860e-001,
         4.87995897e-002, -3.24232460e-001],
       [-6.51976220e-002, -1.78895084e-001, -1.50921432e-316,
        -5.43016198e-002, -1.29206530e-001, -3.44406823e-001,
        -1.34144531e-001, -1.89601408e-001],
       [-5.09619910e-001,  2.87804651e-001,  3.13683576e-295,
         6.43373815e-002,  1.92905876e-001,  4.24217884e-001,
         4.34610944e-001, -2.01032555e-001],
       [ 4.43626872e-001,  4.87668122e-001,  1.03612630e-315,
         5.59827163e-002,  2.54820749e-001,  2.00233529e-001,
         1.74972703e-001,  2.13486822e-001]]), array([[-1.78552513e-316, -1.69057343e-002,  8.49346447e-001,
        -2.39535725e-002, -1.60452919e-308, -7.50710549e-072,
        -3.76180953e-001, -1.21353340e-007],
       [-7.11673347e-316,  1.68120934e-003, -5.27201031e-001,
         1.11112392e-001,  2.36733866e-316,  1.04832614e-061,
         3.90692301e-001, -6.67141795e-008],
       [ 5.54297584e-317,  2.39803605e-317,  9.45962547e-316,
        -1.93951859e-294, -3.13432688e-299, -3.24337639e-316,
         1.15249818e-315, -7.13907022e-317],
       [ 3.50624074e-301,  7.28249531e-004,  1.00985854e-001,
         4.47275377e-002,  1.18617183e-307,  1.33597224e-046,
         1.26515083e-001, -2.78600248e-007],
       [ 1.53180696e-316,  1.38265485e-002,  3.61163371e-001,
         8.82052795e-002,  1.87635781e-314,  3.25148857e-071,
         4.46081114e-001, -1.76178071e-007],
       [ 5.11594008e-316,  7.98774116e-004, -2.90117144e-001,
         9.39647268e-002,  2.16971463e-316,  9.28334949e-060,
         4.81868260e-001, -1.07509284e-007],
       [ 4.27189893e-316, -1.63387314e-003,  6.20383397e-002,
         1.90177198e-002, -1.47737284e-294, -3.59078080e-094,
         4.19852608e-001,  1.20317658e-015],
       [ 1.01070056e-316, -5.35247642e-004, -4.25795700e-001,
         1.39282192e-002, -1.79524176e-314, -3.86312512e-093,
         2.98730619e-001,  3.51528003e-013]]), array([[-3.11615360e-316, -6.42732370e-317,  2.66015063e-302,
         9.47241643e-316,  8.00414191e-308, -8.06363758e-315,
        -1.08332638e-316, -3.89710497e-293],
       [ 3.32461883e-074,  1.96429825e-003, -2.11266343e-309,
         7.91748776e-305,  4.23603521e-003, -1.64823781e-021,
        -1.03238083e-001,  9.69801785e-002],
       [-3.01694633e-108,  1.00027954e+000,  2.53344685e-314,
        -6.17765331e-315, -6.49276961e-002, -1.29634308e-071,
        -6.87598809e-003, -2.88349873e-001],
       [-7.05272702e-057, -5.90797781e-002, -1.43185077e-308,
        -5.89370479e-316,  4.71632185e-002, -2.01121290e-015,
         2.81666018e-001, -1.66354589e-001],
       [ 6.60459347e-317, -6.84613568e-304,  1.95923979e-315,
         8.40426167e-316, -2.61050024e-316,  4.94748291e-316,
         4.83000552e-316,  4.30401543e-309],
       [-5.77670630e-218,  3.86331306e-033, -9.05608318e-294,
        -2.02615142e-299,  2.37048075e-028, -6.27107952e-148,
         2.13089160e-045,  1.33787618e-033],
       [ 2.55593042e-026,  6.60090910e-002, -1.30367044e-315,
        -2.83861342e-297,  2.87130272e-001,  1.01847225e-005,
         5.59367037e-001,  6.40072172e-001],
       [ 1.22466887e-155,  7.88793639e-006, -1.49764421e-315,
         2.89234230e-298,  6.19895895e-007,  6.68012606e-134,
         1.54596526e-007,  2.02890684e-006]]), array([[ 9.45124275e-017,  3.02870430e-039,  3.43287943e-028,
        -3.59732166e-165, -3.36157490e-046, -8.09378786e-317,
         1.00244136e-162, -8.83442879e-030],
       [ 1.51276616e-001,  5.33956898e-001,  6.54436571e-001,
         1.09805719e-145, -1.89231283e-001,  2.60894131e-303,
         5.09505689e-001,  1.55339813e-001],
       [ 3.33924237e-292, -5.62088068e-313, -4.17896558e-316,
        -1.26023852e-295,  1.26850223e-316, -4.42266397e-303,
        -1.06026355e-299, -2.14523402e-316],
       [-1.67733073e-316, -3.23927446e-316,  1.09780278e-028,
        -1.74116469e-292,  4.17857935e-302, -4.55467311e-317,
        -8.44680159e-312,  1.54123141e-316],
       [ 4.48063206e-001,  1.24464484e-001, -1.74955213e-001,
         1.62192226e-153,  1.25105280e-001,  1.31285980e-298,
        -1.26055026e-001,  2.16984806e-001],
       [ 3.08264324e-007,  1.98510816e-016,  2.64313995e-080,
        -2.46626864e-224,  5.97881971e-022,  5.53590828e-316,
        -2.02157423e-165,  7.05252539e-014],
       [ 5.20215429e-001, -4.85876378e-002, -2.51560710e-002,
        -1.37804102e-126,  8.21215152e-002, -2.87584682e-293,
        -1.53705584e-001,  1.11679738e-001],
       [ 5.28479509e-001, -2.12858414e-001, -1.51924403e-001,
        -1.03903374e-119, -5.22932915e-002,  4.43126599e-298,
        -3.45839173e-001,  2.96937238e-001]]), array([[-2.20120097e-271, -6.44555329e-316,  6.28085225e-001,
         1.65152613e-001, -7.53534250e-002,  2.66949799e-242,
        -5.87124441e-001, -5.37011481e-303],
       [-1.11610840e-257,  5.23244424e-298,  4.51785765e-001,
         3.56507392e-001, -6.68664181e-002, -1.11742584e-259,
         6.78453940e-001, -2.32337255e-316],
       [-3.21365735e-285, -2.65770623e-316, -2.39445861e-001,
         5.16469315e-001,  1.47568474e-001,  9.10740455e-312,
         4.04823885e-001, -7.21603262e-309],
       [-4.93429992e-296,  1.25416978e-314,  6.16529574e-173,
        -4.28151634e-184, -7.28592908e-213, -5.15768191e-288,
         1.93386975e-185,  8.18077988e-307],
       [-1.07452395e-289,  1.44226955e-300,  2.55952883e-001,
        -1.84951988e-001,  8.21350839e-002, -7.37921052e-299,
         2.00570693e-001,  1.47668347e-310],
       [-7.04851492e-293, -9.55485883e-296, -1.68368935e-308,
         8.82040748e-316, -2.64406933e-316, -1.07768809e-306,
        -5.62090580e-295, -1.25835111e-317],
       [-2.07850001e-290,  6.13061421e-316, -1.68107073e-001,
         5.43637162e-001,  1.12318051e-001,  7.37064054e-299,
         3.67220311e-001,  5.72245264e-310],
       [-5.87304614e-289, -4.65662592e-316,  1.22169961e-001,
        -8.50982982e-002,  9.18182819e-003, -3.64067568e-272,
        -5.90271485e-002, -3.53100140e-316]]), array([[-1.52552579e-299, -7.71269689e-295,  1.25593598e-290,
         8.35425071e-284, -7.15804252e-291,  4.23279439e-305,
         2.71164202e-291, -1.04770871e-315],
       [ 4.67439771e-316, -2.40213889e-304,  2.43009086e-301,
         2.02931550e-299, -4.39557460e-301, -1.31427875e-316,
        -5.74444414e-027,  1.01151656e-316],
       [-1.02126493e-315, -1.05360678e-229,  1.20140082e-001,
        -6.21322657e-001, -4.30739426e-006,  2.97972666e-316,
        -4.31558962e-001,  1.39185087e-179],
       [ 3.16149113e-305,  3.54851134e-219,  3.33117265e-001,
         5.02902020e-001, -7.98316298e-007,  6.22316357e-316,
         4.00852855e-001,  3.95919822e-187],
       [-2.86012841e-310,  1.24919441e-252,  5.49587042e-002,
         1.59636171e-001, -8.30209769e-022,  9.88371852e-316,
        -1.96548123e-002,  6.14649239e-225],
       [-1.21075372e-315,  1.28862918e-316,  2.53599646e-310,
        -1.16384929e-293, -2.31645394e-286,  9.59364997e-199,
         2.04908292e-298, -4.78174568e-316],
       [ 7.15396191e-316,  3.67425416e-232, -4.03352447e-001,
         5.42399295e-001, -4.08848812e-013,  2.86041598e-316,
         3.91744548e-001, -4.32476689e-243],
       [ 5.57679841e-302, -1.19125853e-310, -1.67935082e-315,
        -9.06441004e-304,  1.51071147e-298,  1.15284261e-314,
         2.77272043e-313, -6.91875776e-297]]), array([[-1.92846104e-316,  9.76682774e-307,  4.36247987e-026,
        -2.75246328e-316, -1.06896399e-306, -6.01297619e-315,
         1.93264316e-316,  4.34677661e-316],
       [ 1.79329046e-316, -1.44810156e-220, -5.24859177e-317,
         4.02323979e-316,  2.79433605e-290, -2.55595316e-303,
         1.78676010e-237,  9.89230107e-297],
       [-1.09787261e-316, -1.82289193e-001,  7.12751144e-310,
        -1.70377593e-255, -8.74878303e-202,  1.74534618e-317,
        -2.30215812e-001,  7.93644376e-317],
       [ 4.90891288e-311,  2.86616997e-001, -3.51418365e-316,
         1.03570242e-157, -1.32719661e-199, -5.65738603e-316,
         7.15605090e-001,  8.77619391e-308],
       [-3.37721118e-304, -3.38692684e-002, -1.64625534e-316,
         1.56641042e-279,  1.23653109e-190, -2.39111119e-298,
         3.11106976e-002,  1.03925903e-316],
       [-1.50540122e-316,  2.84904434e-315,  3.86751920e-317,
        -1.54478285e-316,  2.09894694e-316,  4.18810119e-300,
         6.90005880e-316, -5.94309003e-301],
       [-5.34803631e-317,  2.44676495e-001,  2.44914492e-316,
         1.95306627e-179, -3.09982067e-208, -3.74958795e-316,
         4.84064990e-001, -3.40613021e-316],
       [ 2.01340646e-305, -1.68745696e-298, -8.03137205e-317,
         6.82487743e-316, -1.87682527e-277, -3.21726351e-309,
        -4.59619082e-288,  3.24945666e-315]]), array([[-8.54364369e-300],
       [ 6.52434562e-001],
       [-2.82813617e-315],
       [-2.89415743e-281],
       [-8.85762402e-197],
       [-5.57223070e-301],
       [ 5.37065028e-001],
       [-4.16836647e-300]])]
[-0.07698633 -0.08474754 -0.12488844  0.20970619 -0.40964223 -0.22049836
  0.27472573 -0.04349125]
TRAIN
Mean PCC: 0.482673804055512 +- 0.4406323048903037
PCC: Min: -0.08990283935533026 Max: 0.8806569182074468
Mean MSE: 0.7718609371848443 +- 0.441322764894151
MSE: Min: 0.30208302403402354 Max: 1.4341182821577667
MSE:
ArgMin: [('4hlb', 95), ('5aiz', 110), ('6c4q', 85), ('5w0h', 80), ('2hcm', 159), ('4rgi', 71), ('5i29', 139), ('3bv8', 85), ('2huj', 125), ('2yvi', 89)]
ArgMax: [('4aqo', 86), ('3dt5', 119), ('1j0p', 108), ('2pne', 81), ('1jni', 62), ('2a3m', 107), ('5dbl', 130), ('1lmi', 131), ('5v0m', 98), ('1sau', 114)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('4aqo', 86), ('2pne', 81), ('2h5c', 198), ('3tch', 517), ('2nwf', 141), ('5nuv', 301), ('2w9y', 136), ('1jni', 62)]
ArgMax: [('5w0h', 80), ('4hlb', 95), ('5aiz', 110), ('6c4q', 85), ('3bv8', 85), ('5zt3', 114), ('1xmt', 95), ('2hcm', 159), ('2p0h', 118), ('2huj', 125)]
MSE vs Length correlation: 0.051154480353709286
PCC vs Length correlation: 0.07122697031487235
MSE vs b-val mean correlation: 3.5014776483821564e-06
PCC vs b-val mean correlation: 8.185500021129499e-07
VAL
Mean PCC: 0.48098114590105484 +- 0.42987572491568105
PCC: Min: -0.006519005001711486 Max: 0.8832885199500756
Mean MSE: 0.7734902146355115 +- 0.42448362711584925
MSE: Min: 0.2819187412449605 Max: 1.331786922302123
MSE:
ArgMin: [('2vc8', 72), ('3mao', 105), ('4i6x', 117), ('2i5u', 77), ('5ijm', 98), ('5hqh', 96), ('1i2t', 61), ('2b1k', 149), ('4gos', 115), ('4zc3', 57)]
ArgMax: [('2rkn', 77), ('3fgh', 67), ('2rbk', 261), ('3sw0', 186), ('1u5p', 211), ('3gvo', 342), ('4e1b', 330), ('2v9k', 467), ('3s9x', 159), ('3zt9', 192)]
PCC:
ArgMin: [('2rbk', 261), ('3gvo', 342), ('2rkn', 77), ('3sw0', 186), ('1u5p', 211), ('4e1b', 330), ('2v9k', 467), ('5hfg', 205), ('4rep', 489), ('3s9x', 159)]
ArgMax: [('2vc8', 72), ('3mao', 105), ('4i6x', 117), ('5hqh', 96), ('2i5u', 77), ('5ijm', 98), ('2b1k', 149), ('3tbn', 87), ('4gos', 115), ('4zc3', 57)]
MSE vs Length correlation: 0.06323557609217356
PCC vs Length correlation: 0.0870776417700625
MSE vs b-val mean correlation: 0.001562238527235138
PCC vs b-val mean correlation: 0.0010183797409337725
TEST
Mean PCC: 0.4736865273876217 +- 0.44099278757148874
PCC: Min: -0.031187642770854257 Max: 0.8567366553330386
Mean MSE: 0.7811225734868371 +- 0.4379655043782097
MSE: Min: 0.33703577560831777 Max: 1.4341159576520035
MSE:
ArgMin: [('4qq6', 58), ('2od5', 91), ('3o70', 55), ('5kuj', 95), ('5ol9', 81), ('3cp0', 63), ('3t7l', 74), ('1tzv', 141), ('3chm', 161), ('2ovg', 58)]
ArgMax: [('4npn', 71), ('5i8g', 226), ('4gs3', 90), ('3b6e', 182), ('2vac', 134), ('4xxt', 221), ('4qdn', 118), ('1uoy', 64), ('3zr8', 65), ('4uyr', 188)]
PCC:
ArgMin: [('4npn', 71), ('5i8g', 226), ('4xxt', 221), ('1r5y', 361), ('4r1b', 282), ('4uyr', 188), ('3ip0', 158), ('4qdn', 118), ('2vac', 134), ('3b6e', 182)]
ArgMax: [('4rwu', 81), ('4qq6', 58), ('2od5', 91), ('3cp0', 63), ('1mud', 225), ('3chm', 161), ('3o70', 55), ('1dqg', 134), ('5kuj', 95), ('1tzv', 141)]
MSE vs Length correlation: 0.0472208924720523
PCC vs Length correlation: 0.06201662492129023
MSE vs b-val mean correlation: 1.145636773780545e-06
PCC vs b-val mean correlation: 4.905739554805777e-06
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.46647107
Validation score: 0.173096
Iteration 2, loss = 0.41215676
Validation score: 0.187420
Iteration 3, loss = 0.40813456
Validation score: 0.190191
Iteration 4, loss = 0.40673817
Validation score: 0.190733
Iteration 5, loss = 0.40586741
Validation score: 0.191171
Iteration 6, loss = 0.40520091
Validation score: 0.190197
Iteration 7, loss = 0.40466017
Validation score: 0.190660
Iteration 8, loss = 0.40417868
Validation score: 0.191050
Iteration 9, loss = 0.40390894
Validation score: 0.191424
Iteration 10, loss = 0.40348809
Validation score: 0.190983
Iteration 11, loss = 0.40315705
Validation score: 0.189655
Iteration 12, loss = 0.40302807
Validation score: 0.191579
Iteration 13, loss = 0.40275589
Validation score: 0.191944
Iteration 14, loss = 0.40244788
Validation score: 0.191868
Iteration 15, loss = 0.40234773
Validation score: 0.190400
Iteration 16, loss = 0.40215032
Validation score: 0.190412
Iteration 17, loss = 0.40193543
Validation score: 0.191059
Iteration 18, loss = 0.40180925
Validation score: 0.190380
Iteration 19, loss = 0.40162245
Validation score: 0.190301
Iteration 20, loss = 0.40146502
Validation score: 0.190947
Iteration 21, loss = 0.40130536
Validation score: 0.191279
Iteration 22, loss = 0.40120319
Validation score: 0.191409
Iteration 23, loss = 0.40105761
Validation score: 0.187617
Iteration 24, loss = 0.40088737
Validation score: 0.190761
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.8007735869242064, total= 1.7min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.50708284
Validation score: -0.000093
Iteration 2, loss = 0.50301086
Validation score: -0.000006
Iteration 3, loss = 0.50294212
Validation score: -0.000061
Iteration 4, loss = 0.50288260
Validation score: -0.000054
Iteration 5, loss = 0.50287157
Validation score: -0.000013
Iteration 6, loss = 0.50288344
Validation score: -0.000001
Iteration 7, loss = 0.50285833
Validation score: -0.000115
Iteration 8, loss = 0.50288960
Validation score: -0.000101
Iteration 9, loss = 0.50283399
Validation score: -0.000242
Iteration 10, loss = 0.50283662
Validation score: -0.000129
Iteration 11, loss = 0.50281535
Validation score: -0.000031
Iteration 12, loss = 0.50284025
Validation score: -0.000295
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.9913524348687475, total=  50.7s
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.53636870
Validation score: 0.182644
Iteration 2, loss = 0.41502960
Validation score: 0.195948
Iteration 3, loss = 0.41097907
Validation score: 0.197815
Iteration 4, loss = 0.40926091
Validation score: 0.199898
Iteration 5, loss = 0.40822210
Validation score: 0.200914
Iteration 6, loss = 0.40754877
Validation score: 0.200095
Iteration 7, loss = 0.40698606
Validation score: 0.201067
Iteration 8, loss = 0.40654916
Validation score: 0.199296
Iteration 9, loss = 0.40614253
Validation score: 0.199666
Iteration 10, loss = 0.40577042
Validation score: 0.200934
Iteration 11, loss = 0.40519658
Validation score: 0.201344
Iteration 12, loss = 0.40521262
Validation score: 0.201573
Iteration 13, loss = 0.40468392
Validation score: 0.199609
Iteration 14, loss = 0.40427411
Validation score: 0.200804
Iteration 15, loss = 0.40380319
Validation score: 0.195565
Iteration 16, loss = 0.40374741
Validation score: 0.199593
Iteration 17, loss = 0.40338219
Validation score: 0.200593
Iteration 18, loss = 0.40311198
Validation score: 0.200102
Iteration 19, loss = 0.40298725
Validation score: 0.199815
Iteration 20, loss = 0.40267295
Validation score: 0.199764
Iteration 21, loss = 0.40262284
Validation score: 0.198827
Iteration 22, loss = 0.40223757
Validation score: 0.198070
Iteration 23, loss = 0.40194911
Validation score: 0.189545
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8016829877637893, total= 1.8min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.42232074
Validation score: 0.193215
Iteration 2, loss = 0.41430449
Validation score: 0.195388
Iteration 3, loss = 0.41396173
Validation score: 0.196560
Iteration 4, loss = 0.41325669
Validation score: 0.194994
Iteration 5, loss = 0.41328102
Validation score: 0.198945
Iteration 6, loss = 0.41255050
Validation score: 0.194202
Iteration 7, loss = 0.41276160
Validation score: 0.192277
Iteration 8, loss = 0.41240261
Validation score: 0.194128
Iteration 9, loss = 0.41241437
Validation score: 0.196167
Iteration 10, loss = 0.41226756
Validation score: 0.195164
Iteration 11, loss = 0.41187501
Validation score: 0.192719
Iteration 12, loss = 0.41193831
Validation score: 0.193991
Iteration 13, loss = 0.41204930
Validation score: 0.198767
Iteration 14, loss = 0.41196063
Validation score: 0.197887
Iteration 15, loss = 0.41202882
Validation score: 0.193325
Iteration 16, loss = 0.41205752
Validation score: 0.195866
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8051411035024241, total= 1.0min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.49606474
Validation score: 0.099319
Iteration 2, loss = 0.43062626
Validation score: 0.178971
Iteration 3, loss = 0.41465582
Validation score: 0.188883
Iteration 4, loss = 0.41158255
Validation score: 0.191727
Iteration 5, loss = 0.41026717
Validation score: 0.192989
Iteration 6, loss = 0.40945206
Validation score: 0.193879
Iteration 7, loss = 0.40885509
Validation score: 0.194679
Iteration 8, loss = 0.40831558
Validation score: 0.195317
Iteration 9, loss = 0.40778040
Validation score: 0.195955
Iteration 10, loss = 0.40738964
Validation score: 0.196453
Iteration 11, loss = 0.40694816
Validation score: 0.196627
Iteration 12, loss = 0.40647347
Validation score: 0.197119
Iteration 13, loss = 0.40610817
Validation score: 0.198029
Iteration 14, loss = 0.40570535
Validation score: 0.198101
Iteration 15, loss = 0.40536361
Validation score: 0.198945
Iteration 16, loss = 0.40501067
Validation score: 0.199137
Iteration 17, loss = 0.40473544
Validation score: 0.199212
Iteration 18, loss = 0.40438705
Validation score: 0.199403
Iteration 19, loss = 0.40419548
Validation score: 0.199647
Iteration 20, loss = 0.40392757
Validation score: 0.200149
Iteration 21, loss = 0.40372329
Validation score: 0.200371
Iteration 22, loss = 0.40354740
Validation score: 0.200389
Iteration 23, loss = 0.40340321
Validation score: 0.199921
Iteration 24, loss = 0.40325110
Validation score: 0.200590
Iteration 25, loss = 0.40312795
Validation score: 0.200763
Iteration 26, loss = 0.40298964
Validation score: 0.201116
Iteration 27, loss = 0.40285029
Validation score: 0.201032
Iteration 28, loss = 0.40272115
Validation score: 0.200727
Iteration 29, loss = 0.40262229
Validation score: 0.200782
Iteration 30, loss = 0.40250258
Validation score: 0.201235
Iteration 31, loss = 0.40241768
Validation score: 0.201050
Iteration 32, loss = 0.40233259
Validation score: 0.201211
Iteration 33, loss = 0.40224833
Validation score: 0.201111
Iteration 34, loss = 0.40212155
Validation score: 0.201054
Iteration 35, loss = 0.40207757
Validation score: 0.201387
Iteration 36, loss = 0.40197271
Validation score: 0.201230
Iteration 37, loss = 0.40185475
Validation score: 0.201465
Iteration 38, loss = 0.40178055
Validation score: 0.201281
Iteration 39, loss = 0.40171663
Validation score: 0.201133
Iteration 40, loss = 0.40164614
Validation score: 0.201170
Iteration 41, loss = 0.40156346
Validation score: 0.200981
Iteration 42, loss = 0.40148020
Validation score: 0.200910
Iteration 43, loss = 0.40140017
Validation score: 0.199999
Iteration 44, loss = 0.40136497
Validation score: 0.200830
Iteration 45, loss = 0.40124231
Validation score: 0.200991
Iteration 46, loss = 0.40122171
Validation score: 0.200667
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.8008264357544914, total= 3.6min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.44001865
Validation score: 0.182366
Iteration 2, loss = 0.41021552
Validation score: 0.187944
Iteration 3, loss = 0.40768879
Validation score: 0.190704
Iteration 4, loss = 0.40631708
Validation score: 0.191830
Iteration 5, loss = 0.40537583
Validation score: 0.191769
Iteration 6, loss = 0.40466968
Validation score: 0.191727
Iteration 7, loss = 0.40429803
Validation score: 0.191777
Iteration 8, loss = 0.40388402
Validation score: 0.191465
Iteration 9, loss = 0.40354740
Validation score: 0.192531
Iteration 10, loss = 0.40330688
Validation score: 0.192648
Iteration 11, loss = 0.40300512
Validation score: 0.192032
Iteration 12, loss = 0.40290264
Validation score: 0.192013
Iteration 13, loss = 0.40264238
Validation score: 0.191258
Iteration 14, loss = 0.40243426
Validation score: 0.191397
Iteration 15, loss = 0.40210121
Validation score: 0.192005
Iteration 16, loss = 0.40225739
Validation score: 0.191500
Iteration 17, loss = 0.40190117
Validation score: 0.191909
Iteration 18, loss = 0.40166481
Validation score: 0.191171
Iteration 19, loss = 0.40141744
Validation score: 0.192006
Iteration 20, loss = 0.40122222
Validation score: 0.191307
Iteration 21, loss = 0.40109678
Validation score: 0.190848
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.8010300384803509, total= 1.6min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.45320418
Validation score: 0.197793
Iteration 2, loss = 0.40931980
Validation score: 0.201389
Iteration 3, loss = 0.40770470
Validation score: 0.202223
Iteration 4, loss = 0.40716967
Validation score: 0.201294
Iteration 5, loss = 0.40642588
Validation score: 0.201718
Iteration 6, loss = 0.40602410
Validation score: 0.203771
Iteration 7, loss = 0.40540054
Validation score: 0.201946
Iteration 8, loss = 0.40534290
Validation score: 0.199996
Iteration 9, loss = 0.40505597
Validation score: 0.203963
Iteration 10, loss = 0.40473623
Validation score: 0.205674
Iteration 11, loss = 0.40482837
Validation score: 0.199770
Iteration 12, loss = 0.40428158
Validation score: 0.202047
Iteration 13, loss = 0.40433995
Validation score: 0.205469
Iteration 14, loss = 0.40395819
Validation score: 0.205682
Iteration 15, loss = 0.40388708
Validation score: 0.205763
Iteration 16, loss = 0.40376361
Validation score: 0.203318
Iteration 17, loss = 0.40352183
Validation score: 0.203946
Iteration 18, loss = 0.40346594
Validation score: 0.204481
Iteration 19, loss = 0.40326128
Validation score: 0.203069
Iteration 20, loss = 0.40327105
Validation score: 0.206581
Iteration 21, loss = 0.40305883
Validation score: 0.205331
Iteration 22, loss = 0.40299173
Validation score: 0.202035
Iteration 23, loss = 0.40306172
Validation score: 0.205546
Iteration 24, loss = 0.40300325
Validation score: 0.205343
Iteration 25, loss = 0.40247057
Validation score: 0.205993
Iteration 26, loss = 0.40264674
Validation score: 0.204452
Iteration 27, loss = 0.40259606
Validation score: 0.206272
Iteration 28, loss = 0.40259614
Validation score: 0.203099
Iteration 29, loss = 0.40280906
Validation score: 0.204802
Iteration 30, loss = 0.40241233
Validation score: 0.202599
Iteration 31, loss = 0.40260262
Validation score: 0.205483
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.7995745181973122, total= 2.2min
12
Input read.
(540304, 25)
(540304, 525)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.47845293
Validation score: 0.156289
Iteration 2, loss = 0.41667113
Validation score: 0.187001
Iteration 3, loss = 0.41074789
Validation score: 0.190253
Iteration 4, loss = 0.40932103
Validation score: 0.191710
Iteration 5, loss = 0.40854881
Validation score: 0.192599
Iteration 6, loss = 0.40796958
Validation score: 0.193530
Iteration 7, loss = 0.40743813
Validation score: 0.194314
Iteration 8, loss = 0.40696518
Validation score: 0.195133
Iteration 9, loss = 0.40651980
Validation score: 0.195752
Iteration 10, loss = 0.40605343
Validation score: 0.196474
Iteration 11, loss = 0.40557392
Validation score: 0.196592
Iteration 12, loss = 0.40515484
Validation score: 0.197577
Iteration 13, loss = 0.40471412
Validation score: 0.198479
Iteration 14, loss = 0.40427904
Validation score: 0.198539
Iteration 15, loss = 0.40393848
Validation score: 0.199288
Iteration 16, loss = 0.40353622
Validation score: 0.199701
Iteration 17, loss = 0.40324569
Validation score: 0.199633
Iteration 18, loss = 0.40299910
Validation score: 0.200128
Iteration 19, loss = 0.40275289
Validation score: 0.200067
Iteration 20, loss = 0.40252185
Validation score: 0.201039
Iteration 21, loss = 0.40238588
Validation score: 0.201184
Iteration 22, loss = 0.40222635
Validation score: 0.201131
Iteration 23, loss = 0.40207865
Validation score: 0.201152
Iteration 24, loss = 0.40192399
Validation score: 0.200063
Iteration 25, loss = 0.40181944
Validation score: 0.201268
Iteration 26, loss = 0.40170395
Validation score: 0.201168
Iteration 27, loss = 0.40163827
Validation score: 0.201238
Iteration 28, loss = 0.40152308
Validation score: 0.200964
Iteration 29, loss = 0.40141353
Validation score: 0.201149
Iteration 30, loss = 0.40135318
Validation score: 0.201116
Iteration 31, loss = 0.40124634
Validation score: 0.201318
Iteration 32, loss = 0.40118389
Validation score: 0.201099
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.000125
0.20486025931386442
[[0.16235483 0.18544949 0.20512832 0.1962494  0.22103002 0.22679117
  0.22656331 0.18377919 0.21768474 0.16080765 0.12195116 0.15249209
  0.19041938 0.20622823 0.3205523  0.20960852 0.26972568 0.2163138
  0.21586481 0.26445932 0.2443708 ]
 [0.2162018  0.23957566 0.21491458 0.22729827 0.2184166  0.20243214
  0.19765202 0.23771746 0.18470688 0.1492114  0.22253635 0.18289997
  0.18914074 0.30970001 0.31677218 0.19932686 0.33260986 0.28087094
  0.19334082 0.21467356 0.2136852 ]
 [0.23555752 0.18398996 0.2417815  0.22537877 0.20625667 0.24901746
  0.19753631 0.23413012 0.19526955 0.19390013 0.22058638 0.24975067
  0.22929802 0.2725897  0.38338362 0.27726023 0.28014403 0.41522873
  0.18395412 0.27904628 0.24308854]
 [0.32808367 0.38962623 0.30640511 0.20261883 0.29305675 0.20745904
  0.30339059 0.33257591 0.36355154 0.31296448 0.35311128 0.27908376
  0.25840793 0.47195289 0.50159545 0.37130685 0.3696961  0.78641206
  0.33145887 0.36647603 0.2766587 ]
 [0.34442326 0.28234409 0.3632346  0.2792714  0.28158917 0.31434003
  0.3693865  0.29258861 0.306538   0.29460541 0.30251477 0.30544319
  0.31226075 0.36986581 0.53714434 0.41458547 0.25142707 0.67892092
  0.373559   0.32095812 0.25701021]
 [0.24642958 0.17703314 0.23769841 0.19279198 0.14245178 0.16930556
  0.24846287 0.20491659 0.2035125  0.2870622  0.22166844 0.24673459
  0.1679898  0.24409519 0.28744787 0.25467255 0.18991408 0.65045473
  0.22122683 0.27322219 0.1768307 ]
 [0.16313262 0.19793312 0.18590672 0.24300671 0.18897714 0.21554689
  0.19845217 0.20315496 0.21818155 0.2182989  0.20200434 0.2293371
  0.21456209 0.24271337 0.32090463 0.22766774 0.2754478  0.35820702
  0.21945345 0.24991353 0.17978416]
 [0.21651351 0.26244476 0.15438742 0.18574102 0.2319835  0.24045609
  0.22513088 0.21181417 0.18301379 0.22813872 0.20447717 0.19881614
  0.22946911 0.22755274 0.26394489 0.23134099 0.2511995  0.27148193
  0.2300486  0.29006093 0.19144346]]
[array([[-1.49122045e-316, -3.50192879e-001,  2.26489400e-001,
        -1.72737698e-258, -2.34643633e-318, -2.39414513e-001,
        -5.30785084e-001, -1.57453471e-001],
       [-3.10387078e-316,  3.23323942e-001,  3.22418960e-001,
        -5.09352811e-207, -3.61737055e-316,  3.74749344e-001,
         5.96032772e-001,  4.82530676e-001],
       [ 1.29043712e-316, -5.02721860e-001,  5.17424089e-001,
        -6.20777824e-269, -1.50099297e-316, -3.64923543e-001,
        -2.95544121e-001, -3.65806387e-001],
       [-2.86523614e-316,  1.11972982e-001, -2.59415628e-002,
        -1.41922655e-212,  8.55272099e-317,  4.43592722e-001,
        -5.40027663e-002,  1.86335656e-001],
       [ 1.35860652e-316, -3.35981577e-001, -2.28977159e-001,
        -1.57705815e-187,  1.79127749e-317, -6.91538739e-002,
         4.14312001e-001,  6.71586862e-001],
       [-8.93496278e-317, -3.67228686e-001, -1.45989543e-001,
        -2.26655573e-211,  2.34244146e-316, -5.39663784e-001,
        -1.11218054e-001,  1.34842560e-001],
       [-3.04102746e-316,  1.53259408e-001,  1.11994310e-002,
         2.46178627e-198,  2.51117125e-316,  4.83350277e-001,
         1.12106880e-001,  1.03350942e-001],
       [-3.88233622e-317,  6.67667662e-002,  1.79299305e-001,
         3.00399294e-247, -3.06478851e-317,  3.23414718e-001,
         5.06156298e-002, -4.72668630e-001]]), array([[ 7.63014183e-317, -1.77064071e-316, -1.17151413e-317,
         2.12486483e-316, -1.56498525e-316,  1.62279962e-317,
        -4.66228011e-317,  2.17439180e-317],
       [ 2.40647942e-001,  2.98010084e-001, -9.94629813e-002,
        -6.48643565e-003, -1.62745444e-002,  4.36871612e-001,
        -3.82957411e-316, -1.46177521e-001],
       [-4.18822294e-001, -6.45106077e-002, -5.22017737e-002,
        -1.73663473e-002, -7.67312772e-002,  3.22722240e-001,
         9.59900035e-317,  2.39824166e-001],
       [-2.56472052e-249, -7.24514859e-293,  2.98452665e-316,
        -2.61902568e-317, -7.10837665e-314, -4.22685355e-305,
         1.67571242e-316, -4.79925816e-295],
       [ 3.00147795e-316, -3.55386024e-316, -2.00713551e-316,
        -9.92218203e-318,  1.65782161e-316, -2.46284081e-316,
         9.76264527e-317,  2.24949670e-317],
       [ 5.43466851e-001,  5.29922664e-001,  2.90966730e-001,
        -3.04596300e-001, -4.18284950e-001,  3.49814298e-001,
         1.53843549e-316, -1.06136987e-001],
       [ 5.02329623e-001,  3.09283861e-001,  5.04153995e-001,
         1.95305915e-002,  4.94613830e-004,  6.94452030e-001,
         1.14053024e-316,  4.60576479e-001],
       [-5.48043422e-001,  3.62914217e-002,  6.73010750e-001,
         1.06235888e-001,  2.70737151e-002, -1.31077736e-001,
         6.40403345e-317,  1.01413641e-001]]), array([[ 3.05464633e-317, -1.71982311e-003,  7.16014441e-001,
         5.91495009e-002, -1.51710585e-001,  6.18215790e-002,
         2.09551585e-316, -4.47332196e-001],
       [ 1.07126984e-316, -7.43279840e-003,  5.54746522e-001,
        -1.55103529e-002,  1.63582814e-001, -1.98985103e-002,
         1.47948501e-317, -1.63734263e-002],
       [-7.31472736e-317, -1.24173127e-001,  6.29426334e-001,
        -6.87876925e-002,  3.20113973e-001, -5.93063646e-002,
         8.48298560e-317,  2.34069056e-001],
       [-2.78270627e-316, -6.74600113e-003, -2.18056438e-001,
        -7.43546924e-003,  1.34927104e-001, -7.30869355e-003,
         7.93468241e-317, -3.63834958e-002],
       [-3.13655807e-316, -1.43690868e-002,  5.29660206e-002,
        -1.66269926e-002,  2.19090349e-001, -1.61127972e-002,
         6.60296700e-317,  2.69658871e-001],
       [-2.33636129e-316,  1.84813386e-002,  2.69046743e-001,
         4.47438926e-003,  5.88922538e-002,  3.04807047e-003,
        -2.98716091e-317, -3.29222788e-001],
       [-2.79567115e-316, -6.50271417e-318, -3.31060015e-316,
         6.33300904e-317, -1.84304223e-317, -6.20801834e-317,
         1.17814904e-316,  2.05441171e-316],
       [-4.14534713e-317, -3.32815042e-002,  1.09221267e-001,
        -2.25421889e-002, -5.74245160e-001, -2.03369752e-002,
         2.05280585e-316, -1.82031579e-001]]), array([[ 3.89734174e-316, -1.65946077e-317,  2.03631028e-316,
         2.20297893e-317, -3.60266631e-316,  1.97301361e-317,
         8.04730913e-317,  2.75586008e-316],
       [ 1.31767747e-001,  3.34986068e-316,  8.17774703e-002,
        -1.08636270e-001, -7.89331726e-317,  7.76361698e-002,
        -1.96275827e-101, -6.33351831e-003],
       [ 6.34401793e-001, -1.54821597e-316,  3.91211498e-001,
        -1.94988783e-001, -3.61841209e-316, -2.62295250e-001,
         1.22049989e-001, -3.74772841e-001],
       [ 1.19237132e-001, -1.73995691e-316,  8.59068180e-002,
        -1.14220103e-001,  4.36688814e-318,  6.94021859e-002,
        -1.58792376e-066, -9.89041865e-003],
       [-2.82469010e-001, -1.25185365e-316,  4.97190178e-001,
         6.59374679e-001,  2.51929330e-316,  2.10567659e-001,
         1.84796729e-002,  2.98410202e-001],
       [ 1.16059660e-001, -7.48185346e-317,  8.47486040e-002,
        -1.12810638e-001, -8.92823756e-317,  6.67992760e-002,
         2.15583527e-068, -8.63163104e-003],
       [ 3.88846363e-317,  3.10740671e-316, -3.24282165e-316,
        -5.16307691e-317,  2.60033078e-316, -2.49636005e-317,
         2.74957364e-317, -4.27537434e-317],
       [-3.49532565e-001,  8.74156029e-317,  8.87088944e-002,
         5.08494426e-001,  1.44428634e-316,  4.65040486e-002,
        -6.51071561e-002,  3.72202802e-001]]), array([[-1.83584280e-316,  1.93410685e-001,  3.62013535e-001,
         2.03121252e-316,  3.15685055e-001, -2.78016633e-002,
        -2.63604032e-316,  6.49256441e-001],
       [-3.12518374e-316,  1.91752979e-316, -5.28200691e-317,
        -8.18250377e-317, -1.56189269e-316, -9.14279446e-317,
        -3.84157551e-316,  2.87705675e-316],
       [-9.66789731e-317,  3.15400315e-001,  4.79701980e-001,
        -3.44052741e-317,  5.25628955e-001,  9.07235351e-002,
         1.15878601e-317,  9.06827288e-002],
       [-3.09599814e-317, -3.33141920e-001, -6.90909150e-001,
        -1.14811849e-316, -3.01333662e-002, -1.15472884e-001,
         9.76937246e-318, -3.98789460e-001],
       [-1.35255861e-316,  3.45269541e-316,  2.60691564e-316,
         2.31412167e-316, -2.11733498e-316,  7.32841693e-317,
        -2.09331316e-316,  1.33224890e-316],
       [-7.15782940e-317, -3.04399278e-001,  7.74941820e-002,
         5.60128349e-317,  2.26142711e-002, -6.67132424e-002,
         5.72291998e-317,  4.85743276e-001],
       [-2.26727382e-316,  1.58808387e-001,  1.90805722e-001,
         1.54121046e-316, -8.14685605e-002,  8.42914456e-002,
        -1.70190526e-316,  2.10317589e-001],
       [ 1.41190745e-316,  2.45477283e-002, -3.27718151e-001,
         3.25344748e-317,  2.65956472e-002, -1.36848414e-001,
         1.14859467e-316,  1.58524025e-002]]), array([[ 3.05619167e-316,  1.75247387e-316,  1.65424265e-316,
         2.47741422e-316, -1.16133045e-317,  9.29188519e-317,
         3.91928883e-316,  8.79588281e-317],
       [ 1.53153852e-001,  6.61904127e-001, -9.53451389e-311,
         3.86611160e-001,  2.75031231e-001,  1.88061355e-316,
         1.63921657e-001,  2.73154765e-002],
       [ 4.34769930e-001,  5.96611483e-001,  4.36575538e-288,
        -5.85841863e-001,  7.69596446e-002,  3.29003897e-316,
        -2.48740449e-001,  1.09273377e-001],
       [ 3.93096760e-317, -5.46867726e-317, -3.55332902e-317,
        -3.53653266e-316,  1.54533408e-317,  1.79824050e-316,
         2.84584875e-317,  6.03743032e-317],
       [ 2.47916178e-001,  2.09688871e-001,  1.94758103e-277,
         4.27541994e-001,  1.90331383e-001, -2.20320314e-316,
         4.96885169e-001,  1.64843749e-001],
       [ 1.12824216e-001,  2.38487610e-001, -8.82193835e-317,
         4.57272509e-001,  8.63854299e-002,  2.08089492e-316,
        -2.18827814e-001, -3.67741273e-001],
       [-3.56700327e-316,  8.46127586e-317, -1.85641683e-316,
         9.71468977e-317, -4.31408092e-317,  2.08600153e-316,
        -2.05893059e-316, -1.20296092e-317],
       [ 3.25001342e-001,  7.33292753e-001,  5.61053281e-304,
        -4.87428212e-001, -1.40903699e-001,  1.24392563e-316,
        -5.66104017e-001, -1.22545525e-002]]), array([[-1.29271581e-001, -2.04202796e-002,  2.43267009e-001,
        -5.84887426e-001,  8.63633511e-003, -5.21250669e-317,
        -3.32650699e-316,  4.43530240e-317],
       [ 6.42979037e-001, -2.25305336e-001,  6.00156064e-001,
         1.19742717e-001, -1.65044496e-001,  2.77513630e-316,
        -6.59129124e-317, -2.02461931e-316],
       [ 2.73202877e-316,  2.60927629e-316, -1.37657637e-316,
        -2.20864379e-316, -2.88636139e-316, -1.42003972e-316,
         4.35460962e-317, -5.18392302e-317],
       [-3.39288239e-001,  2.40202167e-002, -1.03602040e-001,
         5.93718440e-001,  1.45633946e-002,  2.34999157e-316,
         2.09648560e-316, -3.18942052e-316],
       [-5.48950354e-003, -1.11191608e-001,  2.15330369e-002,
         4.29519255e-001, -8.50273445e-003,  5.10194913e-317,
        -2.21197641e-316,  3.55506462e-316],
       [-4.87940220e-317, -3.64860731e-316, -1.77287053e-316,
         5.54452424e-317, -6.01665980e-317,  1.31993540e-317,
         7.51245589e-318,  8.89337135e-317],
       [-3.83783455e-001, -2.09111435e-001,  3.13275349e-001,
         6.71143257e-001, -2.27814590e-002, -3.02723809e-316,
        -4.08960516e-317, -8.46405597e-317],
       [-1.49929315e-001, -2.37332638e-001, -4.05661286e-001,
         8.99458124e-002,  1.25671345e-002,  2.60817156e-317,
        -2.69644212e-316,  6.86903469e-317]]), array([[ 7.72406731e-001],
       [-1.62129498e-001],
       [ 5.30447220e-001],
       [-2.83930025e-001],
       [-8.14063499e-002],
       [ 1.64547921e-316],
       [ 2.97271414e-316],
       [-1.18927668e-316]])]
[-0.05464779  0.10337628  0.01177039  0.09761479 -0.01137227  0.10659083
  0.0302085   0.03588991]
TRAIN
Mean PCC: 0.4794893900787057 +- 0.4433352513712717
PCC: Min: -0.07584269485459309 Max: 0.8811478230474148
Mean MSE: 0.7759666694957259 +- 0.43948410937465765
MSE: Min: 0.2823105942159756 Max: 1.4153335661405124
MSE:
ArgMin: [('6c4q', 85), ('4hlb', 95), ('5aiz', 110), ('4rgi', 71), ('3o2e', 86), ('5w0h', 80), ('5i29', 139), ('2huj', 125), ('2yvi', 89), ('3bv8', 85)]
ArgMax: [('4aqo', 86), ('3dt5', 119), ('2pne', 81), ('1j0p', 108), ('5v0m', 98), ('1jni', 62), ('5dbl', 130), ('2a3m', 107), ('2w9y', 136), ('1sau', 114)]
PCC:
ArgMin: [('3dt5', 119), ('1lmi', 131), ('4aqo', 86), ('2nwf', 141), ('2h5c', 198), ('2pne', 81), ('5nuv', 301), ('2uyq', 274), ('3zfp', 148), ('2w9y', 136)]
ArgMax: [('4hlb', 95), ('6c4q', 85), ('5w0h', 80), ('3bv8', 85), ('5aiz', 110), ('2huj', 125), ('5zt3', 114), ('2p0h', 118), ('5i29', 139), ('1xmt', 95)]
MSE vs Length correlation: 0.04892644312869476
PCC vs Length correlation: 0.0711913556818431
MSE vs b-val mean correlation: 9.739995464608242e-07
PCC vs b-val mean correlation: 5.128022284917044e-06
VAL
Mean PCC: 0.4809505431539687 +- 0.4321420193669648
PCC: Min: 0.008644859739801575 Max: 0.8657288073899673
Mean MSE: 0.7740036430863275 +- 0.42138399731176046
MSE: Min: 0.2983903203158025 Max: 1.3576787047375076
MSE:
ArgMin: [('2vc8', 72), ('3mao', 105), ('5ijm', 98), ('2i5u', 77), ('5hqh', 96), ('4i6x', 117), ('4gos', 115), ('4zc3', 57), ('2b1k', 149), ('3tbn', 87)]
ArgMax: [('2rkn', 77), ('3fgh', 67), ('2rbk', 261), ('1u5p', 211), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('3s9x', 159), ('3cao', 102), ('3zt9', 192)]
PCC:
ArgMin: [('2rbk', 261), ('2rkn', 77), ('3gvo', 342), ('1u5p', 211), ('3sw0', 186), ('2v9k', 467), ('5hfg', 205), ('3s9x', 159), ('4rep', 489), ('3zt9', 192)]
ArgMax: [('2vc8', 72), ('5hqh', 96), ('3mao', 105), ('4i6x', 117), ('5ijm', 98), ('2i5u', 77), ('4gos', 115), ('3tbn', 87), ('2b1k', 149), ('4zc3', 57)]
MSE vs Length correlation: 0.06406805251389602
PCC vs Length correlation: 0.08687223925364573
MSE vs b-val mean correlation: 0.0020292223998059633
PCC vs b-val mean correlation: 0.0020257702174745207
TEST
Mean PCC: 0.4721113213223839 +- 0.44591199725375663
PCC: Min: -0.06624570581897585 Max: 0.8516388457930137
Mean MSE: 0.7828904864089498 +- 0.4378267008137985
MSE: Min: 0.34994624361963894 Max: 1.4044375606792994
MSE:
ArgMin: [('2od5', 91), ('4qq6', 58), ('3o70', 55), ('3cp0', 63), ('5ol9', 81), ('3t7l', 74), ('5kuj', 95), ('3chm', 161), ('2ovg', 58), ('1tzv', 141)]
ArgMax: [('4npn', 71), ('5i8g', 226), ('4gs3', 90), ('3b6e', 182), ('2vac', 134), ('4xxt', 221), ('4qdn', 118), ('2c4x', 250), ('3zr8', 65), ('4uyr', 188)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('1r5y', 361), ('2vac', 134), ('3ip0', 158), ('4r1b', 282), ('4uyr', 188), ('4gs3', 90), ('4qdn', 118)]
ArgMax: [('3cp0', 63), ('4qq6', 58), ('2od5', 91), ('5ol9', 81), ('3t7l', 74), ('5kuj', 95), ('1mud', 225), ('4rwu', 81), ('3o70', 55), ('3chm', 161)]
MSE vs Length correlation: 0.0464466785562021
PCC vs Length correlation: 0.06112803253204102
MSE vs b-val mean correlation: 1.710039346691783e-05
PCC vs b-val mean correlation: 1.1898056691439507e-05
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.42559943
Validation score: 0.184944
Iteration 2, loss = 0.40841159
Validation score: 0.188228
Iteration 3, loss = 0.40649567
Validation score: 0.189698
Iteration 4, loss = 0.40512334
Validation score: 0.189890
Iteration 5, loss = 0.40415551
Validation score: 0.190606
Iteration 6, loss = 0.40353098
Validation score: 0.191531
Iteration 7, loss = 0.40316875
Validation score: 0.192057
Iteration 8, loss = 0.40282976
Validation score: 0.192601
Iteration 9, loss = 0.40229278
Validation score: 0.191380
Iteration 10, loss = 0.40196933
Validation score: 0.189303
Iteration 11, loss = 0.40169408
Validation score: 0.191043
Iteration 12, loss = 0.40150315
Validation score: 0.191369
Iteration 13, loss = 0.40106886
Validation score: 0.187986
Iteration 14, loss = 0.40089910
Validation score: 0.191543
Iteration 15, loss = 0.40061956
Validation score: 0.190883
Iteration 16, loss = 0.40053560
Validation score: 0.189636
Iteration 17, loss = 0.40026729
Validation score: 0.191635
Iteration 18, loss = 0.40000262
Validation score: 0.191640
Iteration 19, loss = 0.39981205
Validation score: 0.190197
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8008015881295065, total= 1.4min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.42405158
Validation score: 0.193443
Iteration 2, loss = 0.40950411
Validation score: 0.196359
Iteration 3, loss = 0.40819364
Validation score: 0.196050
Iteration 4, loss = 0.40771858
Validation score: 0.195506
Iteration 5, loss = 0.40692800
Validation score: 0.189022
Iteration 6, loss = 0.40630500
Validation score: 0.195143
Iteration 7, loss = 0.40607659
Validation score: 0.197735
Iteration 8, loss = 0.40548965
Validation score: 0.196702
Iteration 9, loss = 0.40507939
Validation score: 0.198639
Iteration 10, loss = 0.40513279
Validation score: 0.197383
Iteration 11, loss = 0.40474483
Validation score: 0.195037
Iteration 12, loss = 0.40463688
Validation score: 0.194840
Iteration 13, loss = 0.40428801
Validation score: 0.196813
Iteration 14, loss = 0.40421515
Validation score: 0.194275
Iteration 15, loss = 0.40405867
Validation score: 0.195869
Iteration 16, loss = 0.40376181
Validation score: 0.194098
Iteration 17, loss = 0.40380116
Validation score: 0.196420
Iteration 18, loss = 0.40376211
Validation score: 0.197450
Iteration 19, loss = 0.40356650
Validation score: 0.191865
Iteration 20, loss = 0.40375195
Validation score: 0.192373
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8015778392831646, total= 1.5min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.45087540
Validation score: 0.191080
Iteration 2, loss = 0.41223664
Validation score: 0.194471
Iteration 3, loss = 0.41021749
Validation score: 0.198363
Iteration 4, loss = 0.40837598
Validation score: 0.201710
Iteration 5, loss = 0.40702055
Validation score: 0.201452
Iteration 6, loss = 0.40604700
Validation score: 0.203392
Iteration 7, loss = 0.40528842
Validation score: 0.204267
Iteration 8, loss = 0.40483941
Validation score: 0.204470
Iteration 9, loss = 0.40443780
Validation score: 0.204594
Iteration 10, loss = 0.40396672
Validation score: 0.204238
Iteration 11, loss = 0.40374477
Validation score: 0.204827
Iteration 12, loss = 0.40345234
Validation score: 0.204316
Iteration 13, loss = 0.40323690
Validation score: 0.204091
Iteration 14, loss = 0.40298071
Validation score: 0.204142
Iteration 15, loss = 0.40282133
Validation score: 0.202880
Iteration 16, loss = 0.40269274
Validation score: 0.204484
Iteration 17, loss = 0.40244742
Validation score: 0.203755
Iteration 18, loss = 0.40219967
Validation score: 0.202617
Iteration 19, loss = 0.40207411
Validation score: 0.201093
Iteration 20, loss = 0.40193343
Validation score: 0.203099
Iteration 21, loss = 0.40177761
Validation score: 0.204346
Iteration 22, loss = 0.40157815
Validation score: 0.204276
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.7992695392058424, total= 1.7min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.43109450
Validation score: 0.177111
Iteration 2, loss = 0.41540452
Validation score: 0.189865
Iteration 3, loss = 0.41237407
Validation score: 0.192278
Iteration 4, loss = 0.41173727
Validation score: 0.190821
Iteration 5, loss = 0.41139710
Validation score: 0.185860
Iteration 6, loss = 0.41059696
Validation score: 0.193515
Iteration 7, loss = 0.41017026
Validation score: 0.189996
Iteration 8, loss = 0.41030262
Validation score: 0.194690
Iteration 9, loss = 0.40978843
Validation score: 0.193720
Iteration 10, loss = 0.40940238
Validation score: 0.184196
Iteration 11, loss = 0.40944107
Validation score: 0.192300
Iteration 12, loss = 0.40927188
Validation score: 0.198014
Iteration 13, loss = 0.40919482
Validation score: 0.192793
Iteration 14, loss = 0.40946107
Validation score: 0.195014
Iteration 15, loss = 0.40902225
Validation score: 0.194341
Iteration 16, loss = 0.40899427
Validation score: 0.189225
Iteration 17, loss = 0.40917647
Validation score: 0.192903
Iteration 18, loss = 0.40907338
Validation score: 0.193818
Iteration 19, loss = 0.40898272
Validation score: 0.193869
Iteration 20, loss = 0.40868038
Validation score: 0.193413
Iteration 21, loss = 0.40868200
Validation score: 0.192955
Iteration 22, loss = 0.40867423
Validation score: 0.189051
Iteration 23, loss = 0.40853048
Validation score: 0.187669
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.802103955198636, total= 1.7min
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.46074376
Validation score: 0.156634
Iteration 2, loss = 0.42248194
Validation score: 0.168438
Iteration 3, loss = 0.41480085
Validation score: 0.181059
Iteration 4, loss = 0.40977337
Validation score: 0.186274
Iteration 5, loss = 0.40773697
Validation score: 0.187750
Iteration 6, loss = 0.40669517
Validation score: 0.187750
Iteration 7, loss = 0.40592195
Validation score: 0.189561
Iteration 8, loss = 0.40533203
Validation score: 0.189692
Iteration 9, loss = 0.40492055
Validation score: 0.189620
Iteration 10, loss = 0.40456525
Validation score: 0.189883
Iteration 11, loss = 0.40433525
Validation score: 0.190517
Iteration 12, loss = 0.40398612
Validation score: 0.190765
Iteration 13, loss = 0.40368306
Validation score: 0.190794
Iteration 14, loss = 0.40353908
Validation score: 0.191238
Iteration 15, loss = 0.40329663
Validation score: 0.190447
Iteration 16, loss = 0.40321138
Validation score: 0.190785
Iteration 17, loss = 0.40303022
Validation score: 0.190069
Iteration 18, loss = 0.40289353
Validation score: 0.190186
Iteration 19, loss = 0.40275695
Validation score: 0.189398
Iteration 20, loss = 0.40265585
Validation score: 0.190469
Iteration 21, loss = 0.40246409
Validation score: 0.190354
Iteration 22, loss = 0.40236498
Validation score: 0.190374
Iteration 23, loss = 0.40224895
Validation score: 0.189881
Iteration 24, loss = 0.40207962
Validation score: 0.189582
Iteration 25, loss = 0.40202301
Validation score: 0.190139
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.7994770223860561, total= 1.9min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.42782514
Validation score: 0.187629
Iteration 2, loss = 0.41644519
Validation score: 0.190125
Iteration 3, loss = 0.41546930
Validation score: 0.194717
Iteration 4, loss = 0.41538334
Validation score: 0.192442
Iteration 5, loss = 0.41511577
Validation score: 0.194769
Iteration 6, loss = 0.41449639
Validation score: 0.194526
Iteration 7, loss = 0.41453640
Validation score: 0.192044
Iteration 8, loss = 0.41423622
Validation score: 0.194481
Iteration 9, loss = 0.41422412
Validation score: 0.193427
Iteration 10, loss = 0.41368321
Validation score: 0.191880
Iteration 11, loss = 0.41389517
Validation score: 0.192452
Iteration 12, loss = 0.41378338
Validation score: 0.192780
Iteration 13, loss = 0.41308635
Validation score: 0.196449
Iteration 14, loss = 0.41269181
Validation score: 0.198057
Iteration 15, loss = 0.41245130
Validation score: 0.195145
Iteration 16, loss = 0.41233898
Validation score: 0.194168
Iteration 17, loss = 0.41225202
Validation score: 0.194790
Iteration 18, loss = 0.41179980
Validation score: 0.190804
Iteration 19, loss = 0.41203918
Validation score: 0.194456
Iteration 20, loss = 0.41196553
Validation score: 0.194850
Iteration 21, loss = 0.41186165
Validation score: 0.197617
Iteration 22, loss = 0.41168337
Validation score: 0.192734
Iteration 23, loss = 0.41165760
Validation score: 0.195853
Iteration 24, loss = 0.41161158
Validation score: 0.194987
Iteration 25, loss = 0.41161920
Validation score: 0.192326
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8041578012304805, total= 1.6min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.60323413
Validation score: 0.024680
Iteration 2, loss = 0.46832654
Validation score: 0.137817
Iteration 3, loss = 0.42306018
Validation score: 0.178571
Iteration 4, loss = 0.41472310
Validation score: 0.184398
Iteration 5, loss = 0.41294644
Validation score: 0.186098
Iteration 6, loss = 0.41215692
Validation score: 0.187274
Iteration 7, loss = 0.41176099
Validation score: 0.187527
Iteration 8, loss = 0.41143903
Validation score: 0.187753
Iteration 9, loss = 0.41123137
Validation score: 0.188233
Iteration 10, loss = 0.41101887
Validation score: 0.188350
Iteration 11, loss = 0.41083416
Validation score: 0.188542
Iteration 12, loss = 0.41066916
Validation score: 0.188622
Iteration 13, loss = 0.41045041
Validation score: 0.189162
Iteration 14, loss = 0.41020679
Validation score: 0.189420
Iteration 15, loss = 0.40998504
Validation score: 0.189935
Iteration 16, loss = 0.40973548
Validation score: 0.190224
Iteration 17, loss = 0.40953130
Validation score: 0.190868
Iteration 18, loss = 0.40925326
Validation score: 0.191117
Iteration 19, loss = 0.40902153
Validation score: 0.191405
Iteration 20, loss = 0.40882222
Validation score: 0.191887
Iteration 21, loss = 0.40859371
Validation score: 0.191605
Iteration 22, loss = 0.40835226
Validation score: 0.192025
Iteration 23, loss = 0.40814315
Validation score: 0.192677
Iteration 24, loss = 0.40796281
Validation score: 0.192900
Iteration 25, loss = 0.40774658
Validation score: 0.193213
Iteration 26, loss = 0.40750546
Validation score: 0.193311
Iteration 27, loss = 0.40733556
Validation score: 0.193725
Iteration 28, loss = 0.40711638
Validation score: 0.193967
Iteration 29, loss = 0.40696450
Validation score: 0.194113
Iteration 30, loss = 0.40674824
Validation score: 0.194141
Iteration 31, loss = 0.40651733
Validation score: 0.194703
Iteration 32, loss = 0.40633677
Validation score: 0.194879
Iteration 33, loss = 0.40618752
Validation score: 0.194892
Iteration 34, loss = 0.40596552
Validation score: 0.195169
Iteration 35, loss = 0.40576689
Validation score: 0.195607
Iteration 36, loss = 0.40556624
Validation score: 0.195860
Iteration 37, loss = 0.40536060
Validation score: 0.195976
Iteration 38, loss = 0.40516808
Validation score: 0.196427
Iteration 39, loss = 0.40490779
Validation score: 0.196654
Iteration 40, loss = 0.40468520
Validation score: 0.196785
Iteration 41, loss = 0.40448432
Validation score: 0.197262
Iteration 42, loss = 0.40427910
Validation score: 0.197528
Iteration 43, loss = 0.40402386
Validation score: 0.197854
Iteration 44, loss = 0.40385780
Validation score: 0.197944
Iteration 45, loss = 0.40362339
Validation score: 0.198026
Iteration 46, loss = 0.40348503
Validation score: 0.198282
Iteration 47, loss = 0.40333388
Validation score: 0.198283
Iteration 48, loss = 0.40316269
Validation score: 0.198442
Iteration 49, loss = 0.40303955
Validation score: 0.198700
Iteration 50, loss = 0.40290028
Validation score: 0.198917
Iteration 51, loss = 0.40275244
Validation score: 0.198926
Iteration 52, loss = 0.40264752
Validation score: 0.198765
Iteration 53, loss = 0.40253761
Validation score: 0.198976
Iteration 54, loss = 0.40244319
Validation score: 0.199006
Iteration 55, loss = 0.40231537
Validation score: 0.199026
Iteration 56, loss = 0.40227886
Validation score: 0.199034
Iteration 57, loss = 0.40217649
Validation score: 0.199165
Iteration 58, loss = 0.40210983
Validation score: 0.199027
Iteration 59, loss = 0.40206000
Validation score: 0.198892
Iteration 60, loss = 0.40198142
Validation score: 0.199020
Iteration 61, loss = 0.40190604
Validation score: 0.198829
Iteration 62, loss = 0.40185783
Validation score: 0.198967
Iteration 63, loss = 0.40182226
Validation score: 0.199093
Iteration 64, loss = 0.40176690
Validation score: 0.198922
Iteration 65, loss = 0.40168864
Validation score: 0.198761
Iteration 66, loss = 0.40160666
Validation score: 0.198974
Iteration 67, loss = 0.40159869
Validation score: 0.198947
Iteration 68, loss = 0.40152137
Validation score: 0.198692
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.7990279409314085, total= 5.5min
13
Input read.
(540304, 27)
(540304, 567)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.41960186
Validation score: 0.193632
Iteration 2, loss = 0.40759601
Validation score: 0.192803
Iteration 3, loss = 0.40670402
Validation score: 0.185910
Iteration 4, loss = 0.40616632
Validation score: 0.195996
Iteration 5, loss = 0.40587605
Validation score: 0.195688
Iteration 6, loss = 0.40528643
Validation score: 0.196634
Iteration 7, loss = 0.40525108
Validation score: 0.196614
Iteration 8, loss = 0.40505724
Validation score: 0.194761
Iteration 9, loss = 0.40467692
Validation score: 0.196533
Iteration 10, loss = 0.40456839
Validation score: 0.189096
Iteration 11, loss = 0.40444127
Validation score: 0.196711
Iteration 12, loss = 0.40404992
Validation score: 0.196731
Iteration 13, loss = 0.40374579
Validation score: 0.196447
Iteration 14, loss = 0.40348049
Validation score: 0.197973
Iteration 15, loss = 0.40339050
Validation score: 0.194994
Iteration 16, loss = 0.40326835
Validation score: 0.196542
Iteration 17, loss = 0.40306726
Validation score: 0.196264
Iteration 18, loss = 0.40296341
Validation score: 0.196705
Iteration 19, loss = 0.40299705
Validation score: 0.192622
Iteration 20, loss = 0.40291418
Validation score: 0.196635
Iteration 21, loss = 0.40281840
Validation score: 0.195221
Iteration 22, loss = 0.40265084
Validation score: 0.196211
Iteration 23, loss = 0.40264729
Validation score: 0.194246
Iteration 24, loss = 0.40261387
Validation score: 0.192750
Iteration 25, loss = 0.40262383
Validation score: 0.197696
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.002
0.2091726873322376
[[0.32420786 0.3100943  0.23234446 0.28891113 0.47082176 0.28836343
  0.27545295 0.35890433 0.24389536 0.38313569 0.30352634 0.32986058
  0.3042752  0.30519185 0.23666262 0.30894585 0.21434219 0.29906056
  0.34296809 0.27464811 0.35275167]
 [0.4441324  0.36484081 0.29839727 0.34475555 0.45938785 0.30377955
  0.26511268 0.35048831 0.28340965 0.36428615 0.32174951 0.40697935
  0.32497888 0.30994941 0.32131544 0.32216367 0.25088725 0.3649042
  0.28262572 0.41238676 0.29919691]
 [0.33521264 0.44933408 0.44262768 0.26996797 0.43002102 0.40369776
  0.45793445 0.40666351 0.39968758 0.48254985 0.33706939 0.35216001
  0.51030898 0.4960584  0.3906268  0.34581198 0.33181777 0.482981
  0.45978985 0.41331894 0.59050169]
 [0.64942338 0.9481272  0.53098295 0.64277656 0.7960191  0.68981971
  0.60011618 0.84255553 0.60187961 0.93891659 0.66254423 0.75464848
  0.68988413 0.53331744 0.82871432 0.60248317 0.70673065 0.87232948
  0.79827322 0.64223393 1.39515299]
 [0.62939537 0.80924584 0.47635774 0.86594663 0.67123067 0.74790193
  0.70443896 0.64957244 0.73111993 0.63888071 0.71839342 0.87043445
  0.81896929 0.46855011 0.66591897 0.73396921 0.6830851  0.79034629
  0.91014195 0.63010154 1.18778545]
 [0.3720564  0.37140308 0.28891644 0.36135675 0.38212806 0.41512851
  0.42632338 0.37326061 0.50206206 0.45599846 0.31839343 0.48211607
  0.39877496 0.38571284 0.34775272 0.6148142  0.30093039 0.4885353
  0.51169494 0.49170406 0.79900678]
 [0.38119847 0.41819302 0.22316868 0.44371912 0.29148572 0.31464671
  0.40326202 0.3285522  0.26088975 0.41956352 0.24001438 0.38620799
  0.31057526 0.29597159 0.33646978 0.53197488 0.40665984 0.38692539
  0.3623587  0.33642087 0.34994616]
 [0.26634653 0.28712728 0.33789052 0.26089582 0.29099863 0.28137239
  0.28049485 0.21932187 0.26196308 0.25912029 0.24350064 0.28385741
  0.2696874  0.27320866 0.41846594 0.40385365 0.36599863 0.3305311
  0.39037816 0.33232    0.30458804]]
[array([[ 3.80154994e-001, -2.10845958e-302,  1.43940954e-001,
        -2.31674745e-001, -1.02262113e-001, -2.23138191e-001,
         3.95710472e-001, -3.14529965e-001],
       [-6.22644711e-002,  1.83808633e-288, -8.12927532e-002,
        -4.56342684e-001, -2.40966259e-001, -1.68935896e-001,
         2.08431818e-001, -6.82376096e-002],
       [-3.06050759e-002,  1.90030455e-304,  1.54483576e-002,
        -4.67596224e-002,  2.87243057e-001,  2.18806275e-001,
        -2.32216328e-001,  2.95266270e-001],
       [ 1.73418848e-001,  4.75209660e-279, -2.00058174e-002,
        -4.21714485e-001, -2.75036964e-001, -1.91462246e-001,
         3.05474586e-001, -1.05791817e-001],
       [-2.33611822e-001, -8.47152576e-295, -4.73503664e-002,
         1.61849327e-001,  1.99991746e-001,  8.77628078e-002,
        -1.95611835e-001,  3.23911808e-001],
       [ 1.09066048e-001,  5.25652500e-304,  5.45448227e-002,
         3.52522651e-001,  2.75054769e-001,  1.45107731e-001,
         2.24377356e-002, -4.44594592e-002],
       [-5.39151273e-001,  2.48240197e-271, -2.41251511e-001,
         1.88105491e-001,  5.08151269e-001,  1.67844038e-001,
         2.74218166e-001,  4.65515461e-001],
       [ 3.13004305e-001, -7.68576005e-296,  1.98323084e-001,
         7.05935546e-001,  5.42244245e-001,  5.06760198e-001,
        -2.78531171e-001,  5.10309199e-001]]), array([[ 2.83150989e-001, -8.98754132e-284, -2.25747122e-001,
         2.30116946e-001,  1.65639893e-173,  1.71474519e-300,
         4.52934225e-285,  5.85279930e-001],
       [ 1.95387662e-296,  1.74111706e-302,  1.73353988e-300,
        -2.73940175e-276,  4.90490723e-284, -6.83181815e-283,
         1.45928452e-304,  6.11313127e-289],
       [ 2.32596574e-001,  2.54351343e-285, -7.11397121e-002,
         1.19260787e-001,  1.01567051e-200, -2.07929096e-305,
        -2.92701332e-290,  1.84949637e-001],
       [ 6.99984232e-001,  2.51094393e-305,  2.19800282e-003,
         3.36673370e-001,  6.98274197e-191, -9.89087625e-305,
        -1.35076784e-236, -8.03636107e-003],
       [ 6.24354614e-001, -1.76225531e-296,  9.00921286e-002,
         2.87337262e-001, -3.19383326e-163, -3.32715957e-273,
         2.64316220e-230, -2.62023550e-001],
       [ 4.30273351e-001,  1.43705283e-301,  2.92933909e-002,
         1.35751180e-001,  3.57756067e-157,  2.39445948e-302,
        -6.59083754e-227, -5.06212956e-002],
       [-4.50474900e-001,  1.68676635e-303, -2.69707361e-002,
        -3.41765412e-001,  4.23770164e-135, -1.06613166e-277,
         3.94201392e-265,  1.53814158e-001],
       [ 5.26026730e-001, -1.23087138e-302,  2.61845656e-001,
         3.30148676e-002, -4.63509926e-157, -1.79592511e-299,
         3.90748274e-230, -4.34364326e-001]]), array([[ 5.71452113e-303, -1.20725367e-304, -1.51188754e-001,
        -1.69221440e-281,  5.32460356e-001,  1.59440943e-278,
         2.75088665e-283,  7.81616575e-001],
       [-1.10528147e-278, -7.23378956e-283, -1.50392295e-303,
        -4.53643347e-303,  6.38570697e-293,  9.49858741e-296,
         1.29131859e-274,  3.98707462e-303],
       [ 4.22804273e-278, -1.40174602e-291, -3.46348607e-001,
        -2.27019913e-282,  2.43236444e-002, -1.31228039e-297,
         2.04002300e-287, -1.93457332e-002],
       [-2.17470525e-291,  9.28154152e-304, -5.92448196e-004,
        -4.37656543e-293,  2.80104083e-001, -1.68584176e-296,
         3.93947213e-296,  3.95079881e-001],
       [-1.69025965e-303, -1.28650916e-304, -1.26987238e-136,
         2.67970561e-288, -6.34196761e-155, -1.20908534e-274,
         4.74864051e-296, -1.50483204e-171],
       [ 1.38221440e-302,  6.68313138e-295, -5.01605338e-303,
        -7.54869646e-279, -1.09613616e-304, -1.18924593e-305,
        -7.82273743e-292,  5.94603215e-305],
       [-7.86097063e-292,  9.26902774e-304,  8.34616535e-287,
         2.88027420e-280, -1.51702208e-290,  6.09066382e-295,
         9.57331111e-307,  9.30718239e-267],
       [ 2.17116995e-300, -2.36526341e-030,  7.46034263e-001,
         3.10215663e-275, -2.83374213e-001,  1.15274241e-252,
        -3.32401781e-270,  2.02156034e-001]]), array([[ 1.36763969e-297,  6.31281866e-294,  5.28231424e-304,
         2.37663631e-290,  2.39964533e-275,  1.11390601e-305,
        -7.07876369e-275, -1.51004969e-270],
       [ 7.57417017e-274,  3.39710752e-303, -5.56234278e-304,
        -4.78911949e-293, -6.60682222e-296, -2.64098093e-297,
         2.37100119e-300, -9.37748452e-296],
       [ 2.01027940e-001, -2.84562576e-001, -1.93544823e-001,
        -6.05374015e-302,  1.47919753e-303,  6.47529571e-122,
        -1.56132385e-288,  5.95110920e-001],
       [ 4.01971755e-303,  3.47547220e-300,  2.95184682e-292,
         6.01268869e-303, -2.84956199e-304,  2.41317958e-272,
        -2.63409545e-300,  4.40525859e-296],
       [ 1.56546088e-001, -4.56000406e-002,  5.97892795e-001,
        -2.01349131e-277, -2.84362409e-282,  1.61381982e-098,
         8.22132055e-299, -3.33073852e-001],
       [-8.46828512e-304, -7.35231960e-305,  6.84458579e-277,
        -3.35725117e-300, -4.87849660e-302,  2.80448194e-304,
         2.07941615e-293,  9.49984489e-287],
       [-4.18789369e-305,  1.27397358e-274,  3.63147321e-305,
        -2.56383759e-279,  8.87039116e-304, -1.77614429e-271,
        -1.07171410e-303,  1.53360662e-305],
       [ 1.38305399e-001, -1.45685178e-001,  5.98456705e-001,
        -1.08883001e-302,  1.60943232e-294, -1.20022834e-079,
        -2.46407247e-274,  3.16140326e-001]]), array([[-8.03325656e-003,  2.47385291e-060,  2.89006079e-002,
         2.26243085e-001,  1.88328548e-281,  3.31308045e-001,
         2.55419762e-001, -6.15890360e-274],
       [ 1.38315312e-001,  7.89477094e-097, -7.49057498e-002,
        -1.37989085e-001, -4.15815266e-285, -4.95672147e-002,
        -2.92624741e-001,  1.03626047e-275],
       [ 5.59566004e-001, -8.13576827e-069,  6.71880899e-001,
        -2.04004844e-001,  3.06435071e-296,  7.18697522e-001,
        -2.40407438e-001, -2.94868010e-303],
       [ 4.55976278e-302, -1.12637983e-304,  7.98642536e-304,
        -8.12216539e-305, -4.47782652e-302, -9.60060116e-305,
        -8.20215317e-291,  3.13064588e-305],
       [ 2.65160292e-297,  1.17813258e-304,  4.02050471e-293,
         4.77010424e-274,  6.49539313e-285,  1.48983544e-291,
         5.08632608e-285,  7.62459161e-305],
       [ 4.06587323e-122, -9.75389962e-136, -5.51075205e-124,
        -3.43907507e-123,  2.30140231e-282,  1.13137284e-122,
        -9.23884815e-112,  7.72511169e-271],
       [-3.29990822e-282, -2.13624671e-301,  1.85442411e-287,
        -7.72946501e-296,  2.88554549e-275, -4.68530943e-279,
        -1.59635853e-300,  8.40230274e-291],
       [-1.53074619e-001, -1.26962731e-060,  4.01997966e-002,
         1.44855356e-001,  9.02781443e-275, -9.69552494e-003,
         4.94804317e-001,  6.71757655e-303]]), array([[-1.86045771e-001,  1.20032562e-207, -1.14362105e-286,
         2.82857308e-001,  2.21137481e-001, -4.56089816e-157,
        -3.11513854e-001, -3.71763049e-011],
       [-7.02064970e-055, -4.33285902e-209, -1.29591812e-284,
        -1.41462654e-078,  1.33791426e-086,  1.03840481e-249,
         2.29908025e-074, -3.12806498e-102],
       [ 2.88516175e-001, -4.95481108e-174,  1.97965366e-302,
         5.94958620e-001,  2.58937082e-001,  1.04429751e-122,
        -2.66989718e-001, -9.38192874e-007],
       [ 1.83925770e-001, -3.32568739e-179, -9.34484402e-274,
         2.82079027e-002,  2.14121249e-002,  1.84793662e-142,
         1.43331363e-001, -8.71527588e-010],
       [-1.09072138e-304, -1.07970851e-292,  3.98922344e-290,
        -1.03497631e-285,  2.18439608e-280,  2.44521875e-015,
         3.51818070e-302,  4.13487714e-298],
       [-3.34172990e-001,  1.01527982e-165, -6.30389719e-292,
         2.07885481e-001,  5.13154072e-001, -7.52343624e-113,
         3.71473975e-001, -1.29334233e-006],
       [ 4.85903308e-001,  2.75994390e-202, -9.52730192e-300,
        -8.33614289e-002, -2.02061666e-001,  7.01112080e-182,
         4.39973510e-001, -2.49934677e-016],
       [-1.41326999e-303,  1.62773292e-303, -2.31072219e-296,
         1.96527659e-300,  2.99957217e-302,  1.77831950e-304,
         1.11942691e-298,  4.91819428e-284]]), array([[ 2.75308437e-001,  1.44952877e-001, -3.80871900e-001,
         3.81754857e-001,  4.93819603e-001, -3.72338116e-277,
         2.49857775e-304,  1.33088504e-093],
       [ 2.19998759e-181, -2.43633753e-207,  5.91176005e-194,
        -1.13469417e-186,  1.13297343e-188, -3.81007940e-294,
         2.81742975e-274, -1.18268845e-210],
       [ 7.28505861e-301, -1.23737492e-299, -2.73127040e-297,
        -3.12805267e-304, -2.76979516e-304,  2.05943971e-280,
        -7.66677913e-305,  1.93415400e-304],
       [-2.73794733e-001,  3.47185518e-001,  7.01601278e-001,
        -8.80335705e-002,  3.66955409e-001, -7.01070434e-305,
        -1.58303206e-304, -5.19375734e-068],
       [ 1.44320230e-001,  1.37203034e-001,  4.40801644e-001,
         7.04366586e-002, -5.01606880e-001,  8.25900493e-306,
         8.85716424e-304, -1.67432739e-067],
       [ 1.83507586e-147, -1.10890162e-190,  1.09298610e-163,
        -1.57866940e-153,  5.90238441e-157, -9.01962536e-288,
        -1.62975250e-304, -2.82759597e-250],
       [ 2.54333893e-001, -1.21098660e-001,  1.80672581e-001,
         4.07731716e-001,  8.64738663e-002,  1.34850967e-272,
        -3.45976829e-276, -4.61599009e-110],
       [ 4.47589280e-007, -1.27819512e-013, -3.66130058e-008,
         1.67686694e-007,  1.34277568e-007, -1.54486846e-283,
        -9.04864324e-272, -5.50699941e-124]]), array([[-5.11818082e-001],
       [ 2.05985824e-001],
       [ 5.28254831e-001],
       [-4.26055394e-001],
       [-4.53735772e-001],
       [-7.42616485e-259],
       [ 1.28632306e-280],
       [-3.00727910e-007]])]
[ 0.18392451 -0.04377265 -0.19353219  0.04696251 -0.14685552 -0.00138989
  0.16438247 -0.37873605]
TRAIN
Mean PCC: 0.4834856388604415 +- 0.44268106567511323
PCC: Min: -0.05081300666934347 Max: 0.8749899063271683
Mean MSE: 0.7720924555315127 +- 0.4333228184531196
MSE: Min: 0.3089823400200594 Max: 1.4506016057232625
MSE:
ArgMin: [('6c4q', 85), ('5aiz', 110), ('4hlb', 95), ('5w0h', 80), ('4rgi', 71), ('2huj', 125), ('2yvi', 89), ('4o7q', 94), ('3o2e', 86), ('3bv8', 85)]
ArgMax: [('4aqo', 86), ('1j0p', 108), ('3dt5', 119), ('2pne', 81), ('5dbl', 130), ('2a3m', 107), ('5v0m', 98), ('1lmi', 131), ('1sau', 114), ('1jni', 62)]
PCC:
ArgMin: [('3dt5', 119), ('2nwf', 141), ('1lmi', 131), ('4aqo', 86), ('2h5c', 198), ('3tch', 517), ('5nuv', 301), ('3zfp', 148), ('6ek7', 364), ('2uyq', 274)]
ArgMax: [('6c4q', 85), ('5w0h', 80), ('4hlb', 95), ('5aiz', 110), ('3bv8', 85), ('1xmt', 95), ('5zt3', 114), ('2huj', 125), ('6c4v', 81), ('4rgi', 71)]
MSE vs Length correlation: 0.048053417665532845
PCC vs Length correlation: 0.06564591335770442
MSE vs b-val mean correlation: 5.834141132754489e-06
PCC vs b-val mean correlation: 2.4692257986069777e-06
VAL
Mean PCC: 0.4799580405272045 +- 0.43282775195039647
PCC: Min: 0.012773359645159306 Max: 0.8958600964414308
Mean MSE: 0.7745107432231132 +- 0.4179664968675866
MSE: Min: 0.30659553675999185 Max: 1.3289787876021357
MSE:
ArgMin: [('2vc8', 72), ('4i6x', 117), ('2i5u', 77), ('3mao', 105), ('5ijm', 98), ('5hqh', 96), ('3tbn', 87), ('4gos', 115), ('2b1k', 149), ('1i2t', 61)]
ArgMax: [('2rkn', 77), ('3fgh', 67), ('3sw0', 186), ('2rbk', 261), ('1u5p', 211), ('3gvo', 342), ('2v9k', 467), ('3cao', 102), ('3zt9', 192), ('3s9x', 159)]
PCC:
ArgMin: [('2rbk', 261), ('2rkn', 77), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('5hfg', 205), ('1u5p', 211), ('4rep', 489), ('3s9x', 159), ('3zt9', 192)]
ArgMax: [('4i6x', 117), ('2vc8', 72), ('5hqh', 96), ('3mao', 105), ('2i5u', 77), ('5ijm', 98), ('3tbn', 87), ('4gos', 115), ('2b1k', 149), ('1i2t', 61)]
MSE vs Length correlation: 0.06464178532811005
PCC vs Length correlation: 0.08594568848673723
MSE vs b-val mean correlation: 0.001608533082886665
PCC vs b-val mean correlation: 0.00136539630237964
TEST
Mean PCC: 0.47213895612640977 +- 0.4442151529286451
PCC: Min: -0.08802966504983434 Max: 0.8447016065734557
Mean MSE: 0.7827275198019625 +- 0.43262849361326894
MSE: Min: 0.3440946452789611 Max: 1.4661509766173701
MSE:
ArgMin: [('5kuj', 95), ('3o70', 55), ('2od5', 91), ('5ol9', 81), ('4qq6', 58), ('3t7l', 74), ('3cp0', 63), ('2ovg', 58), ('1tzv', 141), ('3chm', 161)]
ArgMax: [('4npn', 71), ('5i8g', 226), ('4gs3', 90), ('2vac', 134), ('4xxt', 221), ('3b6e', 182), ('4qdn', 118), ('3zuc', 153), ('4r1b', 282), ('4uyr', 188)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('4r1b', 282), ('2vac', 134), ('1r5y', 361), ('3ip0', 158), ('4uyr', 188), ('4gs3', 90), ('4qdn', 118)]
ArgMax: [('5kuj', 95), ('2od5', 91), ('5ol9', 81), ('1mud', 225), ('3cp0', 63), ('3o70', 55), ('4qq6', 58), ('4rwu', 81), ('3chm', 161), ('2eaq', 89)]
MSE vs Length correlation: 0.045176208541773843
PCC vs Length correlation: 0.058131652808692036
MSE vs b-val mean correlation: 1.5717974164886073e-05
PCC vs b-val mean correlation: 8.810280267002035e-06
[CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.48528087
Validation score: 0.172171
Iteration 2, loss = 0.41421651
Validation score: 0.181073
Iteration 3, loss = 0.41143737
Validation score: 0.181334
Iteration 4, loss = 0.41062711
Validation score: 0.182952
Iteration 5, loss = 0.40992793
Validation score: 0.183532
Iteration 6, loss = 0.40951715
Validation score: 0.184134
Iteration 7, loss = 0.40912295
Validation score: 0.184352
Iteration 8, loss = 0.40887038
Validation score: 0.184456
Iteration 9, loss = 0.40857984
Validation score: 0.183556
Iteration 10, loss = 0.40830631
Validation score: 0.184755
Iteration 11, loss = 0.40801016
Validation score: 0.185141
Iteration 12, loss = 0.40770325
Validation score: 0.185141
Iteration 13, loss = 0.40749403
Validation score: 0.184768
Iteration 14, loss = 0.40722555
Validation score: 0.185374
Iteration 15, loss = 0.40694731
Validation score: 0.185034
Iteration 16, loss = 0.40667550
Validation score: 0.184931
Iteration 17, loss = 0.40644144
Validation score: 0.185842
Iteration 18, loss = 0.40607853
Validation score: 0.186062
Iteration 19, loss = 0.40581780
Validation score: 0.185986
Iteration 20, loss = 0.40558133
Validation score: 0.186339
Iteration 21, loss = 0.40529673
Validation score: 0.185421
Iteration 22, loss = 0.40498907
Validation score: 0.186116
Iteration 23, loss = 0.40470062
Validation score: 0.186613
Iteration 24, loss = 0.40446780
Validation score: 0.184937
Iteration 25, loss = 0.40412505
Validation score: 0.186025
Iteration 26, loss = 0.40401386
Validation score: 0.186491
Iteration 27, loss = 0.40366763
Validation score: 0.185861
Iteration 28, loss = 0.40357167
Validation score: 0.186111
Iteration 29, loss = 0.40329741
Validation score: 0.185923
Iteration 30, loss = 0.40311630
Validation score: 0.185814
Iteration 31, loss = 0.40287666
Validation score: 0.184485
Iteration 32, loss = 0.40268632
Validation score: 0.185328
Iteration 33, loss = 0.40257832
Validation score: 0.185137
Iteration 34, loss = 0.40232797
Validation score: 0.185912
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.8032140565360962, total= 2.9min
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.45090700
Validation score: 0.188192
Iteration 2, loss = 0.40861773
Validation score: 0.189787
Iteration 3, loss = 0.40742083
Validation score: 0.189319
Iteration 4, loss = 0.40694189
Validation score: 0.190511
Iteration 5, loss = 0.40637611
Validation score: 0.189642
Iteration 6, loss = 0.40621452
Validation score: 0.182754
Iteration 7, loss = 0.40548742
Validation score: 0.189104
Iteration 8, loss = 0.40484428
Validation score: 0.188268
Iteration 9, loss = 0.40461332
Validation score: 0.186232
Iteration 10, loss = 0.40397832
Validation score: 0.189131
Iteration 11, loss = 0.40354846
Validation score: 0.187035
Iteration 12, loss = 0.40297600
Validation score: 0.187626
Iteration 13, loss = 0.40275216
Validation score: 0.188430
Iteration 14, loss = 0.40231083
Validation score: 0.187388
Iteration 15, loss = 0.40222463
Validation score: 0.187502
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.8003552704977659, total= 1.1min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.42255563
Validation score: 0.194944
Iteration 2, loss = 0.41120386
Validation score: 0.195279
Iteration 3, loss = 0.41047218
Validation score: 0.196710
Iteration 4, loss = 0.41010634
Validation score: 0.193968
Iteration 5, loss = 0.40997990
Validation score: 0.191348
Iteration 6, loss = 0.40959889
Validation score: 0.197671
Iteration 7, loss = 0.40926645
Validation score: 0.197915
Iteration 8, loss = 0.40932735
Validation score: 0.197004
Iteration 9, loss = 0.40921875
Validation score: 0.196117
Iteration 10, loss = 0.40893431
Validation score: 0.198430
Iteration 11, loss = 0.40912039
Validation score: 0.197118
Iteration 12, loss = 0.40878049
Validation score: 0.195263
Iteration 13, loss = 0.40894855
Validation score: 0.198313
Iteration 14, loss = 0.40867979
Validation score: 0.199065
Iteration 15, loss = 0.40849943
Validation score: 0.199723
Iteration 16, loss = 0.40823703
Validation score: 0.196224
Iteration 17, loss = 0.40817603
Validation score: 0.198572
Iteration 18, loss = 0.40817351
Validation score: 0.191393
Iteration 19, loss = 0.40818661
Validation score: 0.199229
Iteration 20, loss = 0.40809677
Validation score: 0.199751
Iteration 21, loss = 0.40814953
Validation score: 0.200508
Iteration 22, loss = 0.40804842
Validation score: 0.199673
Iteration 23, loss = 0.40808505
Validation score: 0.200371
Iteration 24, loss = 0.40780306
Validation score: 0.195515
Iteration 25, loss = 0.40818312
Validation score: 0.200604
Iteration 26, loss = 0.40779787
Validation score: 0.200441
Iteration 27, loss = 0.40778991
Validation score: 0.198353
Iteration 28, loss = 0.40812015
Validation score: 0.199988
Iteration 29, loss = 0.40793386
Validation score: 0.195943
Iteration 30, loss = 0.40816256
Validation score: 0.199613
Iteration 31, loss = 0.40789967
Validation score: 0.199349
Iteration 32, loss = 0.40785850
Validation score: 0.198603
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.8002488389553463, total= 2.4min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.56755115
Validation score: -0.040413
Iteration 2, loss = 0.51037783
Validation score: -0.002553
Iteration 3, loss = 0.50342871
Validation score: -0.000137
Iteration 4, loss = 0.50288934
Validation score: -0.000068
Iteration 5, loss = 0.50266552
Validation score: -0.000118
Iteration 6, loss = 0.50249481
Validation score: -0.000027
Iteration 7, loss = 0.50233066
Validation score: -0.000044
Iteration 8, loss = 0.50219715
Validation score: -0.000120
Iteration 9, loss = 0.50207231
Validation score: -0.000075
Iteration 10, loss = 0.50196775
Validation score: -0.000081
Iteration 11, loss = 0.50186940
Validation score: -0.000044
Iteration 12, loss = 0.50180360
Validation score: -0.000026
Iteration 13, loss = 0.50175145
Validation score: -0.000007
Iteration 14, loss = 0.50171251
Validation score: -0.000023
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.9913509236186294, total= 1.0min
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.43234289
Validation score: 0.199760
Iteration 2, loss = 0.40852006
Validation score: 0.202064
Iteration 3, loss = 0.40681338
Validation score: 0.204239
Iteration 4, loss = 0.40631661
Validation score: 0.202193
Iteration 5, loss = 0.40573244
Validation score: 0.204364
Iteration 6, loss = 0.40521287
Validation score: 0.202388
Iteration 7, loss = 0.40479641
Validation score: 0.204834
Iteration 8, loss = 0.40473802
Validation score: 0.201989
Iteration 9, loss = 0.40440041
Validation score: 0.203859
Iteration 10, loss = 0.40430408
Validation score: 0.201527
Iteration 11, loss = 0.40397856
Validation score: 0.203171
Iteration 12, loss = 0.40412080
Validation score: 0.205072
Iteration 13, loss = 0.40366215
Validation score: 0.204702
Iteration 14, loss = 0.40370799
Validation score: 0.196930
Iteration 15, loss = 0.40340593
Validation score: 0.202480
Iteration 16, loss = 0.40345389
Validation score: 0.203417
Iteration 17, loss = 0.40349444
Validation score: 0.202146
Iteration 18, loss = 0.40332095
Validation score: 0.202225
Iteration 19, loss = 0.40306571
Validation score: 0.201500
Iteration 20, loss = 0.40322087
Validation score: 0.203185
Iteration 21, loss = 0.40327829
Validation score: 0.203280
Iteration 22, loss = 0.40305235
Validation score: 0.201665
Iteration 23, loss = 0.40314252
Validation score: 0.201993
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.7992725917811363, total= 1.8min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.43303629
Validation score: 0.190046
Iteration 2, loss = 0.41636570
Validation score: 0.199283
Iteration 3, loss = 0.41502894
Validation score: 0.195117
Iteration 4, loss = 0.41415561
Validation score: 0.198053
Iteration 5, loss = 0.41377560
Validation score: 0.196068
Iteration 6, loss = 0.41353885
Validation score: 0.198622
Iteration 7, loss = 0.41396941
Validation score: 0.195789
Iteration 8, loss = 0.41292362
Validation score: 0.198134
Iteration 9, loss = 0.41312501
Validation score: 0.196812
Iteration 10, loss = 0.41304126
Validation score: 0.187734
Iteration 11, loss = 0.41289953
Validation score: 0.194608
Iteration 12, loss = 0.41238960
Validation score: 0.196662
Iteration 13, loss = 0.41273210
Validation score: 0.199587
Iteration 14, loss = 0.41249555
Validation score: 0.192635
Iteration 15, loss = 0.41274050
Validation score: 0.199384
Iteration 16, loss = 0.41264877
Validation score: 0.199026
Iteration 17, loss = 0.41251444
Validation score: 0.193033
Iteration 18, loss = 0.41293415
Validation score: 0.200745
Iteration 19, loss = 0.41246772
Validation score: 0.197086
Iteration 20, loss = 0.41296728
Validation score: 0.201627
Iteration 21, loss = 0.41229040
Validation score: 0.193353
Iteration 22, loss = 0.41265477
Validation score: 0.193364
Iteration 23, loss = 0.41228394
Validation score: 0.192303
Iteration 24, loss = 0.41259972
Validation score: 0.196484
Iteration 25, loss = 0.41239583
Validation score: 0.199646
Iteration 26, loss = 0.41213375
Validation score: 0.196525
Iteration 27, loss = 0.41237225
Validation score: 0.199904
Iteration 28, loss = 0.41245280
Validation score: 0.201276
Iteration 29, loss = 0.41262476
Validation score: 0.197639
Iteration 30, loss = 0.41240248
Validation score: 0.198285
Iteration 31, loss = 0.41226624
Validation score: 0.199804
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8032143144166959, total= 1.6min
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.53101783
Validation score: 0.048381
Iteration 2, loss = 0.44042062
Validation score: 0.176499
Iteration 3, loss = 0.41505928
Validation score: 0.187079
Iteration 4, loss = 0.41214767
Validation score: 0.190268
Iteration 5, loss = 0.41101941
Validation score: 0.191401
Iteration 6, loss = 0.41036565
Validation score: 0.192138
Iteration 7, loss = 0.40994272
Validation score: 0.192751
Iteration 8, loss = 0.40961665
Validation score: 0.193154
Iteration 9, loss = 0.40931085
Validation score: 0.193572
Iteration 10, loss = 0.40903747
Validation score: 0.193922
Iteration 11, loss = 0.40877791
Validation score: 0.194085
Iteration 12, loss = 0.40857991
Validation score: 0.194555
Iteration 13, loss = 0.40830955
Validation score: 0.194836
Iteration 14, loss = 0.40809935
Validation score: 0.194867
Iteration 15, loss = 0.40788293
Validation score: 0.195296
Iteration 16, loss = 0.40766614
Validation score: 0.195409
Iteration 17, loss = 0.40746554
Validation score: 0.195651
Iteration 18, loss = 0.40729566
Validation score: 0.195924
Iteration 19, loss = 0.40713144
Validation score: 0.195485
Iteration 20, loss = 0.40695919
Validation score: 0.196217
Iteration 21, loss = 0.40673494
Validation score: 0.196377
Iteration 22, loss = 0.40655858
Validation score: 0.196700
Iteration 23, loss = 0.40636442
Validation score: 0.197041
Iteration 24, loss = 0.40625185
Validation score: 0.197021
Iteration 25, loss = 0.40605254
Validation score: 0.197103
Iteration 26, loss = 0.40588473
Validation score: 0.197152
Iteration 27, loss = 0.40571499
Validation score: 0.196518
Iteration 28, loss = 0.40555196
Validation score: 0.197534
Iteration 29, loss = 0.40535806
Validation score: 0.197672
Iteration 30, loss = 0.40519785
Validation score: 0.197217
Iteration 31, loss = 0.40502334
Validation score: 0.198004
Iteration 32, loss = 0.40487736
Validation score: 0.198235
Iteration 33, loss = 0.40472372
Validation score: 0.198087
Iteration 34, loss = 0.40458859
Validation score: 0.198109
Iteration 35, loss = 0.40441707
Validation score: 0.198318
Iteration 36, loss = 0.40425052
Validation score: 0.198784
Iteration 37, loss = 0.40409703
Validation score: 0.198625
Iteration 38, loss = 0.40395657
Validation score: 0.198944
Iteration 39, loss = 0.40379213
Validation score: 0.198762
Iteration 40, loss = 0.40368469
Validation score: 0.198860
Iteration 41, loss = 0.40351312
Validation score: 0.198451
Iteration 42, loss = 0.40338901
Validation score: 0.198936
Iteration 43, loss = 0.40323821
Validation score: 0.198298
Iteration 44, loss = 0.40311218
Validation score: 0.199123
Iteration 45, loss = 0.40298661
Validation score: 0.199049
Iteration 46, loss = 0.40285512
Validation score: 0.199487
Iteration 47, loss = 0.40269318
Validation score: 0.199648
Iteration 48, loss = 0.40255813
Validation score: 0.199507
Iteration 49, loss = 0.40243636
Validation score: 0.199480
Iteration 50, loss = 0.40232968
Validation score: 0.199574
Iteration 51, loss = 0.40213665
Validation score: 0.199321
Iteration 52, loss = 0.40204926
Validation score: 0.199384
Iteration 53, loss = 0.40193270
Validation score: 0.199279
Iteration 54, loss = 0.40182970
Validation score: 0.199273
Iteration 55, loss = 0.40173047
Validation score: 0.198559
Iteration 56, loss = 0.40154736
Validation score: 0.199525
Iteration 57, loss = 0.40148515
Validation score: 0.198623
Iteration 58, loss = 0.40138586
Validation score: 0.199276
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.8032231443128195, total= 5.0min
14
Input read.
(540304, 29)
(540304, 609)
Converted to numpy array.
Fitting 1 folds for each of 7 candidates, totalling 7 fits
Iteration 1, loss = 0.51857147
Validation score: 0.177961
Iteration 2, loss = 0.41275765
Validation score: 0.188180
Iteration 3, loss = 0.40959157
Validation score: 0.189614
Iteration 4, loss = 0.40842921
Validation score: 0.190323
Iteration 5, loss = 0.40760001
Validation score: 0.190696
Iteration 6, loss = 0.40701556
Validation score: 0.191178
Iteration 7, loss = 0.40645751
Validation score: 0.191570
Iteration 8, loss = 0.40595460
Validation score: 0.192719
Iteration 9, loss = 0.40551249
Validation score: 0.192388
Iteration 10, loss = 0.40511691
Validation score: 0.193384
Iteration 11, loss = 0.40470212
Validation score: 0.193721
Iteration 12, loss = 0.40435615
Validation score: 0.193262
Iteration 13, loss = 0.40404672
Validation score: 0.193855
Iteration 14, loss = 0.40375889
Validation score: 0.194078
Iteration 15, loss = 0.40342920
Validation score: 0.194280
Iteration 16, loss = 0.40315602
Validation score: 0.192853
Iteration 17, loss = 0.40283537
Validation score: 0.191484
Iteration 18, loss = 0.40255740
Validation score: 0.192665
Iteration 19, loss = 0.40236123
Validation score: 0.194451
Iteration 20, loss = 0.40209679
Validation score: 0.193794
Iteration 21, loss = 0.40193212
Validation score: 0.194446
Iteration 22, loss = 0.40160619
Validation score: 0.193191
Iteration 23, loss = 0.40143480
Validation score: 0.194393
Iteration 24, loss = 0.40119939
Validation score: 0.192695
Iteration 25, loss = 0.40103861
Validation score: 0.194079
Iteration 26, loss = 0.40075137
Validation score: 0.194487
Iteration 27, loss = 0.40070875
Validation score: 0.194704
Iteration 28, loss = 0.40035000
Validation score: 0.194285
Iteration 29, loss = 0.40024620
Validation score: 0.193789
Iteration 30, loss = 0.40000040
Validation score: 0.193348
Iteration 31, loss = 0.39988781
Validation score: 0.194309
Iteration 32, loss = 0.39971693
Validation score: 0.194186
Iteration 33, loss = 0.39970522
Validation score: 0.192633
Iteration 34, loss = 0.39934987
Validation score: 0.193348
Iteration 35, loss = 0.39934577
Validation score: 0.193395
Iteration 36, loss = 0.39920402
Validation score: 0.193483
Iteration 37, loss = 0.39901152
Validation score: 0.193756
Iteration 38, loss = 0.39892863
Validation score: 0.192731
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Model fit done.
Best LR: 0.00025
0.20810495449348254
[[0.20779518 0.20594183 0.17205699 0.23995199 0.23978359 0.19698476
  0.20460676 0.1958961  0.21244228 0.23437857 0.16706142 0.19906263
  0.19338568 0.27310653 0.20132222 0.2597888  0.27829254 0.30315499
  0.2445786  0.2967818  0.22849545]
 [0.2486981  0.19195175 0.19871578 0.25193738 0.20715792 0.23010401
  0.24076384 0.21780772 0.19532655 0.23096297 0.18189316 0.1694967
  0.16152399 0.26425904 0.38825814 0.16334738 0.37539888 0.35877882
  0.16885004 0.37757055 0.25163304]
 [0.20252658 0.2521512  0.16966575 0.26472483 0.22310667 0.22819172
  0.23890774 0.24928442 0.20709688 0.14675684 0.17192953 0.16561465
  0.21519296 0.30733407 0.49445166 0.2521413  0.3492942  0.32045142
  0.19767013 0.34825823 0.25251226]
 [0.29722536 0.35783506 0.34433238 0.2889943  0.39922513 0.3999872
  0.4402782  0.41223011 0.32416313 0.30274554 0.27777669 0.22798858
  0.29786941 0.74832675 0.6497353  0.51675895 0.3813513  0.3164413
  0.49161138 0.47070444 0.52316641]
 [0.29675518 0.42201221 0.49051728 0.38214405 0.34196127 0.3182035
  0.33896951 0.46808072 0.28384299 0.39673499 0.4145002  0.25813593
  0.2686962  0.64349732 0.72825051 0.49874253 0.3784899  0.40356424
  0.44293413 0.52232155 0.46970199]
 [0.23233799 0.25616018 0.20850914 0.26696177 0.24564934 0.26519042
  0.28662267 0.26631344 0.2780046  0.28548015 0.26112309 0.28378356
  0.28449415 0.2033758  0.32638526 0.32444837 0.27349516 0.37772307
  0.22944358 0.24989388 0.24875526]
 [0.20307785 0.18441612 0.22757913 0.22242502 0.184787   0.21265355
  0.21224777 0.15804859 0.27068006 0.25497593 0.19361886 0.23388164
  0.18852332 0.29212457 0.39889125 0.24682527 0.33757601 0.33272722
  0.16242819 0.38372131 0.27320949]
 [0.16355363 0.14791006 0.22400123 0.15597915 0.15572525 0.20697705
  0.28830029 0.16328808 0.21782374 0.22205035 0.17728373 0.21775381
  0.20300194 0.25071425 0.31576487 0.24135798 0.32181895 0.28379417
  0.17815501 0.39455809 0.30012181]]
[array([[-5.06524008e-001,  2.83257480e-001,  4.69239996e-001,
         1.33815850e-003,  2.70683289e-001, -2.74304471e-316,
         1.68272504e-316,  4.93315801e-001],
       [-2.99588225e-001,  1.15532363e-001,  2.64814402e-001,
        -6.64712060e-001,  3.16387993e-001, -3.39863657e-316,
        -2.88885909e-316,  3.87516188e-001],
       [-9.48900612e-002,  1.55670304e-001,  1.25639071e-001,
        -3.91209687e-001, -5.66094142e-002,  1.86544153e-316,
        -2.73468102e-316, -5.10629703e-001],
       [ 5.79764824e-001,  1.22938561e-001,  1.73829631e-001,
        -8.79502175e-002, -7.35097328e-002, -1.87909701e-316,
        -7.84138108e-317,  2.65858761e-001],
       [ 6.23755393e-001, -2.24739781e-001, -5.17694760e-001,
        -3.47528557e-001,  2.89809560e-002, -2.27890571e-316,
         3.16079021e-316,  4.31438651e-001],
       [-1.60701359e-001,  1.46075791e-001,  3.58658128e-001,
         3.30796859e-002, -2.26999173e-001, -3.70755813e-316,
        -7.84712459e-317, -5.25965447e-001],
       [ 6.72777871e-001,  1.01367887e-001,  1.29006891e-001,
         2.32771219e-001,  4.69922664e-002, -3.23608710e-316,
        -1.95706507e-316,  4.79773731e-002],
       [-2.46246307e-001,  2.13686212e-001,  2.43157096e-001,
         3.05751052e-001, -1.08710036e-002,  1.86618268e-316,
        -1.97348055e-316, -4.19104502e-001]]), array([[ 7.04689941e-001,  2.86021460e-316,  3.51506045e-001,
         2.86876670e-001, -2.78856298e-001,  5.59019098e-002,
         3.08643574e-001,  8.85369018e-002],
       [ 2.58679187e-002,  3.36607009e-316,  2.03148640e-001,
        -1.43611313e-001, -9.93906068e-002,  1.44552494e-001,
         1.97938212e-001,  4.92097615e-002],
       [-3.77244384e-001,  5.64333984e-317, -4.21343437e-001,
         3.61224005e-001, -1.30007985e-001,  4.52692426e-001,
        -1.98159382e-001, -5.66415635e-002],
       [ 4.96316042e-002, -4.42800653e-317, -4.68785720e-001,
         3.89884133e-001, -1.12552988e-001, -2.68663720e-001,
        -4.27495072e-001, -5.86054413e-002],
       [-2.25200657e-001,  3.32075058e-317, -3.36109904e-001,
         2.63537345e-001,  6.29345639e-002,  2.13721612e-001,
        -1.88170276e-001, -2.62436393e-001],
       [ 2.56311326e-317,  3.11742814e-316, -2.15276007e-316,
         4.63056208e-317,  8.56867140e-317, -5.65827362e-316,
         3.22738334e-316, -6.51051695e-316],
       [-2.92837466e-316, -6.67358677e-317, -1.19764684e-316,
        -4.22401458e-316,  1.17918243e-316, -2.70180209e-316,
        -1.25385990e-316, -2.48209075e-316],
       [-3.86406941e-001, -3.16332521e-316,  6.39457439e-001,
         1.95761596e-001, -8.88175359e-002,  6.05494340e-001,
         6.70338982e-001,  3.44579245e-001]]), array([[ 5.27524767e-001,  3.07749489e-317, -6.11602423e-002,
         3.25749732e-001, -2.65459480e-316,  1.48275770e-317,
         5.23561476e-001,  6.38389460e-001],
       [ 2.45543773e-316, -1.86186326e-316, -1.21371929e-316,
         5.79195790e-316, -2.11230489e-316,  1.07013710e-316,
        -2.15054271e-316, -4.30628333e-316],
       [ 5.55119580e-001, -8.29102776e-317, -4.82150919e-001,
        -6.85398799e-002,  1.96734569e-317,  1.97686949e-316,
        -2.82760015e-001, -1.67813282e-001],
       [-5.30030350e-001,  1.96347765e-317,  7.25416908e-002,
         2.91142286e-001,  1.91326832e-316,  2.04566799e-316,
         5.15164640e-001,  5.47759275e-001],
       [-2.61374312e-001,  2.85149839e-317,  1.90001713e-001,
        -7.26632691e-013,  5.71513232e-316, -2.72404033e-317,
         3.13361978e-001, -1.85394132e-001],
       [-6.77730103e-002,  9.53458259e-318,  3.89006474e-001,
        -4.19368846e-001,  4.17235360e-316,  1.17024023e-316,
        -4.82922863e-001,  3.96596623e-002],
       [ 5.43032590e-001, -6.02432720e-317,  3.13332031e-001,
         8.43099843e-002, -1.17322968e-316,  6.12119075e-317,
        -2.21225178e-001,  2.36894560e-001],
       [ 3.59534545e-001, -2.34564735e-316, -5.40896238e-002,
        -8.87509090e-002, -2.23928218e-316,  1.19157675e-316,
         8.71196046e-002,  1.25531422e-001]]), array([[-3.30971056e-060, -3.02830764e-316,  1.57287334e-082,
         5.35067672e-001,  3.62942906e-316, -6.81830974e-002,
        -1.79872701e-317, -2.19612391e-001],
       [-8.15661670e-317, -2.14089534e-316, -1.99315148e-316,
         8.70045749e-317,  2.67374494e-317, -1.39830904e-316,
        -2.04632366e-316,  9.71083655e-317],
       [-1.00873557e-102,  1.59569222e-316,  6.31346193e-122,
        -1.96552808e-001,  1.14153121e-316,  2.93496403e-001,
        -9.34338363e-317,  2.95136158e-001],
       [-9.96069918e-140, -2.29517138e-316, -1.39069610e-207,
        -3.19127947e-001, -1.43234868e-317,  2.35428928e-001,
         2.90290676e-316,  1.85012852e-001],
       [-3.69249432e-316, -2.36778510e-316, -1.71035329e-316,
        -1.97158279e-317,  5.59758398e-316, -9.51440099e-317,
         1.22915939e-316,  3.21706038e-316],
       [ 3.30773689e-316,  3.56485132e-316, -5.60493306e-316,
        -2.65929233e-316,  2.27446035e-316, -3.82082308e-317,
         2.56191234e-316,  2.99598196e-317],
       [-1.35575640e-139, -1.52478836e-317, -2.11675885e-161,
        -8.02816825e-001,  1.12798937e-316,  5.73123059e-001,
        -2.87341238e-316,  3.79499871e-001],
       [ 1.38703520e-061,  1.46827476e-316, -2.74622841e-077,
         4.36075770e-001, -3.42267904e-316,  6.44632834e-001,
         4.16146281e-316,  1.06179229e-001]]), array([[ 2.88553305e-116,  1.77183049e-106,  1.51103588e-087,
        -1.68706007e-071, -4.94748233e-070,  7.25101033e-113,
        -3.87841870e-146, -8.08145775e-098],
       [ 1.72559097e-317,  1.38767151e-316,  1.66900785e-316,
        -1.22673822e-316, -2.64326435e-316, -2.09328722e-316,
         5.46112201e-317,  1.92717133e-316],
       [ 8.70648596e-289, -4.00206328e-245,  2.26225831e-208,
         2.45455919e-200,  3.56712809e-193,  7.72770821e-233,
        -6.30803501e-317,  6.62983899e-223],
       [ 2.51734287e-001,  4.18177862e-001, -4.49448209e-001,
         6.65048255e-001,  2.65057604e-001,  3.84321261e-001,
         1.02625311e-058,  6.50929492e-001],
       [-2.35179264e-316,  2.63023193e-316, -1.04482073e-316,
         9.64809812e-317, -2.61572646e-316, -2.61338024e-316,
         3.28974658e-316,  8.71107743e-317],
       [ 2.96185556e-001,  2.86294072e-002,  6.64290013e-001,
        -3.03515873e-001, -2.68205718e-002, -2.98115228e-001,
        -3.27363185e-070,  4.55356420e-001],
       [-2.73921012e-317, -1.76763635e-316,  1.15636277e-316,
         1.19069327e-316, -1.39260110e-317,  4.41966671e-317,
        -2.37900642e-316,  1.32427928e-316],
       [ 2.59862161e-001, -2.05890147e-001,  3.24754951e-001,
         5.15731784e-002, -2.50055971e-001,  3.13965840e-001,
         6.04363004e-100, -5.42297292e-001]]), array([[-4.48582796e-002,  2.95585080e-001,  2.77098476e-316,
         1.29262795e-316, -1.73235400e-001,  4.19658488e-001,
         2.06589704e-001, -4.70401681e-001],
       [-3.50017608e-002,  1.55313643e-001, -3.64308469e-316,
        -2.89666108e-316,  5.91570042e-002,  3.78144711e-001,
        -1.59267741e-001,  4.87523384e-001],
       [ 1.08111448e-001, -8.36505249e-001, -6.10589892e-317,
         1.93926166e-316, -5.86100655e-001,  2.93966031e-001,
         2.92697633e-001, -6.77206747e-001],
       [ 6.64302749e-001, -2.44202959e-001,  3.45846461e-316,
        -2.86989344e-317,  3.75027721e-001, -3.93854460e-001,
        -1.90845465e-001,  1.70353338e-001],
       [ 6.31393285e-001, -3.18512686e-001,  2.68072638e-316,
         3.69364070e-316, -2.43407311e-001, -1.41957205e-001,
        -3.29727929e-001,  5.05788526e-001],
       [-2.68490427e-002,  3.81386581e-001, -7.78189311e-317,
         2.53593778e-316,  2.43176432e-001,  3.81504358e-001,
        -2.69519444e-001, -1.40055225e-001],
       [-3.99219891e-063,  4.42222283e-128,  2.71345966e-316,
         1.20076810e-316, -3.74682749e-112,  1.27997832e-117,
         3.21766853e-093,  1.07055091e-103],
       [ 2.96597748e-001,  3.67626567e-001,  1.23756765e-316,
        -2.90825665e-317,  3.05396926e-001,  6.40503912e-001,
         3.54706166e-001, -4.67306183e-002]]), array([[ 1.36359311e-001, -4.66900606e-002,  9.95750229e-317,
         4.15399203e-002,  4.51712083e-001, -2.20565749e-202,
         6.43998835e-001,  9.68678445e-318],
       [-5.81097294e-001, -1.70504919e-003,  4.37018949e-317,
        -1.32542321e-001,  7.41243458e-001, -3.67652797e-308,
         2.12359563e-001,  1.07165151e-316],
       [-3.51386014e-316, -3.20965962e-316,  3.25598460e-316,
        -1.14200191e-316, -1.39695846e-316, -6.87947677e-317,
         1.74076965e-317,  3.04492732e-316],
       [-3.35965617e-316,  1.38251470e-316, -5.59651551e-316,
         1.42171861e-316,  2.45631406e-317,  1.34494960e-316,
         2.82001752e-317, -3.19924250e-316],
       [ 2.08239754e-001,  1.98411639e-002,  2.28888475e-316,
        -4.47198538e-001,  2.91658628e-002,  1.85868078e-228,
         4.20637959e-001, -1.09265641e-316],
       [ 1.34832828e-001, -9.86858833e-002,  2.01221134e-316,
         4.19802592e-001,  3.91535485e-001, -2.99811479e-195,
         1.58316991e-001, -2.41570621e-316],
       [-7.20343787e-003, -4.11719211e-003,  1.27733830e-316,
         2.03947244e-002,  1.50238566e-001,  1.76282825e-316,
        -4.50235269e-001,  9.57408906e-317],
       [ 1.27074151e-001, -5.53847647e-004,  4.11837362e-317,
        -1.81060057e-001,  8.74041711e-002,  4.27648205e-259,
         7.49674949e-001,  2.23939710e-316]]), array([[-5.94167188e-001],
       [ 4.54351649e-002],
       [ 2.39838669e-316],
       [-9.77755038e-002],
       [ 4.26168264e-001],
       [-1.80617201e-309],
       [ 8.59600134e-001],
       [-1.45274124e-317]])][CV] learning_rate_init=0.00025 ......................................
Iteration 1, loss = 0.48207721
Validation score: 0.165671
Iteration 2, loss = 0.41508432
Validation score: 0.178719
Iteration 3, loss = 0.41070474
Validation score: 0.183188
Iteration 4, loss = 0.40905753
Validation score: 0.184653
Iteration 5, loss = 0.40797028
Validation score: 0.185877
Iteration 6, loss = 0.40692781
Validation score: 0.186892
Iteration 7, loss = 0.40621688
Validation score: 0.188112
Iteration 8, loss = 0.40560587
Validation score: 0.187469
Iteration 9, loss = 0.40506531
Validation score: 0.188673
Iteration 10, loss = 0.40453940
Validation score: 0.188644
Iteration 11, loss = 0.40414337
Validation score: 0.188731
Iteration 12, loss = 0.40375472
Validation score: 0.188565
Iteration 13, loss = 0.40341267
Validation score: 0.189242
Iteration 14, loss = 0.40310336
Validation score: 0.188750
Iteration 15, loss = 0.40277442
Validation score: 0.188970
Iteration 16, loss = 0.40245914
Validation score: 0.188360
Iteration 17, loss = 0.40234450
Validation score: 0.188842
Iteration 18, loss = 0.40200819
Validation score: 0.188556
Iteration 19, loss = 0.40176821
Validation score: 0.187942
Iteration 20, loss = 0.40151368
Validation score: 0.187394
Iteration 21, loss = 0.40127648
Validation score: 0.187686
Iteration 22, loss = 0.40112006
Validation score: 0.187621
Iteration 23, loss = 0.40087948
Validation score: 0.187282
Iteration 24, loss = 0.40061863
Validation score: 0.187102
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.00025, score=-0.7989032085842158, total= 1.9min

[ 0.17895905  0.17448261 -0.01293483  0.12773136 -0.00564431  0.13158106
  0.0472407   0.05458089]
TRAIN
Mean PCC: 0.4822070940143683 +- 0.4399167011370477
PCC: Min: -0.05698979967804128 Max: 0.8789591220507106
Mean MSE: 0.7735111627814409 +- 0.42629514484713177
MSE: Min: 0.33689850490470263 Max: 1.4057603492118853
MSE:
ArgMin: [('4hlb', 95), ('5i29', 139), ('5w0h', 80), ('5aiz', 110), ('4rgi', 71), ('2jku', 35), ('3o2e', 86), ('4o7q', 94), ('2huj', 125), ('6c4q', 85)]
ArgMax: [('4aqo', 86), ('1j0p', 108), ('3dt5', 119), ('2pne', 81), ('5dbl', 130), ('5v0m', 98), ('2w9y', 136), ('1jni', 62), ('1sau', 114), ('2a3m', 107)]
PCC:
ArgMin: [('3dt5', 119), ('4aqo', 86), ('1lmi', 131), ('2h5c', 198), ('2nwf', 141), ('3tch', 517), ('2w9y', 136), ('5j1n', 171), ('5nuv', 301), ('2pne', 81)]
ArgMax: [('5w0h', 80), ('2jku', 35), ('4hlb', 95), ('5zt3', 114), ('5i29', 139), ('2huj', 125), ('6c4q', 85), ('5aiz', 110), ('1xmt', 95), ('6ekb', 62)]
MSE vs Length correlation: 0.04780797372814261
PCC vs Length correlation: 0.06547981000051328
MSE vs b-val mean correlation: 7.3126271151746636e-06
PCC vs b-val mean correlation: 1.27713154163267e-07
VAL
Mean PCC: 0.47893298015078334 +- 0.43461139589527303
PCC: Min: -0.03200492173350541 Max: 0.869471359956026
Mean MSE: 0.776428683850839 +- 0.4181069373985742
MSE: Min: 0.3001833241345815 Max: 1.432688733191061
MSE:
ArgMin: [('2vc8', 72), ('2i5u', 77), ('3mao', 105), ('5hqh', 96), ('4i6x', 117), ('4gos', 115), ('5ijm', 98), ('2b1k', 149), ('5amh', 106), ('1i2t', 61)]
ArgMax: [('2rkn', 77), ('3fgh', 67), ('2rbk', 261), ('1u5p', 211), ('3sw0', 186), ('3gvo', 342), ('2v9k', 467), ('5hfg', 205), ('1cqy', 99), ('3lpz', 314)]
PCC:
ArgMin: [('2rkn', 77), ('2rbk', 261), ('3gvo', 342), ('1u5p', 211), ('5hfg', 205), ('3sw0', 186), ('2v9k', 467), ('4e1b', 330), ('3s9x', 159), ('4rep', 489)]
ArgMax: [('5hqh', 96), ('2vc8', 72), ('4i6x', 117), ('3mao', 105), ('2i5u', 77), ('4gos', 115), ('5ijm', 98), ('2b1k', 149), ('4ytv', 69), ('3tbn', 87)]
MSE vs Length correlation: 0.05755672987668248
PCC vs Length correlation: 0.0816304929570646
MSE vs b-val mean correlation: 0.0018271173485737702
PCC vs b-val mean correlation: 0.0016570896388972134
TEST
Mean PCC: 0.470398098695809 +- 0.44438898369425706
PCC: Min: -0.0374793514257445 Max: 0.8663744995510082
Mean MSE: 0.7843884479662643 +- 0.4323069721707609
MSE: Min: 0.3215685317743255 Max: 1.3309972859590127
MSE:
ArgMin: [('2od5', 91), ('3o70', 55), ('5ol9', 81), ('5kuj', 95), ('3t7l', 74), ('3cp0', 63), ('3chm', 161), ('4qq6', 58), ('1mud', 225), ('2ovg', 58)]
ArgMax: [('4npn', 71), ('4gs3', 90), ('5i8g', 226), ('2vac', 134), ('4xxt', 221), ('3b6e', 182), ('3zr8', 65), ('4qdn', 118), ('5fie', 142), ('4r1b', 282)]
PCC:
ArgMin: [('4npn', 71), ('4xxt', 221), ('5i8g', 226), ('2vac', 134), ('4r1b', 282), ('1r5y', 361), ('4gs3', 90), ('3ip0', 158), ('2xfd', 109), ('4qdn', 118)]
ArgMax: [('2od5', 91), ('5ol9', 81), ('1mud', 225), ('5kuj', 95), ('3o70', 55), ('3cp0', 63), ('3t7l', 74), ('4rwu', 81), ('3chm', 161), ('2eaq', 89)]
MSE vs Length correlation: 0.04486308614021417
PCC vs Length correlation: 0.05882858977398375
MSE vs b-val mean correlation: 2.6461038149516725e-07
PCC vs b-val mean correlation: 1.6466746565302337e-05
[CV] learning_rate_init=0.000125 .....................................
Iteration 1, loss = 0.52577602
Validation score: -0.002807
Iteration 2, loss = 0.50331552
Validation score: -0.000000
Iteration 3, loss = 0.50204207
Validation score: -0.000000
Iteration 4, loss = 0.50133587
Validation score: -0.000004
Iteration 5, loss = 0.50089424
Validation score: -0.000018
Iteration 6, loss = 0.50062789
Validation score: -0.000010
Iteration 7, loss = 0.50047771
Validation score: -0.000002
Iteration 8, loss = 0.50041090
Validation score: -0.000004
Iteration 9, loss = 0.50037838
Validation score: -0.000003
Iteration 10, loss = 0.50036464
Validation score: -0.000000
Iteration 11, loss = 0.50035600
Validation score: -0.000001
Iteration 12, loss = 0.50035458
Validation score: -0.000018
Iteration 13, loss = 0.50035172
Validation score: -0.000038
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.000125, score=-0.9913802564754015, total=  59.2s
[CV] learning_rate_init=0.002 ........................................
Iteration 1, loss = 0.43802089
Validation score: 0.160523
Iteration 2, loss = 0.42017730
Validation score: 0.171400
Iteration 3, loss = 0.41512891
Validation score: 0.177749
Iteration 4, loss = 0.41152397
Validation score: 0.183779
Iteration 5, loss = 0.40968388
Validation score: 0.182848
Iteration 6, loss = 0.40782382
Validation score: 0.185337
Iteration 7, loss = 0.40702672
Validation score: 0.187332
Iteration 8, loss = 0.40621287
Validation score: 0.189616
Iteration 9, loss = 0.40545201
Validation score: 0.190723
Iteration 10, loss = 0.40486458
Validation score: 0.193281
Iteration 11, loss = 0.40413013
Validation score: 0.190619
Iteration 12, loss = 0.40410960
Validation score: 0.184742
Iteration 13, loss = 0.40368986
Validation score: 0.188237
Iteration 14, loss = 0.40370315
Validation score: 0.193472
Iteration 15, loss = 0.40318826
Validation score: 0.191547
Iteration 16, loss = 0.40292247
Validation score: 0.191388
Iteration 17, loss = 0.40253715
Validation score: 0.192591
Iteration 18, loss = 0.40294962
Validation score: 0.191933
Iteration 19, loss = 0.40243408
Validation score: 0.192661
Iteration 20, loss = 0.40213509
Validation score: 0.189512
Iteration 21, loss = 0.40220288
Validation score: 0.192921
Iteration 22, loss = 0.40205488
Validation score: 0.190727
Iteration 23, loss = 0.40229781
Validation score: 0.190251
Iteration 24, loss = 0.40196217
Validation score: 0.191034
Iteration 25, loss = 0.40199710
Validation score: 0.190952
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.002, score=-0.8020010939623906, total= 1.8min
[CV] learning_rate_init=0.0005 .......................................
Iteration 1, loss = 0.47506364
Validation score: 0.159001
Iteration 2, loss = 0.41555499
Validation score: 0.184378
Iteration 3, loss = 0.40949857
Validation score: 0.189587
Iteration 4, loss = 0.40802522
Validation score: 0.187926
Iteration 5, loss = 0.40713607
Validation score: 0.191377
Iteration 6, loss = 0.40636230
Validation score: 0.191691
Iteration 7, loss = 0.40567219
Validation score: 0.192284
Iteration 8, loss = 0.40510604
Validation score: 0.192466
Iteration 9, loss = 0.40452541
Validation score: 0.191486
Iteration 10, loss = 0.40388081
Validation score: 0.192280
Iteration 11, loss = 0.40334024
Validation score: 0.190606
Iteration 12, loss = 0.40285495
Validation score: 0.190309
Iteration 13, loss = 0.40248640
Validation score: 0.188591
Iteration 14, loss = 0.40198052
Validation score: 0.188817
Iteration 15, loss = 0.40148044
Validation score: 0.190504
Iteration 16, loss = 0.40107809
Validation score: 0.188510
Iteration 17, loss = 0.40085814
Validation score: 0.187245
Iteration 18, loss = 0.40043039
Validation score: 0.188728
Iteration 19, loss = 0.40006553
Validation score: 0.185155
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.0005, score=-0.8023238916043179, total= 1.4min
[CV] learning_rate_init=0.004 ........................................
Iteration 1, loss = 0.43896262
Validation score: 0.183584
Iteration 2, loss = 0.41256084
Validation score: 0.183096
Iteration 3, loss = 0.41103853
Validation score: 0.186239
Iteration 4, loss = 0.40993059
Validation score: 0.180851
Iteration 5, loss = 0.40955841
Validation score: 0.185560
Iteration 6, loss = 0.40937780
Validation score: 0.188424
Iteration 7, loss = 0.40920503
Validation score: 0.189704
Iteration 8, loss = 0.40906522
Validation score: 0.179189
Iteration 9, loss = 0.40856657
Validation score: 0.188805
Iteration 10, loss = 0.40875169
Validation score: 0.189161
Iteration 11, loss = 0.40842973
Validation score: 0.190686
Iteration 12, loss = 0.40843375
Validation score: 0.189565
Iteration 13, loss = 0.40842543
Validation score: 0.191182
Iteration 14, loss = 0.40808350
Validation score: 0.189246
Iteration 15, loss = 0.40819721
Validation score: 0.189739
Iteration 16, loss = 0.40826641
Validation score: 0.186240
Iteration 17, loss = 0.40809032
Validation score: 0.187039
Iteration 18, loss = 0.40784674
Validation score: 0.187973
Iteration 19, loss = 0.40782005
Validation score: 0.192690
Iteration 20, loss = 0.40769148
Validation score: 0.192823
Iteration 21, loss = 0.40752827
Validation score: 0.193410
Iteration 22, loss = 0.40725208
Validation score: 0.194221
Iteration 23, loss = 0.40732074
Validation score: 0.190911
Iteration 24, loss = 0.40692355
Validation score: 0.191330
Iteration 25, loss = 0.40730381
Validation score: 0.180621
Iteration 26, loss = 0.40718461
Validation score: 0.193075
Iteration 27, loss = 0.40706154
Validation score: 0.191685
Iteration 28, loss = 0.40730474
Validation score: 0.194479
Iteration 29, loss = 0.40729416
Validation score: 0.193213
Iteration 30, loss = 0.40713885
Validation score: 0.190645
Iteration 31, loss = 0.40699757
Validation score: 0.191539
Iteration 32, loss = 0.40706543
Validation score: 0.189375
Iteration 33, loss = 0.40722094
Validation score: 0.187679
Iteration 34, loss = 0.40688573
Validation score: 0.193244
Iteration 35, loss = 0.40685505
Validation score: 0.186882
Iteration 36, loss = 0.40691630
Validation score: 0.194499
Iteration 37, loss = 0.40712164
Validation score: 0.194058
Iteration 38, loss = 0.40682502
Validation score: 0.193576
Iteration 39, loss = 0.40716494
Validation score: 0.194304
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.004, score=-0.7993476470584195, total= 2.5min
[CV] learning_rate_init=0.001 ........................................
Iteration 1, loss = 0.45154395
Validation score: 0.184472
Iteration 2, loss = 0.41175764
Validation score: 0.187470
Iteration 3, loss = 0.40952896
Validation score: 0.189134
Iteration 4, loss = 0.40773108
Validation score: 0.186200
Iteration 5, loss = 0.40609653
Validation score: 0.194398
Iteration 6, loss = 0.40500767
Validation score: 0.193588
Iteration 7, loss = 0.40410827
Validation score: 0.192590
Iteration 8, loss = 0.40355024
Validation score: 0.194369
Iteration 9, loss = 0.40307484
Validation score: 0.194976
Iteration 10, loss = 0.40245440
Validation score: 0.195421
Iteration 11, loss = 0.40211639
Validation score: 0.192950
Iteration 12, loss = 0.40160725
Validation score: 0.194254
Iteration 13, loss = 0.40157239
Validation score: 0.193774
Iteration 14, loss = 0.40116431
Validation score: 0.193823
Iteration 15, loss = 0.40087879
Validation score: 0.193305
Iteration 16, loss = 0.40073433
Validation score: 0.191783
Iteration 17, loss = 0.40055799
Validation score: 0.186532
Iteration 18, loss = 0.40051262
Validation score: 0.192907
Iteration 19, loss = 0.40018017
Validation score: 0.189255
Iteration 20, loss = 0.40008384
Validation score: 0.188405
Iteration 21, loss = 0.39976615
Validation score: 0.191498
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.001, score=-0.7990316366515122, total= 1.7min
[CV] learning_rate_init=0.008 ........................................
Iteration 1, loss = 0.42930277
Validation score: 0.185771
Iteration 2, loss = 0.41626635
Validation score: 0.190652
Iteration 3, loss = 0.41473158
Validation score: 0.192462
Iteration 4, loss = 0.41436808
Validation score: 0.194448
Iteration 5, loss = 0.41388974
Validation score: 0.189102
Iteration 6, loss = 0.41343301
Validation score: 0.188930
Iteration 7, loss = 0.41295043
Validation score: 0.194362
Iteration 8, loss = 0.41257250
Validation score: 0.194548
Iteration 9, loss = 0.41288384
Validation score: 0.192512
Iteration 10, loss = 0.41275598
Validation score: 0.194923
Iteration 11, loss = 0.41231409
Validation score: 0.189634
Iteration 12, loss = 0.41257898
Validation score: 0.194628
Iteration 13, loss = 0.41258726
Validation score: 0.195119
Iteration 14, loss = 0.41242892
Validation score: 0.192763
Iteration 15, loss = 0.41251600
Validation score: 0.194740
Iteration 16, loss = 0.41237509
Validation score: 0.193439
Iteration 17, loss = 0.41190338
Validation score: 0.195402
Iteration 18, loss = 0.41236218
Validation score: 0.193841
Iteration 19, loss = 0.41205446
Validation score: 0.195136
Iteration 20, loss = 0.41211413
Validation score: 0.177653
Iteration 21, loss = 0.41237691
Validation score: 0.195892
Iteration 22, loss = 0.41218768
Validation score: 0.187347
Iteration 23, loss = 0.41196473
Validation score: 0.190831
Iteration 24, loss = 0.41211270
Validation score: 0.193722
Iteration 25, loss = 0.41176142
Validation score: 0.190597
Iteration 26, loss = 0.41203034
Validation score: 0.196749
Iteration 27, loss = 0.41201011
Validation score: 0.193943
Iteration 28, loss = 0.41196163
Validation score: 0.192483
Iteration 29, loss = 0.41201956
Validation score: 0.194236
Iteration 30, loss = 0.41179938
Validation score: 0.193820
Iteration 31, loss = 0.41206066
Validation score: 0.193101
Iteration 32, loss = 0.41202776
Validation score: 0.194227
Iteration 33, loss = 0.41202068
Validation score: 0.196571
Iteration 34, loss = 0.41214105
Validation score: 0.193292
Iteration 35, loss = 0.41188878
Validation score: 0.194547
Iteration 36, loss = 0.41171439
Validation score: 0.195072
Iteration 37, loss = 0.41204980
Validation score: 0.185661
Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
[CV]  learning_rate_init=0.008, score=-0.8038267945195308, total= 2.4min
